{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73968,"status":"ok","timestamp":1706020256865,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"},"user_tz":-360},"id":"VsnnqvxNv8B3","outputId":"77ec2eef-e389-4f63-e0c9-d45cab632ed4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7300,"status":"ok","timestamp":1706020264128,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"},"user_tz":-360},"id":"CK6i8Q8zuzm8","outputId":"d03ca464-3456-40c3-9f26-c6cc89b66758"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n"]}],"source":["pip install numpy scipy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11205,"status":"ok","timestamp":1706020275290,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"},"user_tz":-360},"id":"XI0UBsmdu1mL","outputId":"46e86600-9019-47ac-dd1a-e4022affb6b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bangla\n","  Downloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n","Installing collected packages: bangla\n","Successfully installed bangla-0.0.2\n"]}],"source":["pip install bangla"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsNO3t5IiMCG"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","import re,json,nltk\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score,f1_score\n","from tensorflow.keras.preprocessing.text import Tokenizer"]},{"cell_type":"markdown","metadata":{"id":"EivU7D4sP9M-"},"source":["**Importing important libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aCBBZEJMzKZC"},"outputs":[],"source":["# general library\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import re\n","import matplotlib.pyplot as plt\n","import os\n","import bangla\n","import io\n","import string\n","%matplotlib inline\n","#import Wordcloud\n","\n","# nlp packages\n","import nltk\n","# import bnltk\n","import regex\n","from nltk import word_tokenize\n","from collections import Counter\n","# from bltk.langtools import Tokenizer\n","# from bnltk.tokenize import Tokenizers\n","#from wordcloud import WordCloud\n","\n","#modeling packages\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score ,log_loss\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn import preprocessing\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from numpy import mean\n","from numpy import std\n","from sklearn import metrics\n","from sklearn import tree\n","import time\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from os import path\n","from PIL import Image\n","\n","#Machine learning model\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.linear_model import PassiveAggressiveClassifier\n","from sklearn.neural_network import MLPClassifier\n","\n","#Deep learning library\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.text import one_hot\n","from tensorflow.keras.layers import Dense, Dropout, Embedding, GRU, LSTM, RNN, SpatialDropout1D\n","# from tensorflow.keras.layers import Dense\n","from keras.preprocessing.text import Tokenizer"]},{"cell_type":"markdown","metadata":{"id":"l8NVgfW5QKFt"},"source":["## **Reading dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":1517,"status":"ok","timestamp":1706020284089,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"},"user_tz":-360},"id":"lTnzApSy0bBd","outputId":"f83240d8-b2a7-4984-ea31-d598c163831c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Serial                                               Data Label\n","0          1  এইডস আমাদের দেশে প্রকট নয়। তারপরও সাবধানতা অবল...  REAL\n","1          2  এইডস সংক্রমিতদের মধ্যে রয়েছেন নারী ও পুরুষ যৌন...  REAL\n","2          3  যারা সহজেই সর্দিতে আক্রান্ত হয় (বিশেষ করে শিশু...  REAL\n","3          4  কোকাকোলা, পেপসি, স্প্রাইট ইত্যাদি কোমল পানীয় ন...  REAL\n","4          5  শরীরের কোন অংশ যদি পুড়ে যায় তাহলে তুলসীর রস এব...  FAKE\n","...      ...                                                ...   ...\n","5033    5034  পিঠ, ঘাড়, নিতম্বে বিরুপ প্রভাব ফেলে মোটা বা বে...  REAL\n","5034    5035          মোটা মানিব্যাগ শারীরিক ভারসাম্য নষ্ট করে।  REAL\n","5035    5036  মোটা মানিব্যাগ পকেটে থাকা অবস্থায় বসে থাকার অভ...  REAL\n","5036    5037  মোটা মানিব্যাগে ওপর বসে থাকলে শিরদাঁড়ায়ও চাপ পড়ে।  REAL\n","5037    5038   মোটা মানিব্যাগের কারণে নানা স্নায়ুর সমস্যাও দ...  REAL\n","\n","[5038 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-1e643ba6-c457-4097-8392-dc0bd3b3dd04\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Serial</th>\n","      <th>Data</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>এইডস আমাদের দেশে প্রকট নয়। তারপরও সাবধানতা অবল...</td>\n","      <td>REAL</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>এইডস সংক্রমিতদের মধ্যে রয়েছেন নারী ও পুরুষ যৌন...</td>\n","      <td>REAL</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>যারা সহজেই সর্দিতে আক্রান্ত হয় (বিশেষ করে শিশু...</td>\n","      <td>REAL</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>কোকাকোলা, পেপসি, স্প্রাইট ইত্যাদি কোমল পানীয় ন...</td>\n","      <td>REAL</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>শরীরের কোন অংশ যদি পুড়ে যায় তাহলে তুলসীর রস এব...</td>\n","      <td>FAKE</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5033</th>\n","      <td>5034</td>\n","      <td>পিঠ, ঘাড়, নিতম্বে বিরুপ প্রভাব ফেলে মোটা বা বে...</td>\n","      <td>REAL</td>\n","    </tr>\n","    <tr>\n","      <th>5034</th>\n","      <td>5035</td>\n","      <td>মোটা মানিব্যাগ শারীরিক ভারসাম্য নষ্ট করে।</td>\n","      <td>REAL</td>\n","    </tr>\n","    <tr>\n","      <th>5035</th>\n","      <td>5036</td>\n","      <td>মোটা মানিব্যাগ পকেটে থাকা অবস্থায় বসে থাকার অভ...</td>\n","      <td>REAL</td>\n","    </tr>\n","    <tr>\n","      <th>5036</th>\n","      <td>5037</td>\n","      <td>মোটা মানিব্যাগে ওপর বসে থাকলে শিরদাঁড়ায়ও চাপ পড়ে।</td>\n","      <td>REAL</td>\n","    </tr>\n","    <tr>\n","      <th>5037</th>\n","      <td>5038</td>\n","      <td>মোটা মানিব্যাগের কারণে নানা স্নায়ুর সমস্যাও দ...</td>\n","      <td>REAL</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5038 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e643ba6-c457-4097-8392-dc0bd3b3dd04')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1e643ba6-c457-4097-8392-dc0bd3b3dd04 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1e643ba6-c457-4097-8392-dc0bd3b3dd04');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-627d2e54-1322-4f34-8086-fb8305331163\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-627d2e54-1322-4f34-8086-fb8305331163')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-627d2e54-1322-4f34-8086-fb8305331163 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_f099ac4a-8518-4a7a-961b-fea3d066b3e4\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_set')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_f099ac4a-8518-4a7a-961b-fea3d066b3e4 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('data_set');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":6}],"source":["data_set = pd.read_csv(\"/content/drive/MyDrive/Thesis/dataset/Health_dataset final.csv\")\n","data_set"]},{"cell_type":"markdown","metadata":{"id":"x6y9yBxDQZaU"},"source":["## ***Data Pre-Processing***"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":144,"status":"ok","timestamp":1706020284097,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"},"user_tz":-360},"id":"aUgrLrp905Rb","outputId":"54109506-3f81-48f1-d928-d9cb09fb2504"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Serial                                               Data  Label\n","0          1  এইডস আমাদের দেশে প্রকট নয়। তারপরও সাবধানতা অবল...      1\n","1          2  এইডস সংক্রমিতদের মধ্যে রয়েছেন নারী ও পুরুষ যৌন...      1\n","2          3  যারা সহজেই সর্দিতে আক্রান্ত হয় (বিশেষ করে শিশু...      1\n","3          4  কোকাকোলা, পেপসি, স্প্রাইট ইত্যাদি কোমল পানীয় ন...      1\n","4          5  শরীরের কোন অংশ যদি পুড়ে যায় তাহলে তুলসীর রস এব...      0\n","...      ...                                                ...    ...\n","5033    5034  পিঠ, ঘাড়, নিতম্বে বিরুপ প্রভাব ফেলে মোটা বা বে...      1\n","5034    5035          মোটা মানিব্যাগ শারীরিক ভারসাম্য নষ্ট করে।      1\n","5035    5036  মোটা মানিব্যাগ পকেটে থাকা অবস্থায় বসে থাকার অভ...      1\n","5036    5037  মোটা মানিব্যাগে ওপর বসে থাকলে শিরদাঁড়ায়ও চাপ পড়ে।      1\n","5037    5038   মোটা মানিব্যাগের কারণে নানা স্নায়ুর সমস্যাও দ...      1\n","\n","[5038 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-55afaa1e-583e-4295-b14c-29457dfe5ccc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Serial</th>\n","      <th>Data</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>এইডস আমাদের দেশে প্রকট নয়। তারপরও সাবধানতা অবল...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>এইডস সংক্রমিতদের মধ্যে রয়েছেন নারী ও পুরুষ যৌন...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>যারা সহজেই সর্দিতে আক্রান্ত হয় (বিশেষ করে শিশু...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>কোকাকোলা, পেপসি, স্প্রাইট ইত্যাদি কোমল পানীয় ন...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>শরীরের কোন অংশ যদি পুড়ে যায় তাহলে তুলসীর রস এব...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5033</th>\n","      <td>5034</td>\n","      <td>পিঠ, ঘাড়, নিতম্বে বিরুপ প্রভাব ফেলে মোটা বা বে...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5034</th>\n","      <td>5035</td>\n","      <td>মোটা মানিব্যাগ শারীরিক ভারসাম্য নষ্ট করে।</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5035</th>\n","      <td>5036</td>\n","      <td>মোটা মানিব্যাগ পকেটে থাকা অবস্থায় বসে থাকার অভ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5036</th>\n","      <td>5037</td>\n","      <td>মোটা মানিব্যাগে ওপর বসে থাকলে শিরদাঁড়ায়ও চাপ পড়ে।</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5037</th>\n","      <td>5038</td>\n","      <td>মোটা মানিব্যাগের কারণে নানা স্নায়ুর সমস্যাও দ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5038 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55afaa1e-583e-4295-b14c-29457dfe5ccc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-55afaa1e-583e-4295-b14c-29457dfe5ccc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-55afaa1e-583e-4295-b14c-29457dfe5ccc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bd7753e4-a674-4ce1-b383-34d8db11844a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd7753e4-a674-4ce1-b383-34d8db11844a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bd7753e4-a674-4ce1-b383-34d8db11844a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_9a19839e-e08d-457b-ac68-8d9d345134a4\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_set')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_9a19839e-e08d-457b-ac68-8d9d345134a4 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('data_set');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":7}],"source":["from sklearn import preprocessing\n","label_encoder = preprocessing.LabelEncoder()\n","data_set['Label']= label_encoder.fit_transform(data_set['Label'])\n","data_set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w4Ip3PJT0xYc"},"outputs":[],"source":["text_data = data_set.drop('Label' ,axis = 1)\n","label = data_set['Label']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10586,"status":"ok","timestamp":1706020294576,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"},"user_tz":-360},"id":"XGdD70JJ1WCI","outputId":"946213f2-5ab6-47c0-d779-df97c0915640"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["pip install torch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11953,"status":"ok","timestamp":1706020307061,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"},"user_tz":-360},"id":"cgsCFe8EtdKa","outputId":"2c82e4e3-2aed-4b27-e0e7-8b494dfc299a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-geometric\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m0.9/1.0 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n"]}],"source":["!pip install torch-geometric"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["cdebf918f579483488985221ca98d144","86df6eb4ea7247d7ab93ca43e85807b3","a4d6fd8a0d9a41b9a55cfaacb36b144c","0c3f63a2ef4640df972be79369db0ed3","ebffbf8852fe4d3aad69a2226a7fc509","2a825d20f7544d1ab320c29d43d71ce8","2ab87aa815c64caf8d8237b5d69a15a3","9470102d19de423294adb4145f37aba4","37ced5aadbdf471cb7657be0bbf465b4","1ea591c743f04e91a23791f9b0556cb5","c1d3ed7945de4d639a065af79bab717d","4a11a81715e343aba1d75d5a22f94450","0cb8275dd2b0441c96efa1fc157dd7b9","e6e8d24e69954726a0e8cd86e2e0c7c5","4bdb5a35b8264bf997087f74e6d34afe","053fc9af99c243708fa4b84c52768145","a87a83538bd44c2a8f55f1404e48ce9a","375f3639f20d446a88d55211324e0881","8cfe51f9dff74728b979305a700effca","23c5b537ccee4ff089f4dbeefd90e384","9536e7a44e2742549df6ada4a6326a7e","eb3e9f5b1cab4ede9b6951b7a6cb5be2","77d685d65e44495086a27efc107dcb44","fd43533b79a349e49ee226a3018d4d57","1f83c854edf74b20b6fd1ec53a1141b9","fc4369f8a2e54691b1bccd5439789f61","6db69e7afc78438b8d746a7ee87ed7d9","6a41039bb68c4804a09b01c85af69fec","837d7f04a6ba402f9f9378354a7916b5","f96225db819445daa53d539fa368bd32","998b52d602d548d7ba85856b848f8944","620012deadb24fde8540bd6bf42f0cda","ea7d802376f745caad2eadb1861c7542"]},"executionInfo":{"elapsed":995845,"status":"ok","timestamp":1706021302783,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"},"user_tz":-360},"id":"Yu1A0ELXta4v","outputId":"82f56132-6846-49c3-ac24-9aeb7bfd240d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/2.24M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdebf918f579483488985221ca98d144"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/491 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a11a81715e343aba1d75d5a22f94450"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/660M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77d685d65e44495086a27efc107dcb44"}},"metadata":{}}],"source":["import torch\n","from transformers import BertTokenizer, BertModel\n","\n","# Initialize the tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n","bert_model = BertModel.from_pretrained(\"sagorsarker/bangla-bert-base\")\n","\n","\n","# Function to encode text data using BERT\n","def encode_with_bert(text_data):\n","    encoded_input = tokenizer(text_data, padding=True, truncation=True, return_tensors='pt', max_length=512)\n","    with torch.no_grad():\n","        output = bert_model(**encoded_input)\n","    return output.last_hidden_state.mean(dim=1)  # Mean pooling\n","\n","# Apply BERT encoding to your text data\n","text_data['bert_embeddings'] = text_data['Data'].apply(encode_with_bert)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":792,"status":"ok","timestamp":1706021303557,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"},"user_tz":-360},"id":"tTp-HaOAtoEC","outputId":"9e1978f7-3d44-48bb-e505-a35c7a949545"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       [[tensor(0.6382), tensor(-0.2183), tensor(0.65...\n","1       [[tensor(0.4591), tensor(-0.9689), tensor(0.19...\n","2       [[tensor(0.3622), tensor(-0.9371), tensor(0.57...\n","3       [[tensor(0.5297), tensor(-0.9820), tensor(0.20...\n","4       [[tensor(0.1362), tensor(-0.5874), tensor(0.78...\n","                              ...                        \n","5033    [[tensor(0.7835), tensor(-1.5372), tensor(0.24...\n","5034    [[tensor(0.5129), tensor(-1.0631), tensor(0.25...\n","5035    [[tensor(0.7858), tensor(-1.3091), tensor(0.42...\n","5036    [[tensor(0.8620), tensor(-0.9559), tensor(-0.0...\n","5037    [[tensor(1.0342), tensor(-1.0037), tensor(0.10...\n","Name: bert_embeddings, Length: 5038, dtype: object"]},"metadata":{},"execution_count":12}],"source":["x_data = text_data['bert_embeddings']\n","x_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1706021303558,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"},"user_tz":-360},"id":"2m0zvdybtqxe","outputId":"bbff2b80-64e0-4717-f3ac-4512e059c53e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, ..., 1, 1, 1])"]},"metadata":{},"execution_count":13}],"source":["y = data_set['Label'].values\n","y"]},{"cell_type":"markdown","metadata":{"id":"XsssFUDQQwMX"},"source":["#***Feature extraction***"]},{"cell_type":"markdown","metadata":{"id":"qWWIYM2ToyD2"},"source":["**My Own**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6iBRx5dol1pv"},"outputs":[],"source":["from torch_geometric.nn import GCNConv\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.data import Data\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fx7QWriiuBui"},"outputs":[],"source":["def create_single_graph_data(embedding, label):\n","    x = embedding.view(1, -1)\n","    y = torch.tensor([label], dtype=torch.long)\n","    edge_index = torch.empty((2, 0), dtype=torch.long)\n","    return Data(x=x, edge_index=edge_index, y=y)\n","\n","# Create a list of graph data objects\n","graph_list = [create_single_graph_data(emb, lbl) for emb, lbl in zip(text_data['bert_embeddings'], data_set['Label'])]"]},{"cell_type":"markdown","metadata":{"id":"_2-XmPXp3x0c"},"source":["## **GCN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqOQVY37y4xC"},"outputs":[],"source":["class GCNModel(torch.nn.Module):\n","    def __init__(self, bert_embedding_size, hidden_channels, num_classes):\n","        super(GCNModel, self).__init__()\n","        self.conv1 = GCNConv(bert_embedding_size, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8zGBDZu-m4E"},"outputs":[],"source":["def train(loader, model, criterion, optimizer):\n","    model.train()\n","    total_loss = 0\n","    for batch in loader:\n","        batch.to(device)  # Move to device\n","        optimizer.zero_grad()\n","        out = model(batch)\n","        loss = criterion(out, batch.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(loader.dataset)\n","\n","def evaluate(loader, model):\n","    model.eval()\n","    total_correct = 0\n","    total = 0\n","    for batch in loader:\n","        batch.to(device)  # Move to device\n","        _, pred = model(batch).max(dim=1)\n","        total_correct += int(pred.eq(batch.y).sum().item())\n","        total += batch.num_graphs\n","    return total_correct / total\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Y4Z5mfEnPR5"},"outputs":[],"source":["from torch_geometric.nn import GCNConv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9XloLy4enRmj"},"outputs":[],"source":["import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWbVIfg3nRsh","executionInfo":{"status":"ok","timestamp":1706024343244,"user_tz":-360,"elapsed":106629,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"37b0172b-e750-4a9e-bf04-4e8f02580623"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1\n","Epoch 0, Train Acc: 0.6499779444199383, Val Acc: 0.7182539682539683\n","Epoch 1, Train Acc: 0.7084252315835906, Val Acc: 0.7222222222222222\n","Epoch 2, Train Acc: 0.7298191442434936, Val Acc: 0.746031746031746\n","Epoch 3, Train Acc: 0.7481252756947507, Val Acc: 0.751984126984127\n","Epoch 4, Train Acc: 0.7516541685046316, Val Acc: 0.7321428571428571\n","Epoch 5, Train Acc: 0.7710630789589766, Val Acc: 0.7817460317460317\n","Epoch 6, Train Acc: 0.78429642699603, Val Acc: 0.7797619047619048\n","Epoch 7, Train Acc: 0.7984119982355536, Val Acc: 0.7797619047619048\n","Epoch 8, Train Acc: 0.8012792236435818, Val Acc: 0.7916666666666666\n","Epoch 9, Train Acc: 0.8134097926775474, Val Acc: 0.7956349206349206\n","Epoch 10, Train Acc: 0.8250992501102778, Val Acc: 0.8214285714285714\n","Epoch 11, Train Acc: 0.8359064843405382, Val Acc: 0.8035714285714286\n","Epoch 12, Train Acc: 0.8303925893250993, Val Acc: 0.8055555555555556\n","Epoch 13, Train Acc: 0.8442876047640053, Val Acc: 0.8134920634920635\n","Epoch 14, Train Acc: 0.848919276576974, Val Acc: 0.8273809523809523\n","Epoch 15, Train Acc: 0.8643581826202029, Val Acc: 0.8134920634920635\n","Epoch 16, Train Acc: 0.8700926334362594, Val Acc: 0.8273809523809523\n","Epoch 17, Train Acc: 0.8597265108072343, Val Acc: 0.8174603174603174\n","Epoch 18, Train Acc: 0.8780326422584914, Val Acc: 0.8650793650793651\n","Epoch 19, Train Acc: 0.868769298632554, Val Acc: 0.8511904761904762\n","Epoch 20, Train Acc: 0.8804587560652846, Val Acc: 0.8551587301587301\n","Epoch 21, Train Acc: 0.888178209086899, Val Acc: 0.878968253968254\n","Epoch 22, Train Acc: 0.8925893250992502, Val Acc: 0.8531746031746031\n","Epoch 23, Train Acc: 0.8965593295103661, Val Acc: 0.8690476190476191\n","Epoch 24, Train Acc: 0.8989854433171592, Val Acc: 0.8849206349206349\n","Epoch 25, Train Acc: 0.8983237759153065, Val Acc: 0.878968253968254\n","Epoch 26, Train Acc: 0.8996471107190119, Val Acc: 0.875\n","Epoch 27, Train Acc: 0.9036171151301279, Val Acc: 0.8888888888888888\n","Epoch 28, Train Acc: 0.9042787825319806, Val Acc: 0.9027777777777778\n","Epoch 29, Train Acc: 0.9044993383325981, Val Acc: 0.9087301587301587\n","Epoch 30, Train Acc: 0.9091310101455669, Val Acc: 0.9047619047619048\n","Epoch 31, Train Acc: 0.9124393471548302, Val Acc: 0.9047619047619048\n","Epoch 32, Train Acc: 0.905602117335686, Val Acc: 0.8829365079365079\n","Epoch 33, Train Acc: 0.9137626819585355, Val Acc: 0.9226190476190477\n","Epoch 34, Train Acc: 0.919497132774592, Val Acc: 0.9186507936507936\n","Epoch 35, Train Acc: 0.9124393471548302, Val Acc: 0.8869047619047619\n","Epoch 36, Train Acc: 0.9161887957653286, Val Acc: 0.9206349206349206\n","Epoch 37, Train Acc: 0.9267754741949713, Val Acc: 0.9206349206349206\n","Epoch 38, Train Acc: 0.9225849139832377, Val Acc: 0.9345238095238095\n","Epoch 39, Train Acc: 0.9168504631671813, Val Acc: 0.9027777777777778\n","Epoch 40, Train Acc: 0.9243493603881782, Val Acc: 0.9047619047619048\n","Epoch 41, Train Acc: 0.9177326863696516, Val Acc: 0.9265873015873016\n","Epoch 42, Train Acc: 0.9269960299955888, Val Acc: 0.9404761904761905\n","Epoch 43, Train Acc: 0.929422143802382, Val Acc: 0.9325396825396826\n","Epoch 44, Train Acc: 0.9265549183943538, Val Acc: 0.9087301587301587\n","Epoch 45, Train Acc: 0.9285399205999118, Val Acc: 0.9325396825396826\n","Epoch 46, Train Acc: 0.9269960299955888, Val Acc: 0.9484126984126984\n","Epoch 47, Train Acc: 0.9344949272165858, Val Acc: 0.9365079365079365\n","Epoch 48, Train Acc: 0.9228054697838554, Val Acc: 0.9404761904761905\n","Epoch 49, Train Acc: 0.9265549183943538, Val Acc: 0.9345238095238095\n","Epoch 50, Train Acc: 0.9389060432289369, Val Acc: 0.9206349206349206\n","Epoch 51, Train Acc: 0.9331715924128805, Val Acc: 0.9305555555555556\n","Epoch 52, Train Acc: 0.9247904719894133, Val Acc: 0.9325396825396826\n","Epoch 53, Train Acc: 0.9367004852227614, Val Acc: 0.9325396825396826\n","Epoch 54, Train Acc: 0.9322893692104103, Val Acc: 0.9404761904761905\n","Epoch 55, Train Acc: 0.9305249228054698, Val Acc: 0.9246031746031746\n","Epoch 56, Train Acc: 0.935377150419056, Val Acc: 0.9325396825396826\n","Epoch 57, Train Acc: 0.9292015880017644, Val Acc: 0.9464285714285714\n","Epoch 58, Train Acc: 0.9393471548301721, Val Acc: 0.9464285714285714\n","Epoch 59, Train Acc: 0.9477282752536391, Val Acc: 0.9543650793650794\n","Epoch 60, Train Acc: 0.9448610498456109, Val Acc: 0.9305555555555556\n","Epoch 61, Train Acc: 0.94133215703573, Val Acc: 0.9503968253968254\n","Epoch 62, Train Acc: 0.9389060432289369, Val Acc: 0.9424603174603174\n","Epoch 63, Train Acc: 0.9395677106307896, Val Acc: 0.9444444444444444\n","Epoch 64, Train Acc: 0.9386854874283194, Val Acc: 0.9444444444444444\n","Epoch 65, Train Acc: 0.9369210410233789, Val Acc: 0.9404761904761905\n","Epoch 66, Train Acc: 0.9422143802382003, Val Acc: 0.9424603174603174\n","Epoch 67, Train Acc: 0.9382443758270842, Val Acc: 0.9523809523809523\n","Epoch 68, Train Acc: 0.9441993824437582, Val Acc: 0.9563492063492064\n","Epoch 69, Train Acc: 0.9466254962505514, Val Acc: 0.9523809523809523\n","Epoch 70, Train Acc: 0.929422143802382, Val Acc: 0.9265873015873016\n","Epoch 71, Train Acc: 0.9318482576091751, Val Acc: 0.9404761904761905\n","Epoch 72, Train Acc: 0.9444199382443759, Val Acc: 0.9345238095238095\n","Epoch 73, Train Acc: 0.9472871636524041, Val Acc: 0.9365079365079365\n","Epoch 74, Train Acc: 0.9446404940449934, Val Acc: 0.9424603174603174\n","Epoch 75, Train Acc: 0.9468460520511689, Val Acc: 0.9444444444444444\n","Epoch 76, Train Acc: 0.9411116012351125, Val Acc: 0.9325396825396826\n","Epoch 77, Train Acc: 0.940891045434495, Val Acc: 0.9464285714285714\n","Epoch 78, Train Acc: 0.9466254962505514, Val Acc: 0.9464285714285714\n","Epoch 79, Train Acc: 0.9470666078517865, Val Acc: 0.9444444444444444\n","Epoch 80, Train Acc: 0.9468460520511689, Val Acc: 0.9464285714285714\n","Epoch 81, Train Acc: 0.94133215703573, Val Acc: 0.9444444444444444\n","Epoch 82, Train Acc: 0.9435377150419056, Val Acc: 0.9384920634920635\n","Epoch 83, Train Acc: 0.9411116012351125, Val Acc: 0.9503968253968254\n","Epoch 84, Train Acc: 0.9439788266431407, Val Acc: 0.9503968253968254\n","Epoch 85, Train Acc: 0.9417732686369652, Val Acc: 0.9345238095238095\n","Epoch 86, Train Acc: 0.9424349360388178, Val Acc: 0.9543650793650794\n","Epoch 87, Train Acc: 0.9497132774591972, Val Acc: 0.9603174603174603\n","Epoch 88, Train Acc: 0.9525805028672254, Val Acc: 0.9543650793650794\n","Epoch 89, Train Acc: 0.9483899426554918, Val Acc: 0.9603174603174603\n","Epoch 90, Train Acc: 0.9448610498456109, Val Acc: 0.9543650793650794\n","Epoch 91, Train Acc: 0.9475077194530216, Val Acc: 0.9603174603174603\n","Epoch 92, Train Acc: 0.9501543890604323, Val Acc: 0.9642857142857143\n","Epoch 93, Train Acc: 0.948831054256727, Val Acc: 0.9603174603174603\n","Epoch 94, Train Acc: 0.9550066166740185, Val Acc: 0.9484126984126984\n","Epoch 95, Train Acc: 0.9550066166740185, Val Acc: 0.9503968253968254\n","Epoch 96, Train Acc: 0.9514777238641376, Val Acc: 0.9444444444444444\n","Epoch 97, Train Acc: 0.9468460520511689, Val Acc: 0.9543650793650794\n","Epoch 98, Train Acc: 0.9561093956771063, Val Acc: 0.9543650793650794\n","Epoch 99, Train Acc: 0.9444199382443759, Val Acc: 0.9444444444444444\n","Epoch 100, Train Acc: 0.9525805028672254, Val Acc: 0.9503968253968254\n","Epoch 101, Train Acc: 0.9424349360388178, Val Acc: 0.9345238095238095\n","Epoch 102, Train Acc: 0.9404499338332598, Val Acc: 0.9444444444444444\n","Epoch 103, Train Acc: 0.9494927216585797, Val Acc: 0.9543650793650794\n","Epoch 104, Train Acc: 0.9561093956771063, Val Acc: 0.9603174603174603\n","Epoch 105, Train Acc: 0.9528010586678429, Val Acc: 0.9543650793650794\n","Epoch 106, Train Acc: 0.9523599470666079, Val Acc: 0.9603174603174603\n","Epoch 107, Train Acc: 0.9561093956771063, Val Acc: 0.9642857142857143\n","Epoch 108, Train Acc: 0.9459638288486987, Val Acc: 0.9583333333333334\n","Epoch 109, Train Acc: 0.9477282752536391, Val Acc: 0.9484126984126984\n","Epoch 110, Train Acc: 0.9563299514777238, Val Acc: 0.9603174603174603\n","Epoch 111, Train Acc: 0.9523599470666079, Val Acc: 0.9404761904761905\n","Epoch 112, Train Acc: 0.9516982796647552, Val Acc: 0.9623015873015873\n","Epoch 113, Train Acc: 0.9516982796647552, Val Acc: 0.9563492063492064\n","Epoch 114, Train Acc: 0.9497132774591972, Val Acc: 0.9563492063492064\n","Epoch 115, Train Acc: 0.9479488310542568, Val Acc: 0.9563492063492064\n","Epoch 116, Train Acc: 0.942876047640053, Val Acc: 0.9424603174603174\n","Epoch 117, Train Acc: 0.9510366122629025, Val Acc: 0.9543650793650794\n","Epoch 118, Train Acc: 0.956771063078959, Val Acc: 0.9464285714285714\n","Epoch 119, Train Acc: 0.9512571680635201, Val Acc: 0.9682539682539683\n","Epoch 120, Train Acc: 0.9486104984561093, Val Acc: 0.9603174603174603\n","Epoch 121, Train Acc: 0.948831054256727, Val Acc: 0.9623015873015873\n","Epoch 122, Train Acc: 0.9468460520511689, Val Acc: 0.9523809523809523\n","Epoch 123, Train Acc: 0.9554477282752536, Val Acc: 0.9543650793650794\n","Epoch 124, Train Acc: 0.9534627260696956, Val Acc: 0.9623015873015873\n","Epoch 125, Train Acc: 0.9528010586678429, Val Acc: 0.9543650793650794\n","Epoch 126, Train Acc: 0.9494927216585797, Val Acc: 0.9623015873015873\n","Epoch 127, Train Acc: 0.957212174680194, Val Acc: 0.9603174603174603\n","Epoch 128, Train Acc: 0.9591971768857521, Val Acc: 0.9523809523809523\n","Epoch 129, Train Acc: 0.9521393912659903, Val Acc: 0.9444444444444444\n","Epoch 130, Train Acc: 0.9475077194530216, Val Acc: 0.9603174603174603\n","Epoch 131, Train Acc: 0.9556682840758712, Val Acc: 0.9702380952380952\n","Epoch 132, Train Acc: 0.9556682840758712, Val Acc: 0.9623015873015873\n","Epoch 133, Train Acc: 0.9532421702690781, Val Acc: 0.9543650793650794\n","Epoch 134, Train Acc: 0.9501543890604323, Val Acc: 0.9662698412698413\n","Epoch 135, Train Acc: 0.9532421702690781, Val Acc: 0.9484126984126984\n","Epoch 136, Train Acc: 0.9483899426554918, Val Acc: 0.9583333333333334\n","Epoch 137, Train Acc: 0.948831054256727, Val Acc: 0.9623015873015873\n","Epoch 138, Train Acc: 0.950816056462285, Val Acc: 0.9523809523809523\n","Epoch 139, Train Acc: 0.9534627260696956, Val Acc: 0.9583333333333334\n","Epoch 140, Train Acc: 0.9516982796647552, Val Acc: 0.9563492063492064\n","Epoch 141, Train Acc: 0.9503749448610499, Val Acc: 0.9583333333333334\n","Epoch 142, Train Acc: 0.9541243934715483, Val Acc: 0.9563492063492064\n","Epoch 143, Train Acc: 0.9459638288486987, Val Acc: 0.9623015873015873\n","Epoch 144, Train Acc: 0.9505955006616674, Val Acc: 0.9682539682539683\n","Epoch 145, Train Acc: 0.948831054256727, Val Acc: 0.9662698412698413\n","Epoch 146, Train Acc: 0.9594177326863697, Val Acc: 0.9563492063492064\n","Epoch 147, Train Acc: 0.9519188354653727, Val Acc: 0.9523809523809523\n","Epoch 148, Train Acc: 0.9583149536832819, Val Acc: 0.9642857142857143\n","Epoch 149, Train Acc: 0.9512571680635201, Val Acc: 0.9603174603174603\n","Epoch 150, Train Acc: 0.9596382884869872, Val Acc: 0.9642857142857143\n","Epoch 151, Train Acc: 0.9470666078517865, Val Acc: 0.9702380952380952\n","Epoch 152, Train Acc: 0.9583149536832819, Val Acc: 0.9642857142857143\n","Epoch 153, Train Acc: 0.9602999558888399, Val Acc: 0.9662698412698413\n","Epoch 154, Train Acc: 0.9532421702690781, Val Acc: 0.9543650793650794\n","Epoch 155, Train Acc: 0.9554477282752536, Val Acc: 0.9603174603174603\n","Epoch 156, Train Acc: 0.943317159241288, Val Acc: 0.9543650793650794\n","Epoch 157, Train Acc: 0.9574327304808117, Val Acc: 0.9642857142857143\n","Epoch 158, Train Acc: 0.9614027348919276, Val Acc: 0.9682539682539683\n","Epoch 159, Train Acc: 0.954786060873401, Val Acc: 0.9583333333333334\n","Epoch 160, Train Acc: 0.950816056462285, Val Acc: 0.9623015873015873\n","Epoch 161, Train Acc: 0.9448610498456109, Val Acc: 0.9543650793650794\n","Epoch 162, Train Acc: 0.9514777238641376, Val Acc: 0.9484126984126984\n","Epoch 163, Train Acc: 0.9483899426554918, Val Acc: 0.9583333333333334\n","Epoch 164, Train Acc: 0.9510366122629025, Val Acc: 0.9563492063492064\n","Epoch 165, Train Acc: 0.9539038376709308, Val Acc: 0.9603174603174603\n","Epoch 166, Train Acc: 0.9580943978826643, Val Acc: 0.9603174603174603\n","Epoch 167, Train Acc: 0.9528010586678429, Val Acc: 0.9623015873015873\n","Epoch 168, Train Acc: 0.9576532862814292, Val Acc: 0.9623015873015873\n","Epoch 169, Train Acc: 0.958756065284517, Val Acc: 0.9642857142857143\n","Epoch 170, Train Acc: 0.9530216144684606, Val Acc: 0.9603174603174603\n","Epoch 171, Train Acc: 0.9598588442876048, Val Acc: 0.9623015873015873\n","Epoch 172, Train Acc: 0.9505955006616674, Val Acc: 0.9603174603174603\n","Epoch 173, Train Acc: 0.9598588442876048, Val Acc: 0.9583333333333334\n","Epoch 174, Train Acc: 0.950816056462285, Val Acc: 0.9523809523809523\n","Epoch 175, Train Acc: 0.9521393912659903, Val Acc: 0.9523809523809523\n","Epoch 176, Train Acc: 0.9468460520511689, Val Acc: 0.9702380952380952\n","Epoch 177, Train Acc: 0.9605205116894574, Val Acc: 0.9682539682539683\n","Epoch 178, Train Acc: 0.9622849580943978, Val Acc: 0.9682539682539683\n","Epoch 179, Train Acc: 0.9585355094838994, Val Acc: 0.9682539682539683\n","Epoch 180, Train Acc: 0.9616232906925453, Val Acc: 0.9742063492063492\n","Epoch 181, Train Acc: 0.9638288486987208, Val Acc: 0.9702380952380952\n","Epoch 182, Train Acc: 0.9629466254962505, Val Acc: 0.9642857142857143\n","Epoch 183, Train Acc: 0.9552271724746361, Val Acc: 0.9801587301587301\n","Epoch 184, Train Acc: 0.9541243934715483, Val Acc: 0.9722222222222222\n","Epoch 185, Train Acc: 0.9583149536832819, Val Acc: 0.9702380952380952\n","Epoch 186, Train Acc: 0.9563299514777238, Val Acc: 0.9563492063492064\n","Epoch 187, Train Acc: 0.9505955006616674, Val Acc: 0.9682539682539683\n","Epoch 188, Train Acc: 0.949272165857962, Val Acc: 0.9742063492063492\n","Epoch 189, Train Acc: 0.9503749448610499, Val Acc: 0.9583333333333334\n","Epoch 190, Train Acc: 0.9523599470666079, Val Acc: 0.9484126984126984\n","Epoch 191, Train Acc: 0.9545655050727834, Val Acc: 0.9484126984126984\n","Epoch 192, Train Acc: 0.9574327304808117, Val Acc: 0.9662698412698413\n","Epoch 193, Train Acc: 0.9541243934715483, Val Acc: 0.9543650793650794\n","Epoch 194, Train Acc: 0.9528010586678429, Val Acc: 0.9603174603174603\n","Epoch 195, Train Acc: 0.950816056462285, Val Acc: 0.9583333333333334\n","Epoch 196, Train Acc: 0.957212174680194, Val Acc: 0.9682539682539683\n","Epoch 197, Train Acc: 0.9591971768857521, Val Acc: 0.9642857142857143\n","Epoch 198, Train Acc: 0.9497132774591972, Val Acc: 0.9603174603174603\n","Epoch 199, Train Acc: 0.9556682840758712, Val Acc: 0.9503968253968254\n","Epoch 200, Train Acc: 0.9556682840758712, Val Acc: 0.9623015873015873\n","Epoch 201, Train Acc: 0.9528010586678429, Val Acc: 0.9642857142857143\n","Epoch 202, Train Acc: 0.9505955006616674, Val Acc: 0.9603174603174603\n","Epoch 203, Train Acc: 0.960741067490075, Val Acc: 0.9682539682539683\n","Epoch 204, Train Acc: 0.9594177326863697, Val Acc: 0.9603174603174603\n","Epoch 205, Train Acc: 0.9616232906925453, Val Acc: 0.9642857142857143\n","Epoch 206, Train Acc: 0.9638288486987208, Val Acc: 0.9603174603174603\n","Epoch 207, Train Acc: 0.9576532862814292, Val Acc: 0.9603174603174603\n","Epoch 208, Train Acc: 0.956771063078959, Val Acc: 0.9603174603174603\n","Epoch 209, Train Acc: 0.9591971768857521, Val Acc: 0.9722222222222222\n","Epoch 210, Train Acc: 0.962726069695633, Val Acc: 0.9523809523809523\n","Epoch 211, Train Acc: 0.9543449492721658, Val Acc: 0.9623015873015873\n","Epoch 212, Train Acc: 0.9521393912659903, Val Acc: 0.9662698412698413\n","Epoch 213, Train Acc: 0.9499338332598147, Val Acc: 0.9583333333333334\n","Epoch 214, Train Acc: 0.9525805028672254, Val Acc: 0.9662698412698413\n","Epoch 215, Train Acc: 0.9596382884869872, Val Acc: 0.9662698412698413\n","Epoch 216, Train Acc: 0.9565505072783415, Val Acc: 0.9642857142857143\n","Epoch 217, Train Acc: 0.9614027348919276, Val Acc: 0.9623015873015873\n","Epoch 218, Train Acc: 0.9545655050727834, Val Acc: 0.9424603174603174\n","Epoch 219, Train Acc: 0.9514777238641376, Val Acc: 0.9642857142857143\n","Epoch 220, Train Acc: 0.9589766210851345, Val Acc: 0.9702380952380952\n","Epoch 221, Train Acc: 0.957212174680194, Val Acc: 0.9603174603174603\n","Epoch 222, Train Acc: 0.9569916188795765, Val Acc: 0.9583333333333334\n","Epoch 223, Train Acc: 0.9585355094838994, Val Acc: 0.9742063492063492\n","Epoch 224, Train Acc: 0.9534627260696956, Val Acc: 0.9563492063492064\n","Epoch 225, Train Acc: 0.9512571680635201, Val Acc: 0.9603174603174603\n","Epoch 226, Train Acc: 0.958756065284517, Val Acc: 0.9722222222222222\n","Epoch 227, Train Acc: 0.9596382884869872, Val Acc: 0.9682539682539683\n","Epoch 228, Train Acc: 0.957212174680194, Val Acc: 0.9603174603174603\n","Epoch 229, Train Acc: 0.957212174680194, Val Acc: 0.9603174603174603\n","Epoch 230, Train Acc: 0.9574327304808117, Val Acc: 0.9642857142857143\n","Epoch 231, Train Acc: 0.9611821790913101, Val Acc: 0.9583333333333334\n","Epoch 232, Train Acc: 0.9525805028672254, Val Acc: 0.9523809523809523\n","Epoch 233, Train Acc: 0.9591971768857521, Val Acc: 0.9662698412698413\n","Epoch 234, Train Acc: 0.9525805028672254, Val Acc: 0.9444444444444444\n","Epoch 235, Train Acc: 0.956771063078959, Val Acc: 0.9523809523809523\n","Epoch 236, Train Acc: 0.949272165857962, Val Acc: 0.9563492063492064\n","Epoch 237, Train Acc: 0.9561093956771063, Val Acc: 0.9543650793650794\n","Epoch 238, Train Acc: 0.9561093956771063, Val Acc: 0.9603174603174603\n","Epoch 239, Train Acc: 0.9539038376709308, Val Acc: 0.9603174603174603\n","Epoch 240, Train Acc: 0.9585355094838994, Val Acc: 0.9523809523809523\n","Epoch 241, Train Acc: 0.958756065284517, Val Acc: 0.9662698412698413\n","Epoch 242, Train Acc: 0.9574327304808117, Val Acc: 0.9523809523809523\n","Epoch 243, Train Acc: 0.9616232906925453, Val Acc: 0.9583333333333334\n","Epoch 244, Train Acc: 0.956771063078959, Val Acc: 0.9662698412698413\n","Epoch 245, Train Acc: 0.9536832818703131, Val Acc: 0.9642857142857143\n","Epoch 246, Train Acc: 0.957212174680194, Val Acc: 0.9623015873015873\n","Epoch 247, Train Acc: 0.9580943978826643, Val Acc: 0.9682539682539683\n","Epoch 248, Train Acc: 0.9539038376709308, Val Acc: 0.9603174603174603\n","Epoch 249, Train Acc: 0.9605205116894574, Val Acc: 0.9702380952380952\n","Best Training Accuracy for Fold 1: 0.9552271724746361\n","Best Validation Accuracy for Fold 1: 0.9801587301587301\n","Classification Report for Fold 1:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.96      0.97       262\n","           1       0.96      0.98      0.97       242\n","\n","    accuracy                           0.97       504\n","   macro avg       0.97      0.97      0.97       504\n","weighted avg       0.97      0.97      0.97       504\n","\n","Fold 2\n","Epoch 0, Train Acc: 0.6387295985884429, Val Acc: 0.7083333333333334\n","Epoch 1, Train Acc: 0.7042346713718571, Val Acc: 0.7341269841269841\n","Epoch 2, Train Acc: 0.7273930304367004, Val Acc: 0.746031746031746\n","Epoch 3, Train Acc: 0.7355535950595501, Val Acc: 0.7341269841269841\n","Epoch 4, Train Acc: 0.7518747243052493, Val Acc: 0.7559523809523809\n","Epoch 5, Train Acc: 0.7739303043670048, Val Acc: 0.7797619047619048\n","Epoch 6, Train Acc: 0.7818703131892368, Val Acc: 0.7857142857142857\n","Epoch 7, Train Acc: 0.7858403176003529, Val Acc: 0.7777777777777778\n","Epoch 8, Train Acc: 0.7942214380238201, Val Acc: 0.7857142857142857\n","Epoch 9, Train Acc: 0.8114247904719895, Val Acc: 0.8055555555555556\n","Epoch 10, Train Acc: 0.8290692545213939, Val Acc: 0.8253968253968254\n","Epoch 11, Train Acc: 0.8387737097485664, Val Acc: 0.8055555555555556\n","Epoch 12, Train Acc: 0.8292898103220114, Val Acc: 0.8214285714285714\n","Epoch 13, Train Acc: 0.8442876047640053, Val Acc: 0.8293650793650794\n","Epoch 14, Train Acc: 0.8491398323775915, Val Acc: 0.8293650793650794\n","Epoch 15, Train Acc: 0.8570798411998235, Val Acc: 0.8313492063492064\n","Epoch 16, Train Acc: 0.8663431848257609, Val Acc: 0.8452380952380952\n","Epoch 17, Train Acc: 0.8619320688134098, Val Acc: 0.8373015873015873\n","Epoch 18, Train Acc: 0.8751654168504631, Val Acc: 0.8670634920634921\n","Epoch 19, Train Acc: 0.8806793118659021, Val Acc: 0.8551587301587301\n","Epoch 20, Train Acc: 0.8877370974856639, Val Acc: 0.871031746031746\n","Epoch 21, Train Acc: 0.8855315394794883, Val Acc: 0.8611111111111112\n","Epoch 22, Train Acc: 0.8879576532862814, Val Acc: 0.8829365079365079\n","Epoch 23, Train Acc: 0.8906043228936921, Val Acc: 0.8670634920634921\n","Epoch 24, Train Acc: 0.8958976621085134, Val Acc: 0.8908730158730159\n","Epoch 25, Train Acc: 0.8947948831054257, Val Acc: 0.876984126984127\n","Epoch 26, Train Acc: 0.8965593295103661, Val Acc: 0.8948412698412699\n","Epoch 27, Train Acc: 0.8994265549183944, Val Acc: 0.9007936507936508\n","Epoch 28, Train Acc: 0.9053815615350683, Val Acc: 0.8869047619047619\n","Epoch 29, Train Acc: 0.9086898985443317, Val Acc: 0.8968253968253969\n","Epoch 30, Train Acc: 0.9044993383325981, Val Acc: 0.8928571428571429\n","Epoch 31, Train Acc: 0.9091310101455669, Val Acc: 0.9047619047619048\n","Epoch 32, Train Acc: 0.9153065725628584, Val Acc: 0.8948412698412699\n","Epoch 33, Train Acc: 0.9144243493603882, Val Acc: 0.9027777777777778\n","Epoch 34, Train Acc: 0.9131010145566828, Val Acc: 0.8988095238095238\n","Epoch 35, Train Acc: 0.9155271283634759, Val Acc: 0.9007936507936508\n","Epoch 36, Train Acc: 0.9175121305690339, Val Acc: 0.9107142857142857\n","Epoch 37, Train Acc: 0.9142037935597707, Val Acc: 0.8829365079365079\n","Epoch 38, Train Acc: 0.9186149095721218, Val Acc: 0.9107142857142857\n","Epoch 39, Train Acc: 0.9228054697838554, Val Acc: 0.9146825396825397\n","Epoch 40, Train Acc: 0.9223643581826202, Val Acc: 0.9107142857142857\n","Epoch 41, Train Acc: 0.9146449051610057, Val Acc: 0.9285714285714286\n","Epoch 42, Train Acc: 0.9272165857962065, Val Acc: 0.9285714285714286\n","Epoch 43, Train Acc: 0.9272165857962065, Val Acc: 0.9067460317460317\n","Epoch 44, Train Acc: 0.9210410233789149, Val Acc: 0.9186507936507936\n","Epoch 45, Train Acc: 0.9261138067931186, Val Acc: 0.9325396825396826\n","Epoch 46, Train Acc: 0.9296426996029996, Val Acc: 0.9305555555555556\n","Epoch 47, Train Acc: 0.9250110277900309, Val Acc: 0.9206349206349206\n","Epoch 48, Train Acc: 0.9269960299955888, Val Acc: 0.9265873015873016\n","Epoch 49, Train Acc: 0.9217026907807675, Val Acc: 0.9067460317460317\n","Epoch 50, Train Acc: 0.9221438023820027, Val Acc: 0.9285714285714286\n","Epoch 51, Train Acc: 0.9318482576091751, Val Acc: 0.9285714285714286\n","Epoch 52, Train Acc: 0.9318482576091751, Val Acc: 0.9325396825396826\n","Epoch 53, Train Acc: 0.9314071460079401, Val Acc: 0.9384920634920635\n","Epoch 54, Train Acc: 0.9309660344067049, Val Acc: 0.9246031746031746\n","Epoch 55, Train Acc: 0.9336127040141156, Val Acc: 0.9365079365079365\n","Epoch 56, Train Acc: 0.9347154830172033, Val Acc: 0.9265873015873016\n","Epoch 57, Train Acc: 0.9265549183943538, Val Acc: 0.9226190476190477\n","Epoch 58, Train Acc: 0.9239082487869431, Val Acc: 0.9246031746031746\n","Epoch 59, Train Acc: 0.9342743714159683, Val Acc: 0.9226190476190477\n","Epoch 60, Train Acc: 0.9289810322011469, Val Acc: 0.9305555555555556\n","Epoch 61, Train Acc: 0.9265549183943538, Val Acc: 0.9265873015873016\n","Epoch 62, Train Acc: 0.9285399205999118, Val Acc: 0.9404761904761905\n","Epoch 63, Train Acc: 0.9320688134097926, Val Acc: 0.9365079365079365\n","Epoch 64, Train Acc: 0.9322893692104103, Val Acc: 0.9226190476190477\n","Epoch 65, Train Acc: 0.935377150419056, Val Acc: 0.9246031746031746\n","Epoch 66, Train Acc: 0.9329510366122629, Val Acc: 0.9265873015873016\n","Epoch 67, Train Acc: 0.933392148213498, Val Acc: 0.9365079365079365\n","Epoch 68, Train Acc: 0.9355977062196735, Val Acc: 0.9265873015873016\n","Epoch 69, Train Acc: 0.9371415968239964, Val Acc: 0.9007936507936508\n","Epoch 70, Train Acc: 0.9351565946184385, Val Acc: 0.9464285714285714\n","Epoch 71, Train Acc: 0.9417732686369652, Val Acc: 0.9345238095238095\n","Epoch 72, Train Acc: 0.9393471548301721, Val Acc: 0.9345238095238095\n","Epoch 73, Train Acc: 0.9364799294221438, Val Acc: 0.9365079365079365\n","Epoch 74, Train Acc: 0.9404499338332598, Val Acc: 0.9285714285714286\n","Epoch 75, Train Acc: 0.9391265990295545, Val Acc: 0.9285714285714286\n","Epoch 76, Train Acc: 0.9347154830172033, Val Acc: 0.9424603174603174\n","Epoch 77, Train Acc: 0.9243493603881782, Val Acc: 0.9186507936507936\n","Epoch 78, Train Acc: 0.9311865902073224, Val Acc: 0.9325396825396826\n","Epoch 79, Train Acc: 0.9280988089986767, Val Acc: 0.9246031746031746\n","Epoch 80, Train Acc: 0.929422143802382, Val Acc: 0.9503968253968254\n","Epoch 81, Train Acc: 0.9371415968239964, Val Acc: 0.9265873015873016\n","Epoch 82, Train Acc: 0.9481693868548743, Val Acc: 0.9325396825396826\n","Epoch 83, Train Acc: 0.9435377150419056, Val Acc: 0.9384920634920635\n","Epoch 84, Train Acc: 0.94133215703573, Val Acc: 0.9305555555555556\n","Epoch 85, Train Acc: 0.943317159241288, Val Acc: 0.9345238095238095\n","Epoch 86, Train Acc: 0.9424349360388178, Val Acc: 0.9464285714285714\n","Epoch 87, Train Acc: 0.9417732686369652, Val Acc: 0.9424603174603174\n","Epoch 88, Train Acc: 0.9404499338332598, Val Acc: 0.9226190476190477\n","Epoch 89, Train Acc: 0.9494927216585797, Val Acc: 0.9444444444444444\n","Epoch 90, Train Acc: 0.9384649316277018, Val Acc: 0.9345238095238095\n","Epoch 91, Train Acc: 0.9287604764005294, Val Acc: 0.9345238095238095\n","Epoch 92, Train Acc: 0.9448610498456109, Val Acc: 0.9325396825396826\n","Epoch 93, Train Acc: 0.9446404940449934, Val Acc: 0.9206349206349206\n","Epoch 94, Train Acc: 0.933392148213498, Val Acc: 0.9146825396825397\n","Epoch 95, Train Acc: 0.9404499338332598, Val Acc: 0.9365079365079365\n","Epoch 96, Train Acc: 0.9325099250110278, Val Acc: 0.9265873015873016\n","Epoch 97, Train Acc: 0.9375827084252316, Val Acc: 0.9265873015873016\n","Epoch 98, Train Acc: 0.94133215703573, Val Acc: 0.9325396825396826\n","Epoch 99, Train Acc: 0.9430966034406705, Val Acc: 0.9404761904761905\n","Epoch 100, Train Acc: 0.9424349360388178, Val Acc: 0.9365079365079365\n","Epoch 101, Train Acc: 0.9521393912659903, Val Acc: 0.9285714285714286\n","Epoch 102, Train Acc: 0.9528010586678429, Val Acc: 0.9384920634920635\n","Epoch 103, Train Acc: 0.9483899426554918, Val Acc: 0.9384920634920635\n","Epoch 104, Train Acc: 0.9486104984561093, Val Acc: 0.9404761904761905\n","Epoch 105, Train Acc: 0.9461843846493163, Val Acc: 0.9246031746031746\n","Epoch 106, Train Acc: 0.9446404940449934, Val Acc: 0.9265873015873016\n","Epoch 107, Train Acc: 0.9424349360388178, Val Acc: 0.9384920634920635\n","Epoch 108, Train Acc: 0.9402293780326423, Val Acc: 0.9345238095238095\n","Epoch 109, Train Acc: 0.9411116012351125, Val Acc: 0.9365079365079365\n","Epoch 110, Train Acc: 0.9415527128363476, Val Acc: 0.9503968253968254\n","Epoch 111, Train Acc: 0.9411116012351125, Val Acc: 0.9424603174603174\n","Epoch 112, Train Acc: 0.9402293780326423, Val Acc: 0.9345238095238095\n","Epoch 113, Train Acc: 0.942876047640053, Val Acc: 0.9246031746031746\n","Epoch 114, Train Acc: 0.9406704896338773, Val Acc: 0.9345238095238095\n","Epoch 115, Train Acc: 0.9435377150419056, Val Acc: 0.9305555555555556\n","Epoch 116, Train Acc: 0.9455227172474636, Val Acc: 0.9345238095238095\n","Epoch 117, Train Acc: 0.9369210410233789, Val Acc: 0.9365079365079365\n","Epoch 118, Train Acc: 0.9439788266431407, Val Acc: 0.9285714285714286\n","Epoch 119, Train Acc: 0.9415527128363476, Val Acc: 0.9186507936507936\n","Epoch 120, Train Acc: 0.9404499338332598, Val Acc: 0.9384920634920635\n","Epoch 121, Train Acc: 0.9446404940449934, Val Acc: 0.9444444444444444\n","Epoch 122, Train Acc: 0.9444199382443759, Val Acc: 0.9325396825396826\n","Epoch 123, Train Acc: 0.9461843846493163, Val Acc: 0.9365079365079365\n","Epoch 124, Train Acc: 0.9441993824437582, Val Acc: 0.9325396825396826\n","Epoch 125, Train Acc: 0.9477282752536391, Val Acc: 0.9365079365079365\n","Epoch 126, Train Acc: 0.9501543890604323, Val Acc: 0.9503968253968254\n","Epoch 127, Train Acc: 0.9453021614468461, Val Acc: 0.9345238095238095\n","Epoch 128, Train Acc: 0.948831054256727, Val Acc: 0.9424603174603174\n","Epoch 129, Train Acc: 0.9459638288486987, Val Acc: 0.9404761904761905\n","Epoch 130, Train Acc: 0.9441993824437582, Val Acc: 0.9384920634920635\n","Epoch 131, Train Acc: 0.9411116012351125, Val Acc: 0.9305555555555556\n","Epoch 132, Train Acc: 0.9453021614468461, Val Acc: 0.9285714285714286\n","Epoch 133, Train Acc: 0.9468460520511689, Val Acc: 0.9365079365079365\n","Epoch 134, Train Acc: 0.9481693868548743, Val Acc: 0.9365079365079365\n","Epoch 135, Train Acc: 0.9505955006616674, Val Acc: 0.9186507936507936\n","Epoch 136, Train Acc: 0.94133215703573, Val Acc: 0.9404761904761905\n","Epoch 137, Train Acc: 0.949272165857962, Val Acc: 0.9384920634920635\n","Epoch 138, Train Acc: 0.9461843846493163, Val Acc: 0.9384920634920635\n","Epoch 139, Train Acc: 0.9512571680635201, Val Acc: 0.9365079365079365\n","Epoch 140, Train Acc: 0.9468460520511689, Val Acc: 0.9444444444444444\n","Epoch 141, Train Acc: 0.949272165857962, Val Acc: 0.9404761904761905\n","Epoch 142, Train Acc: 0.9457432730480811, Val Acc: 0.9345238095238095\n","Epoch 143, Train Acc: 0.950816056462285, Val Acc: 0.9246031746031746\n","Epoch 144, Train Acc: 0.9424349360388178, Val Acc: 0.9305555555555556\n","Epoch 145, Train Acc: 0.9472871636524041, Val Acc: 0.9345238095238095\n","Epoch 146, Train Acc: 0.9455227172474636, Val Acc: 0.9325396825396826\n","Epoch 147, Train Acc: 0.9457432730480811, Val Acc: 0.9246031746031746\n","Epoch 148, Train Acc: 0.9516982796647552, Val Acc: 0.9325396825396826\n","Epoch 149, Train Acc: 0.9461843846493163, Val Acc: 0.9424603174603174\n","Epoch 150, Train Acc: 0.9459638288486987, Val Acc: 0.9246031746031746\n","Epoch 151, Train Acc: 0.9470666078517865, Val Acc: 0.9424603174603174\n","Epoch 152, Train Acc: 0.9475077194530216, Val Acc: 0.9523809523809523\n","Epoch 153, Train Acc: 0.9523599470666079, Val Acc: 0.9384920634920635\n","Epoch 154, Train Acc: 0.9523599470666079, Val Acc: 0.9285714285714286\n","Epoch 155, Train Acc: 0.9505955006616674, Val Acc: 0.9404761904761905\n","Epoch 156, Train Acc: 0.9475077194530216, Val Acc: 0.9107142857142857\n","Epoch 157, Train Acc: 0.9444199382443759, Val Acc: 0.9325396825396826\n","Epoch 158, Train Acc: 0.9470666078517865, Val Acc: 0.9384920634920635\n","Epoch 159, Train Acc: 0.9580943978826643, Val Acc: 0.9305555555555556\n","Epoch 160, Train Acc: 0.9558888398764888, Val Acc: 0.9285714285714286\n","Epoch 161, Train Acc: 0.9530216144684606, Val Acc: 0.9325396825396826\n","Epoch 162, Train Acc: 0.9486104984561093, Val Acc: 0.9365079365079365\n","Epoch 163, Train Acc: 0.9464049404499338, Val Acc: 0.9206349206349206\n","Epoch 164, Train Acc: 0.9453021614468461, Val Acc: 0.9265873015873016\n","Epoch 165, Train Acc: 0.9422143802382003, Val Acc: 0.9345238095238095\n","Epoch 166, Train Acc: 0.9475077194530216, Val Acc: 0.9384920634920635\n","Epoch 167, Train Acc: 0.9536832818703131, Val Acc: 0.9325396825396826\n","Epoch 168, Train Acc: 0.942876047640053, Val Acc: 0.9365079365079365\n","Epoch 169, Train Acc: 0.9514777238641376, Val Acc: 0.9325396825396826\n","Epoch 170, Train Acc: 0.9494927216585797, Val Acc: 0.9404761904761905\n","Epoch 171, Train Acc: 0.950816056462285, Val Acc: 0.9404761904761905\n","Epoch 172, Train Acc: 0.950816056462285, Val Acc: 0.9384920634920635\n","Epoch 173, Train Acc: 0.9419938244375827, Val Acc: 0.9345238095238095\n","Epoch 174, Train Acc: 0.9497132774591972, Val Acc: 0.9305555555555556\n","Epoch 175, Train Acc: 0.9523599470666079, Val Acc: 0.9285714285714286\n","Epoch 176, Train Acc: 0.9532421702690781, Val Acc: 0.9325396825396826\n","Epoch 177, Train Acc: 0.9543449492721658, Val Acc: 0.9345238095238095\n","Epoch 178, Train Acc: 0.9545655050727834, Val Acc: 0.9404761904761905\n","Epoch 179, Train Acc: 0.948831054256727, Val Acc: 0.9226190476190477\n","Epoch 180, Train Acc: 0.9497132774591972, Val Acc: 0.9384920634920635\n","Epoch 181, Train Acc: 0.9536832818703131, Val Acc: 0.9424603174603174\n","Epoch 182, Train Acc: 0.9490516100573445, Val Acc: 0.9265873015873016\n","Epoch 183, Train Acc: 0.9516982796647552, Val Acc: 0.9365079365079365\n","Epoch 184, Train Acc: 0.9426554918394354, Val Acc: 0.9345238095238095\n","Epoch 185, Train Acc: 0.9441993824437582, Val Acc: 0.9305555555555556\n","Epoch 186, Train Acc: 0.9528010586678429, Val Acc: 0.9325396825396826\n","Epoch 187, Train Acc: 0.9543449492721658, Val Acc: 0.9464285714285714\n","Epoch 188, Train Acc: 0.9422143802382003, Val Acc: 0.9404761904761905\n","Epoch 189, Train Acc: 0.9510366122629025, Val Acc: 0.9404761904761905\n","Epoch 190, Train Acc: 0.9516982796647552, Val Acc: 0.9345238095238095\n","Epoch 191, Train Acc: 0.9461843846493163, Val Acc: 0.9484126984126984\n","Epoch 192, Train Acc: 0.9521393912659903, Val Acc: 0.9265873015873016\n","Epoch 193, Train Acc: 0.9472871636524041, Val Acc: 0.9305555555555556\n","Epoch 194, Train Acc: 0.9494927216585797, Val Acc: 0.9503968253968254\n","Epoch 195, Train Acc: 0.9497132774591972, Val Acc: 0.9305555555555556\n","Epoch 196, Train Acc: 0.9477282752536391, Val Acc: 0.9484126984126984\n","Epoch 197, Train Acc: 0.9483899426554918, Val Acc: 0.9365079365079365\n","Epoch 198, Train Acc: 0.9483899426554918, Val Acc: 0.9265873015873016\n","Epoch 199, Train Acc: 0.9360388178209087, Val Acc: 0.9265873015873016\n","Epoch 200, Train Acc: 0.9499338332598147, Val Acc: 0.9325396825396826\n","Epoch 201, Train Acc: 0.9497132774591972, Val Acc: 0.9404761904761905\n","Epoch 202, Train Acc: 0.9552271724746361, Val Acc: 0.9265873015873016\n","Epoch 203, Train Acc: 0.9530216144684606, Val Acc: 0.9384920634920635\n","Epoch 204, Train Acc: 0.9543449492721658, Val Acc: 0.9384920634920635\n","Epoch 205, Train Acc: 0.9503749448610499, Val Acc: 0.9285714285714286\n","Epoch 206, Train Acc: 0.9519188354653727, Val Acc: 0.9444444444444444\n","Epoch 207, Train Acc: 0.9530216144684606, Val Acc: 0.9404761904761905\n","Epoch 208, Train Acc: 0.9450816056462285, Val Acc: 0.9484126984126984\n","Epoch 209, Train Acc: 0.9510366122629025, Val Acc: 0.9444444444444444\n","Epoch 210, Train Acc: 0.9464049404499338, Val Acc: 0.9444444444444444\n","Epoch 211, Train Acc: 0.9479488310542568, Val Acc: 0.9384920634920635\n","Epoch 212, Train Acc: 0.9461843846493163, Val Acc: 0.9424603174603174\n","Epoch 213, Train Acc: 0.948831054256727, Val Acc: 0.9325396825396826\n","Epoch 214, Train Acc: 0.954786060873401, Val Acc: 0.9503968253968254\n","Epoch 215, Train Acc: 0.9554477282752536, Val Acc: 0.9365079365079365\n","Epoch 216, Train Acc: 0.9528010586678429, Val Acc: 0.9404761904761905\n","Epoch 217, Train Acc: 0.9525805028672254, Val Acc: 0.9444444444444444\n","Epoch 218, Train Acc: 0.9424349360388178, Val Acc: 0.9404761904761905\n","Epoch 219, Train Acc: 0.9470666078517865, Val Acc: 0.9206349206349206\n","Epoch 220, Train Acc: 0.9563299514777238, Val Acc: 0.9484126984126984\n","Epoch 221, Train Acc: 0.9448610498456109, Val Acc: 0.9404761904761905\n","Epoch 222, Train Acc: 0.9561093956771063, Val Acc: 0.9345238095238095\n","Epoch 223, Train Acc: 0.9514777238641376, Val Acc: 0.9345238095238095\n","Epoch 224, Train Acc: 0.9481693868548743, Val Acc: 0.9365079365079365\n","Epoch 225, Train Acc: 0.9501543890604323, Val Acc: 0.9444444444444444\n","Epoch 226, Train Acc: 0.9530216144684606, Val Acc: 0.9265873015873016\n","Epoch 227, Train Acc: 0.9521393912659903, Val Acc: 0.9384920634920635\n","Epoch 228, Train Acc: 0.9503749448610499, Val Acc: 0.9305555555555556\n","Epoch 229, Train Acc: 0.9574327304808117, Val Acc: 0.9424603174603174\n","Epoch 230, Train Acc: 0.9501543890604323, Val Acc: 0.9345238095238095\n","Epoch 231, Train Acc: 0.9461843846493163, Val Acc: 0.9226190476190477\n","Epoch 232, Train Acc: 0.948831054256727, Val Acc: 0.9345238095238095\n","Epoch 233, Train Acc: 0.9477282752536391, Val Acc: 0.9424603174603174\n","Epoch 234, Train Acc: 0.9541243934715483, Val Acc: 0.9464285714285714\n","Epoch 235, Train Acc: 0.9516982796647552, Val Acc: 0.9384920634920635\n","Epoch 236, Train Acc: 0.9528010586678429, Val Acc: 0.9365079365079365\n","Epoch 237, Train Acc: 0.9525805028672254, Val Acc: 0.9285714285714286\n","Epoch 238, Train Acc: 0.9483899426554918, Val Acc: 0.9305555555555556\n","Epoch 239, Train Acc: 0.948831054256727, Val Acc: 0.9404761904761905\n","Epoch 240, Train Acc: 0.9543449492721658, Val Acc: 0.9365079365079365\n","Epoch 241, Train Acc: 0.9494927216585797, Val Acc: 0.9365079365079365\n","Epoch 242, Train Acc: 0.9521393912659903, Val Acc: 0.9444444444444444\n","Epoch 243, Train Acc: 0.9530216144684606, Val Acc: 0.9325396825396826\n","Epoch 244, Train Acc: 0.9472871636524041, Val Acc: 0.9345238095238095\n","Epoch 245, Train Acc: 0.948831054256727, Val Acc: 0.9424603174603174\n","Epoch 246, Train Acc: 0.9419938244375827, Val Acc: 0.9285714285714286\n","Epoch 247, Train Acc: 0.9516982796647552, Val Acc: 0.9246031746031746\n","Epoch 248, Train Acc: 0.9552271724746361, Val Acc: 0.9384920634920635\n","Epoch 249, Train Acc: 0.9625055138950155, Val Acc: 0.9345238095238095\n","Best Training Accuracy for Fold 2: 0.9475077194530216\n","Best Validation Accuracy for Fold 2: 0.9523809523809523\n","Classification Report for Fold 2:\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.94      0.93       242\n","           1       0.94      0.93      0.94       262\n","\n","    accuracy                           0.93       504\n","   macro avg       0.93      0.93      0.93       504\n","weighted avg       0.93      0.93      0.93       504\n","\n","Fold 3\n","Epoch 0, Train Acc: 0.6488751654168504, Val Acc: 0.7123015873015873\n","Epoch 1, Train Acc: 0.7152624614027349, Val Acc: 0.7321428571428571\n","Epoch 2, Train Acc: 0.7346713718570799, Val Acc: 0.7361111111111112\n","Epoch 3, Train Acc: 0.7538597265108072, Val Acc: 0.7638888888888888\n","Epoch 4, Train Acc: 0.7565063961182179, Val Acc: 0.7638888888888888\n","Epoch 5, Train Acc: 0.7739303043670048, Val Acc: 0.7738095238095238\n","Epoch 6, Train Acc: 0.7924569916188796, Val Acc: 0.7777777777777778\n","Epoch 7, Train Acc: 0.7986325540361712, Val Acc: 0.8095238095238095\n","Epoch 8, Train Acc: 0.8063520070577856, Val Acc: 0.8373015873015873\n","Epoch 9, Train Acc: 0.8153947948831054, Val Acc: 0.8154761904761905\n","Epoch 10, Train Acc: 0.8220114689016321, Val Acc: 0.8392857142857143\n","Epoch 11, Train Acc: 0.8259814733127481, Val Acc: 0.8412698412698413\n","Epoch 12, Train Acc: 0.8411998235553595, Val Acc: 0.8452380952380952\n","Epoch 13, Train Acc: 0.8462726069695633, Val Acc: 0.8472222222222222\n","Epoch 14, Train Acc: 0.8500220555800617, Val Acc: 0.8531746031746031\n","Epoch 15, Train Acc: 0.86281429201588, Val Acc: 0.8591269841269841\n","Epoch 16, Train Acc: 0.8681076312307013, Val Acc: 0.8690476190476191\n","Epoch 17, Train Acc: 0.8636965152183502, Val Acc: 0.876984126984127\n","Epoch 18, Train Acc: 0.8709748566387296, Val Acc: 0.878968253968254\n","Epoch 19, Train Acc: 0.8756065284516983, Val Acc: 0.875\n","Epoch 20, Train Acc: 0.8804587560652846, Val Acc: 0.8670634920634921\n","Epoch 21, Train Acc: 0.8877370974856639, Val Acc: 0.876984126984127\n","Epoch 22, Train Acc: 0.8828848698720776, Val Acc: 0.8968253968253969\n","Epoch 23, Train Acc: 0.884649316277018, Val Acc: 0.8968253968253969\n","Epoch 24, Train Acc: 0.8892809880899868, Val Acc: 0.8948412698412699\n","Epoch 25, Train Acc: 0.8998676665196295, Val Acc: 0.8869047619047619\n","Epoch 26, Train Acc: 0.905602117335686, Val Acc: 0.9007936507936508\n","Epoch 27, Train Acc: 0.9022937803264226, Val Acc: 0.8988095238095238\n","Epoch 28, Train Acc: 0.8892809880899868, Val Acc: 0.8968253968253969\n","Epoch 29, Train Acc: 0.898103220114689, Val Acc: 0.8988095238095238\n","Epoch 30, Train Acc: 0.8996471107190119, Val Acc: 0.875\n","Epoch 31, Train Acc: 0.9058226731363035, Val Acc: 0.9047619047619048\n","Epoch 32, Train Acc: 0.9084693427437142, Val Acc: 0.9126984126984127\n","Epoch 33, Train Acc: 0.9025143361270401, Val Acc: 0.9047619047619048\n","Epoch 34, Train Acc: 0.9142037935597707, Val Acc: 0.9007936507936508\n","Epoch 35, Train Acc: 0.9104543449492721, Val Acc: 0.8968253968253969\n","Epoch 36, Train Acc: 0.9093515659461844, Val Acc: 0.8928571428571429\n","Epoch 37, Train Acc: 0.919938244375827, Val Acc: 0.9087301587301587\n","Epoch 38, Train Acc: 0.9197176885752095, Val Acc: 0.9246031746031746\n","Epoch 39, Train Acc: 0.9243493603881782, Val Acc: 0.9265873015873016\n","Epoch 40, Train Acc: 0.913542126157918, Val Acc: 0.9186507936507936\n","Epoch 41, Train Acc: 0.9201588001764447, Val Acc: 0.9186507936507936\n","Epoch 42, Train Acc: 0.9210410233789149, Val Acc: 0.9146825396825397\n","Epoch 43, Train Acc: 0.913542126157918, Val Acc: 0.9126984126984127\n","Epoch 44, Train Acc: 0.9239082487869431, Val Acc: 0.9285714285714286\n","Epoch 45, Train Acc: 0.9225849139832377, Val Acc: 0.9265873015873016\n","Epoch 46, Train Acc: 0.9168504631671813, Val Acc: 0.878968253968254\n","Epoch 47, Train Acc: 0.9261138067931186, Val Acc: 0.9166666666666666\n","Epoch 48, Train Acc: 0.9190560211733568, Val Acc: 0.9206349206349206\n","Epoch 49, Train Acc: 0.9234671371857079, Val Acc: 0.9146825396825397\n","Epoch 50, Train Acc: 0.9161887957653286, Val Acc: 0.9325396825396826\n","Epoch 51, Train Acc: 0.9296426996029996, Val Acc: 0.9384920634920635\n","Epoch 52, Train Acc: 0.9247904719894133, Val Acc: 0.9265873015873016\n","Epoch 53, Train Acc: 0.9245699161887958, Val Acc: 0.9265873015873016\n","Epoch 54, Train Acc: 0.9228054697838554, Val Acc: 0.9305555555555556\n","Epoch 55, Train Acc: 0.9307454786060874, Val Acc: 0.9325396825396826\n","Epoch 56, Train Acc: 0.9201588001764447, Val Acc: 0.9305555555555556\n","Epoch 57, Train Acc: 0.9280988089986767, Val Acc: 0.9166666666666666\n","Epoch 58, Train Acc: 0.9148654609616232, Val Acc: 0.9126984126984127\n","Epoch 59, Train Acc: 0.9298632554036171, Val Acc: 0.9206349206349206\n","Epoch 60, Train Acc: 0.9307454786060874, Val Acc: 0.9166666666666666\n","Epoch 61, Train Acc: 0.9205999117776797, Val Acc: 0.9325396825396826\n","Epoch 62, Train Acc: 0.9265549183943538, Val Acc: 0.9384920634920635\n","Epoch 63, Train Acc: 0.9307454786060874, Val Acc: 0.9325396825396826\n","Epoch 64, Train Acc: 0.9338332598147331, Val Acc: 0.9384920634920635\n","Epoch 65, Train Acc: 0.9342743714159683, Val Acc: 0.9325396825396826\n","Epoch 66, Train Acc: 0.9371415968239964, Val Acc: 0.9305555555555556\n","Epoch 67, Train Acc: 0.9303043670048522, Val Acc: 0.9265873015873016\n","Epoch 68, Train Acc: 0.9331715924128805, Val Acc: 0.9246031746031746\n","Epoch 69, Train Acc: 0.9305249228054698, Val Acc: 0.9226190476190477\n","Epoch 70, Train Acc: 0.9369210410233789, Val Acc: 0.9126984126984127\n","Epoch 71, Train Acc: 0.927878253198059, Val Acc: 0.9265873015873016\n","Epoch 72, Train Acc: 0.9316277018085576, Val Acc: 0.9404761904761905\n","Epoch 73, Train Acc: 0.9309660344067049, Val Acc: 0.9404761904761905\n","Epoch 74, Train Acc: 0.9303043670048522, Val Acc: 0.9285714285714286\n","Epoch 75, Train Acc: 0.9358182620202912, Val Acc: 0.9325396825396826\n","Epoch 76, Train Acc: 0.9285399205999118, Val Acc: 0.9365079365079365\n","Epoch 77, Train Acc: 0.937362152624614, Val Acc: 0.9384920634920635\n","Epoch 78, Train Acc: 0.9250110277900309, Val Acc: 0.9345238095238095\n","Epoch 79, Train Acc: 0.9347154830172033, Val Acc: 0.9404761904761905\n","Epoch 80, Train Acc: 0.9316277018085576, Val Acc: 0.9285714285714286\n","Epoch 81, Train Acc: 0.9309660344067049, Val Acc: 0.9285714285714286\n","Epoch 82, Train Acc: 0.9322893692104103, Val Acc: 0.9325396825396826\n","Epoch 83, Train Acc: 0.9316277018085576, Val Acc: 0.9345238095238095\n","Epoch 84, Train Acc: 0.9360388178209087, Val Acc: 0.9305555555555556\n","Epoch 85, Train Acc: 0.9364799294221438, Val Acc: 0.9404761904761905\n","Epoch 86, Train Acc: 0.9455227172474636, Val Acc: 0.9444444444444444\n","Epoch 87, Train Acc: 0.9417732686369652, Val Acc: 0.9444444444444444\n","Epoch 88, Train Acc: 0.9417732686369652, Val Acc: 0.9365079365079365\n","Epoch 89, Train Acc: 0.9358182620202912, Val Acc: 0.9404761904761905\n","Epoch 90, Train Acc: 0.9384649316277018, Val Acc: 0.9384920634920635\n","Epoch 91, Train Acc: 0.9380238200264667, Val Acc: 0.9365079365079365\n","Epoch 92, Train Acc: 0.9263343625937362, Val Acc: 0.9206349206349206\n","Epoch 93, Train Acc: 0.9307454786060874, Val Acc: 0.9464285714285714\n","Epoch 94, Train Acc: 0.9316277018085576, Val Acc: 0.9384920634920635\n","Epoch 95, Train Acc: 0.9391265990295545, Val Acc: 0.9305555555555556\n","Epoch 96, Train Acc: 0.9364799294221438, Val Acc: 0.9424603174603174\n","Epoch 97, Train Acc: 0.9382443758270842, Val Acc: 0.9285714285714286\n","Epoch 98, Train Acc: 0.9364799294221438, Val Acc: 0.9345238095238095\n","Epoch 99, Train Acc: 0.9437582708425232, Val Acc: 0.9444444444444444\n","Epoch 100, Train Acc: 0.9307454786060874, Val Acc: 0.9345238095238095\n","Epoch 101, Train Acc: 0.9338332598147331, Val Acc: 0.9384920634920635\n","Epoch 102, Train Acc: 0.9369210410233789, Val Acc: 0.9325396825396826\n","Epoch 103, Train Acc: 0.9371415968239964, Val Acc: 0.9345238095238095\n","Epoch 104, Train Acc: 0.9367004852227614, Val Acc: 0.9384920634920635\n","Epoch 105, Train Acc: 0.9386854874283194, Val Acc: 0.9404761904761905\n","Epoch 106, Train Acc: 0.9347154830172033, Val Acc: 0.9444444444444444\n","Epoch 107, Train Acc: 0.9371415968239964, Val Acc: 0.9365079365079365\n","Epoch 108, Train Acc: 0.9369210410233789, Val Acc: 0.9325396825396826\n","Epoch 109, Train Acc: 0.9417732686369652, Val Acc: 0.9384920634920635\n","Epoch 110, Train Acc: 0.9384649316277018, Val Acc: 0.9543650793650794\n","Epoch 111, Train Acc: 0.9415527128363476, Val Acc: 0.9365079365079365\n","Epoch 112, Train Acc: 0.9367004852227614, Val Acc: 0.9424603174603174\n","Epoch 113, Train Acc: 0.9446404940449934, Val Acc: 0.9365079365079365\n","Epoch 114, Train Acc: 0.9450816056462285, Val Acc: 0.9424603174603174\n","Epoch 115, Train Acc: 0.9453021614468461, Val Acc: 0.9325396825396826\n","Epoch 116, Train Acc: 0.9389060432289369, Val Acc: 0.9484126984126984\n","Epoch 117, Train Acc: 0.9355977062196735, Val Acc: 0.9484126984126984\n","Epoch 118, Train Acc: 0.943317159241288, Val Acc: 0.9384920634920635\n","Epoch 119, Train Acc: 0.9375827084252316, Val Acc: 0.9464285714285714\n","Epoch 120, Train Acc: 0.9422143802382003, Val Acc: 0.9384920634920635\n","Epoch 121, Train Acc: 0.9419938244375827, Val Acc: 0.9345238095238095\n","Epoch 122, Train Acc: 0.9318482576091751, Val Acc: 0.9503968253968254\n","Epoch 123, Train Acc: 0.9400088222320248, Val Acc: 0.9404761904761905\n","Epoch 124, Train Acc: 0.9395677106307896, Val Acc: 0.9345238095238095\n","Epoch 125, Train Acc: 0.9424349360388178, Val Acc: 0.9404761904761905\n","Epoch 126, Train Acc: 0.9400088222320248, Val Acc: 0.9484126984126984\n","Epoch 127, Train Acc: 0.9389060432289369, Val Acc: 0.9404761904761905\n","Epoch 128, Train Acc: 0.9437582708425232, Val Acc: 0.9444444444444444\n","Epoch 129, Train Acc: 0.9430966034406705, Val Acc: 0.9503968253968254\n","Epoch 130, Train Acc: 0.937362152624614, Val Acc: 0.9484126984126984\n","Epoch 131, Train Acc: 0.943317159241288, Val Acc: 0.9444444444444444\n","Epoch 132, Train Acc: 0.9479488310542568, Val Acc: 0.9404761904761905\n","Epoch 133, Train Acc: 0.9461843846493163, Val Acc: 0.9503968253968254\n","Epoch 134, Train Acc: 0.9441993824437582, Val Acc: 0.9424603174603174\n","Epoch 135, Train Acc: 0.9450816056462285, Val Acc: 0.9523809523809523\n","Epoch 136, Train Acc: 0.940891045434495, Val Acc: 0.9424603174603174\n","Epoch 137, Train Acc: 0.9446404940449934, Val Acc: 0.9444444444444444\n","Epoch 138, Train Acc: 0.9389060432289369, Val Acc: 0.9384920634920635\n","Epoch 139, Train Acc: 0.9417732686369652, Val Acc: 0.9404761904761905\n","Epoch 140, Train Acc: 0.9457432730480811, Val Acc: 0.9583333333333334\n","Epoch 141, Train Acc: 0.942876047640053, Val Acc: 0.9424603174603174\n","Epoch 142, Train Acc: 0.9419938244375827, Val Acc: 0.9384920634920635\n","Epoch 143, Train Acc: 0.9499338332598147, Val Acc: 0.9464285714285714\n","Epoch 144, Train Acc: 0.9395677106307896, Val Acc: 0.9285714285714286\n","Epoch 145, Train Acc: 0.9472871636524041, Val Acc: 0.9464285714285714\n","Epoch 146, Train Acc: 0.9477282752536391, Val Acc: 0.9384920634920635\n","Epoch 147, Train Acc: 0.9430966034406705, Val Acc: 0.9444444444444444\n","Epoch 148, Train Acc: 0.9453021614468461, Val Acc: 0.9464285714285714\n","Epoch 149, Train Acc: 0.9490516100573445, Val Acc: 0.9384920634920635\n","Epoch 150, Train Acc: 0.9450816056462285, Val Acc: 0.9484126984126984\n","Epoch 151, Train Acc: 0.9389060432289369, Val Acc: 0.9484126984126984\n","Epoch 152, Train Acc: 0.9417732686369652, Val Acc: 0.9503968253968254\n","Epoch 153, Train Acc: 0.9371415968239964, Val Acc: 0.9484126984126984\n","Epoch 154, Train Acc: 0.9389060432289369, Val Acc: 0.9484126984126984\n","Epoch 155, Train Acc: 0.9468460520511689, Val Acc: 0.9563492063492064\n","Epoch 156, Train Acc: 0.942876047640053, Val Acc: 0.9444444444444444\n","Epoch 157, Train Acc: 0.9461843846493163, Val Acc: 0.9464285714285714\n","Epoch 158, Train Acc: 0.9437582708425232, Val Acc: 0.9484126984126984\n","Epoch 159, Train Acc: 0.9422143802382003, Val Acc: 0.9384920634920635\n","Epoch 160, Train Acc: 0.9448610498456109, Val Acc: 0.9464285714285714\n","Epoch 161, Train Acc: 0.9466254962505514, Val Acc: 0.9444444444444444\n","Epoch 162, Train Acc: 0.9393471548301721, Val Acc: 0.9444444444444444\n","Epoch 163, Train Acc: 0.9499338332598147, Val Acc: 0.9484126984126984\n","Epoch 164, Train Acc: 0.9422143802382003, Val Acc: 0.9444444444444444\n","Epoch 165, Train Acc: 0.9505955006616674, Val Acc: 0.9464285714285714\n","Epoch 166, Train Acc: 0.9523599470666079, Val Acc: 0.9464285714285714\n","Epoch 167, Train Acc: 0.9461843846493163, Val Acc: 0.9424603174603174\n","Epoch 168, Train Acc: 0.9430966034406705, Val Acc: 0.9503968253968254\n","Epoch 169, Train Acc: 0.9446404940449934, Val Acc: 0.9464285714285714\n","Epoch 170, Train Acc: 0.9426554918394354, Val Acc: 0.9424603174603174\n","Epoch 171, Train Acc: 0.9455227172474636, Val Acc: 0.9424603174603174\n","Epoch 172, Train Acc: 0.9501543890604323, Val Acc: 0.9384920634920635\n","Epoch 173, Train Acc: 0.9391265990295545, Val Acc: 0.9384920634920635\n","Epoch 174, Train Acc: 0.9406704896338773, Val Acc: 0.9305555555555556\n","Epoch 175, Train Acc: 0.9369210410233789, Val Acc: 0.9523809523809523\n","Epoch 176, Train Acc: 0.9464049404499338, Val Acc: 0.9404761904761905\n","Epoch 177, Train Acc: 0.9490516100573445, Val Acc: 0.9424603174603174\n","Epoch 178, Train Acc: 0.9477282752536391, Val Acc: 0.9523809523809523\n","Epoch 179, Train Acc: 0.9461843846493163, Val Acc: 0.9384920634920635\n","Epoch 180, Train Acc: 0.9455227172474636, Val Acc: 0.9503968253968254\n","Epoch 181, Train Acc: 0.9419938244375827, Val Acc: 0.9404761904761905\n","Epoch 182, Train Acc: 0.9455227172474636, Val Acc: 0.9424603174603174\n","Epoch 183, Train Acc: 0.9435377150419056, Val Acc: 0.9503968253968254\n","Epoch 184, Train Acc: 0.9441993824437582, Val Acc: 0.9365079365079365\n","Epoch 185, Train Acc: 0.9448610498456109, Val Acc: 0.9464285714285714\n","Epoch 186, Train Acc: 0.9481693868548743, Val Acc: 0.9424603174603174\n","Epoch 187, Train Acc: 0.9514777238641376, Val Acc: 0.9503968253968254\n","Epoch 188, Train Acc: 0.9461843846493163, Val Acc: 0.9424603174603174\n","Epoch 189, Train Acc: 0.9450816056462285, Val Acc: 0.9503968253968254\n","Epoch 190, Train Acc: 0.9453021614468461, Val Acc: 0.9523809523809523\n","Epoch 191, Train Acc: 0.9441993824437582, Val Acc: 0.9523809523809523\n","Epoch 192, Train Acc: 0.9505955006616674, Val Acc: 0.9444444444444444\n","Epoch 193, Train Acc: 0.9494927216585797, Val Acc: 0.9484126984126984\n","Epoch 194, Train Acc: 0.9501543890604323, Val Acc: 0.9543650793650794\n","Epoch 195, Train Acc: 0.9470666078517865, Val Acc: 0.9503968253968254\n","Epoch 196, Train Acc: 0.9422143802382003, Val Acc: 0.9305555555555556\n","Epoch 197, Train Acc: 0.9479488310542568, Val Acc: 0.9503968253968254\n","Epoch 198, Train Acc: 0.9437582708425232, Val Acc: 0.9503968253968254\n","Epoch 199, Train Acc: 0.9556682840758712, Val Acc: 0.9523809523809523\n","Epoch 200, Train Acc: 0.9528010586678429, Val Acc: 0.9563492063492064\n","Epoch 201, Train Acc: 0.9543449492721658, Val Acc: 0.9523809523809523\n","Epoch 202, Train Acc: 0.9512571680635201, Val Acc: 0.9523809523809523\n","Epoch 203, Train Acc: 0.943317159241288, Val Acc: 0.9404761904761905\n","Epoch 204, Train Acc: 0.9446404940449934, Val Acc: 0.9404761904761905\n","Epoch 205, Train Acc: 0.9391265990295545, Val Acc: 0.9424603174603174\n","Epoch 206, Train Acc: 0.9569916188795765, Val Acc: 0.9503968253968254\n","Epoch 207, Train Acc: 0.9534627260696956, Val Acc: 0.9484126984126984\n","Epoch 208, Train Acc: 0.9475077194530216, Val Acc: 0.9543650793650794\n","Epoch 209, Train Acc: 0.9499338332598147, Val Acc: 0.9543650793650794\n","Epoch 210, Train Acc: 0.9475077194530216, Val Acc: 0.9583333333333334\n","Epoch 211, Train Acc: 0.9479488310542568, Val Acc: 0.9325396825396826\n","Epoch 212, Train Acc: 0.9514777238641376, Val Acc: 0.9543650793650794\n","Epoch 213, Train Acc: 0.9486104984561093, Val Acc: 0.9563492063492064\n","Epoch 214, Train Acc: 0.9503749448610499, Val Acc: 0.9464285714285714\n","Epoch 215, Train Acc: 0.9516982796647552, Val Acc: 0.9444444444444444\n","Epoch 216, Train Acc: 0.9519188354653727, Val Acc: 0.9365079365079365\n","Epoch 217, Train Acc: 0.9510366122629025, Val Acc: 0.9404761904761905\n","Epoch 218, Train Acc: 0.949272165857962, Val Acc: 0.9484126984126984\n","Epoch 219, Train Acc: 0.9523599470666079, Val Acc: 0.9424603174603174\n","Epoch 220, Train Acc: 0.9384649316277018, Val Acc: 0.9464285714285714\n","Epoch 221, Train Acc: 0.9521393912659903, Val Acc: 0.9484126984126984\n","Epoch 222, Train Acc: 0.9512571680635201, Val Acc: 0.9444444444444444\n","Epoch 223, Train Acc: 0.9543449492721658, Val Acc: 0.9503968253968254\n","Epoch 224, Train Acc: 0.9521393912659903, Val Acc: 0.9464285714285714\n","Epoch 225, Train Acc: 0.943317159241288, Val Acc: 0.9523809523809523\n","Epoch 226, Train Acc: 0.9475077194530216, Val Acc: 0.9444444444444444\n","Epoch 227, Train Acc: 0.9516982796647552, Val Acc: 0.9464285714285714\n","Epoch 228, Train Acc: 0.948831054256727, Val Acc: 0.9523809523809523\n","Epoch 229, Train Acc: 0.9475077194530216, Val Acc: 0.9464285714285714\n","Epoch 230, Train Acc: 0.9457432730480811, Val Acc: 0.9523809523809523\n","Epoch 231, Train Acc: 0.9536832818703131, Val Acc: 0.9503968253968254\n","Epoch 232, Train Acc: 0.9514777238641376, Val Acc: 0.9543650793650794\n","Epoch 233, Train Acc: 0.9532421702690781, Val Acc: 0.9404761904761905\n","Epoch 234, Train Acc: 0.9472871636524041, Val Acc: 0.9384920634920635\n","Epoch 235, Train Acc: 0.9397882664314071, Val Acc: 0.9484126984126984\n","Epoch 236, Train Acc: 0.9391265990295545, Val Acc: 0.9365079365079365\n","Epoch 237, Train Acc: 0.9455227172474636, Val Acc: 0.9444444444444444\n","Epoch 238, Train Acc: 0.9441993824437582, Val Acc: 0.9583333333333334\n","Epoch 239, Train Acc: 0.9486104984561093, Val Acc: 0.9464285714285714\n","Epoch 240, Train Acc: 0.9554477282752536, Val Acc: 0.9444444444444444\n","Epoch 241, Train Acc: 0.9499338332598147, Val Acc: 0.9543650793650794\n","Epoch 242, Train Acc: 0.9497132774591972, Val Acc: 0.9523809523809523\n","Epoch 243, Train Acc: 0.9543449492721658, Val Acc: 0.9503968253968254\n","Epoch 244, Train Acc: 0.9494927216585797, Val Acc: 0.9503968253968254\n","Epoch 245, Train Acc: 0.9448610498456109, Val Acc: 0.9603174603174603\n","Epoch 246, Train Acc: 0.9435377150419056, Val Acc: 0.9563492063492064\n","Epoch 247, Train Acc: 0.9561093956771063, Val Acc: 0.9523809523809523\n","Epoch 248, Train Acc: 0.9481693868548743, Val Acc: 0.9464285714285714\n","Epoch 249, Train Acc: 0.9536832818703131, Val Acc: 0.9424603174603174\n","Best Training Accuracy for Fold 3: 0.9448610498456109\n","Best Validation Accuracy for Fold 3: 0.9603174603174603\n","Classification Report for Fold 3:\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.94      0.94       252\n","           1       0.94      0.95      0.94       252\n","\n","    accuracy                           0.94       504\n","   macro avg       0.94      0.94      0.94       504\n","weighted avg       0.94      0.94      0.94       504\n","\n","Fold 4\n","Epoch 0, Train Acc: 0.6422584913983238, Val Acc: 0.7142857142857143\n","Epoch 1, Train Acc: 0.7009263343625938, Val Acc: 0.7242063492063492\n","Epoch 2, Train Acc: 0.7291574768416409, Val Acc: 0.7380952380952381\n","Epoch 3, Train Acc: 0.7494486104984561, Val Acc: 0.75\n","Epoch 4, Train Acc: 0.7644464049404499, Val Acc: 0.7638888888888888\n","Epoch 5, Train Acc: 0.7772386413762682, Val Acc: 0.7857142857142857\n","Epoch 6, Train Acc: 0.7836347595941773, Val Acc: 0.7837301587301587\n","Epoch 7, Train Acc: 0.796206440229378, Val Acc: 0.7916666666666666\n","Epoch 8, Train Acc: 0.8048081164534627, Val Acc: 0.8174603174603174\n","Epoch 9, Train Acc: 0.8178209086898985, Val Acc: 0.8234126984126984\n","Epoch 10, Train Acc: 0.8198059108954565, Val Acc: 0.8095238095238095\n","Epoch 11, Train Acc: 0.8264225849139832, Val Acc: 0.8452380952380952\n","Epoch 12, Train Acc: 0.8365681517423909, Val Acc: 0.8492063492063492\n","Epoch 13, Train Acc: 0.8427437141596824, Val Acc: 0.8313492063492064\n","Epoch 14, Train Acc: 0.8504631671812969, Val Acc: 0.8432539682539683\n","Epoch 15, Train Acc: 0.8584031760035289, Val Acc: 0.8670634920634921\n","Epoch 16, Train Acc: 0.8634759594177327, Val Acc: 0.876984126984127\n","Epoch 17, Train Acc: 0.8709748566387296, Val Acc: 0.871031746031746\n","Epoch 18, Train Acc: 0.8678870754300838, Val Acc: 0.8948412698412699\n","Epoch 19, Train Acc: 0.8692104102337892, Val Acc: 0.8869047619047619\n","Epoch 20, Train Acc: 0.8793559770621967, Val Acc: 0.873015873015873\n","Epoch 21, Train Acc: 0.886193206881341, Val Acc: 0.8690476190476191\n","Epoch 22, Train Acc: 0.8908248786943097, Val Acc: 0.8908730158730159\n","Epoch 23, Train Acc: 0.8992059991177768, Val Acc: 0.9007936507936508\n","Epoch 24, Train Acc: 0.8950154389060432, Val Acc: 0.8888888888888888\n","Epoch 25, Train Acc: 0.8883987648875166, Val Acc: 0.9107142857142857\n","Epoch 26, Train Acc: 0.8963387737097486, Val Acc: 0.9027777777777778\n","Epoch 27, Train Acc: 0.9038376709307455, Val Acc: 0.9166666666666666\n","Epoch 28, Train Acc: 0.906043228936921, Val Acc: 0.9047619047619048\n","Epoch 29, Train Acc: 0.9018526687251874, Val Acc: 0.9087301587301587\n","Epoch 30, Train Acc: 0.9089104543449493, Val Acc: 0.9146825396825397\n","Epoch 31, Train Acc: 0.9075871195412439, Val Acc: 0.8988095238095238\n","Epoch 32, Train Acc: 0.913983237759153, Val Acc: 0.9087301587301587\n","Epoch 33, Train Acc: 0.9197176885752095, Val Acc: 0.9305555555555556\n","Epoch 34, Train Acc: 0.9221438023820027, Val Acc: 0.9226190476190477\n","Epoch 35, Train Acc: 0.9164093515659462, Val Acc: 0.9186507936507936\n","Epoch 36, Train Acc: 0.9155271283634759, Val Acc: 0.9126984126984127\n","Epoch 37, Train Acc: 0.9183943537715042, Val Acc: 0.9305555555555556\n","Epoch 38, Train Acc: 0.9131010145566828, Val Acc: 0.9186507936507936\n","Epoch 39, Train Acc: 0.9153065725628584, Val Acc: 0.9345238095238095\n","Epoch 40, Train Acc: 0.9272165857962065, Val Acc: 0.9206349206349206\n","Epoch 41, Train Acc: 0.9309660344067049, Val Acc: 0.9206349206349206\n","Epoch 42, Train Acc: 0.9232465813850904, Val Acc: 0.9365079365079365\n","Epoch 43, Train Acc: 0.9243493603881782, Val Acc: 0.9265873015873016\n","Epoch 44, Train Acc: 0.9223643581826202, Val Acc: 0.9305555555555556\n","Epoch 45, Train Acc: 0.9325099250110278, Val Acc: 0.9424603174603174\n","Epoch 46, Train Acc: 0.9314071460079401, Val Acc: 0.9325396825396826\n","Epoch 47, Train Acc: 0.9311865902073224, Val Acc: 0.9166666666666666\n","Epoch 48, Train Acc: 0.9311865902073224, Val Acc: 0.9345238095238095\n","Epoch 49, Train Acc: 0.9292015880017644, Val Acc: 0.9365079365079365\n","Epoch 50, Train Acc: 0.927878253198059, Val Acc: 0.9265873015873016\n","Epoch 51, Train Acc: 0.9287604764005294, Val Acc: 0.9305555555555556\n","Epoch 52, Train Acc: 0.9402293780326423, Val Acc: 0.9305555555555556\n","Epoch 53, Train Acc: 0.9400088222320248, Val Acc: 0.9265873015873016\n","Epoch 54, Train Acc: 0.9316277018085576, Val Acc: 0.9345238095238095\n","Epoch 55, Train Acc: 0.9292015880017644, Val Acc: 0.9265873015873016\n","Epoch 56, Train Acc: 0.9263343625937362, Val Acc: 0.9384920634920635\n","Epoch 57, Train Acc: 0.940891045434495, Val Acc: 0.9285714285714286\n","Epoch 58, Train Acc: 0.933392148213498, Val Acc: 0.9365079365079365\n","Epoch 59, Train Acc: 0.9320688134097926, Val Acc: 0.9384920634920635\n","Epoch 60, Train Acc: 0.9362593736215262, Val Acc: 0.9424603174603174\n","Epoch 61, Train Acc: 0.9384649316277018, Val Acc: 0.9365079365079365\n","Epoch 62, Train Acc: 0.9393471548301721, Val Acc: 0.9365079365079365\n","Epoch 63, Train Acc: 0.9389060432289369, Val Acc: 0.9325396825396826\n","Epoch 64, Train Acc: 0.9384649316277018, Val Acc: 0.9424603174603174\n","Epoch 65, Train Acc: 0.9384649316277018, Val Acc: 0.9464285714285714\n","Epoch 66, Train Acc: 0.9397882664314071, Val Acc: 0.9305555555555556\n","Epoch 67, Train Acc: 0.9380238200264667, Val Acc: 0.9365079365079365\n","Epoch 68, Train Acc: 0.9355977062196735, Val Acc: 0.9265873015873016\n","Epoch 69, Train Acc: 0.9378032642258491, Val Acc: 0.9404761904761905\n","Epoch 70, Train Acc: 0.934936038817821, Val Acc: 0.9404761904761905\n","Epoch 71, Train Acc: 0.933392148213498, Val Acc: 0.9226190476190477\n","Epoch 72, Train Acc: 0.935377150419056, Val Acc: 0.9444444444444444\n","Epoch 73, Train Acc: 0.933392148213498, Val Acc: 0.9365079365079365\n","Epoch 74, Train Acc: 0.9446404940449934, Val Acc: 0.9503968253968254\n","Epoch 75, Train Acc: 0.9382443758270842, Val Acc: 0.9404761904761905\n","Epoch 76, Train Acc: 0.9404499338332598, Val Acc: 0.9246031746031746\n","Epoch 77, Train Acc: 0.9426554918394354, Val Acc: 0.9424603174603174\n","Epoch 78, Train Acc: 0.9355977062196735, Val Acc: 0.9325396825396826\n","Epoch 79, Train Acc: 0.9367004852227614, Val Acc: 0.9404761904761905\n","Epoch 80, Train Acc: 0.9466254962505514, Val Acc: 0.9444444444444444\n","Epoch 81, Train Acc: 0.9397882664314071, Val Acc: 0.9146825396825397\n","Epoch 82, Train Acc: 0.9400088222320248, Val Acc: 0.9365079365079365\n","Epoch 83, Train Acc: 0.9435377150419056, Val Acc: 0.9424603174603174\n","Epoch 84, Train Acc: 0.929422143802382, Val Acc: 0.9484126984126984\n","Epoch 85, Train Acc: 0.9362593736215262, Val Acc: 0.9444444444444444\n","Epoch 86, Train Acc: 0.9444199382443759, Val Acc: 0.9365079365079365\n","Epoch 87, Train Acc: 0.9296426996029996, Val Acc: 0.9265873015873016\n","Epoch 88, Train Acc: 0.9402293780326423, Val Acc: 0.9404761904761905\n","Epoch 89, Train Acc: 0.9395677106307896, Val Acc: 0.9384920634920635\n","Epoch 90, Train Acc: 0.9402293780326423, Val Acc: 0.9464285714285714\n","Epoch 91, Train Acc: 0.9435377150419056, Val Acc: 0.9404761904761905\n","Epoch 92, Train Acc: 0.9404499338332598, Val Acc: 0.9404761904761905\n","Epoch 93, Train Acc: 0.9402293780326423, Val Acc: 0.9464285714285714\n","Epoch 94, Train Acc: 0.9411116012351125, Val Acc: 0.9484126984126984\n","Epoch 95, Train Acc: 0.9389060432289369, Val Acc: 0.9484126984126984\n","Epoch 96, Train Acc: 0.94133215703573, Val Acc: 0.9404761904761905\n","Epoch 97, Train Acc: 0.9406704896338773, Val Acc: 0.9484126984126984\n","Epoch 98, Train Acc: 0.9415527128363476, Val Acc: 0.9424603174603174\n","Epoch 99, Train Acc: 0.9435377150419056, Val Acc: 0.9384920634920635\n","Epoch 100, Train Acc: 0.9486104984561093, Val Acc: 0.9365079365079365\n","Epoch 101, Train Acc: 0.9453021614468461, Val Acc: 0.9523809523809523\n","Epoch 102, Train Acc: 0.9486104984561093, Val Acc: 0.9484126984126984\n","Epoch 103, Train Acc: 0.9384649316277018, Val Acc: 0.9503968253968254\n","Epoch 104, Train Acc: 0.9430966034406705, Val Acc: 0.9365079365079365\n","Epoch 105, Train Acc: 0.9395677106307896, Val Acc: 0.9404761904761905\n","Epoch 106, Train Acc: 0.9426554918394354, Val Acc: 0.9543650793650794\n","Epoch 107, Train Acc: 0.9464049404499338, Val Acc: 0.9404761904761905\n","Epoch 108, Train Acc: 0.943317159241288, Val Acc: 0.9444444444444444\n","Epoch 109, Train Acc: 0.9453021614468461, Val Acc: 0.9464285714285714\n","Epoch 110, Train Acc: 0.9435377150419056, Val Acc: 0.9464285714285714\n","Epoch 111, Train Acc: 0.9437582708425232, Val Acc: 0.9523809523809523\n","Epoch 112, Train Acc: 0.9389060432289369, Val Acc: 0.9503968253968254\n","Epoch 113, Train Acc: 0.9441993824437582, Val Acc: 0.9464285714285714\n","Epoch 114, Train Acc: 0.9459638288486987, Val Acc: 0.9424603174603174\n","Epoch 115, Train Acc: 0.9475077194530216, Val Acc: 0.9484126984126984\n","Epoch 116, Train Acc: 0.9499338332598147, Val Acc: 0.9503968253968254\n","Epoch 117, Train Acc: 0.9477282752536391, Val Acc: 0.9543650793650794\n","Epoch 118, Train Acc: 0.9441993824437582, Val Acc: 0.9484126984126984\n","Epoch 119, Train Acc: 0.9437582708425232, Val Acc: 0.9464285714285714\n","Epoch 120, Train Acc: 0.9457432730480811, Val Acc: 0.9503968253968254\n","Epoch 121, Train Acc: 0.9444199382443759, Val Acc: 0.9563492063492064\n","Epoch 122, Train Acc: 0.9525805028672254, Val Acc: 0.9484126984126984\n","Epoch 123, Train Acc: 0.9561093956771063, Val Acc: 0.9503968253968254\n","Epoch 124, Train Acc: 0.9470666078517865, Val Acc: 0.9424603174603174\n","Epoch 125, Train Acc: 0.9486104984561093, Val Acc: 0.9464285714285714\n","Epoch 126, Train Acc: 0.9475077194530216, Val Acc: 0.9444444444444444\n","Epoch 127, Train Acc: 0.9503749448610499, Val Acc: 0.9464285714285714\n","Epoch 128, Train Acc: 0.9486104984561093, Val Acc: 0.9583333333333334\n","Epoch 129, Train Acc: 0.948831054256727, Val Acc: 0.9543650793650794\n","Epoch 130, Train Acc: 0.9455227172474636, Val Acc: 0.9523809523809523\n","Epoch 131, Train Acc: 0.9444199382443759, Val Acc: 0.9484126984126984\n","Epoch 132, Train Acc: 0.9455227172474636, Val Acc: 0.9503968253968254\n","Epoch 133, Train Acc: 0.9446404940449934, Val Acc: 0.9484126984126984\n","Epoch 134, Train Acc: 0.9422143802382003, Val Acc: 0.9464285714285714\n","Epoch 135, Train Acc: 0.9406704896338773, Val Acc: 0.9484126984126984\n","Epoch 136, Train Acc: 0.9382443758270842, Val Acc: 0.9444444444444444\n","Epoch 137, Train Acc: 0.9530216144684606, Val Acc: 0.9444444444444444\n","Epoch 138, Train Acc: 0.9499338332598147, Val Acc: 0.9563492063492064\n","Epoch 139, Train Acc: 0.9552271724746361, Val Acc: 0.9484126984126984\n","Epoch 140, Train Acc: 0.9441993824437582, Val Acc: 0.9523809523809523\n","Epoch 141, Train Acc: 0.9499338332598147, Val Acc: 0.9444444444444444\n","Epoch 142, Train Acc: 0.9464049404499338, Val Acc: 0.9523809523809523\n","Epoch 143, Train Acc: 0.9528010586678429, Val Acc: 0.9523809523809523\n","Epoch 144, Train Acc: 0.9483899426554918, Val Acc: 0.9603174603174603\n","Epoch 145, Train Acc: 0.9446404940449934, Val Acc: 0.9543650793650794\n","Epoch 146, Train Acc: 0.9455227172474636, Val Acc: 0.9444444444444444\n","Epoch 147, Train Acc: 0.9475077194530216, Val Acc: 0.9543650793650794\n","Epoch 148, Train Acc: 0.9534627260696956, Val Acc: 0.9583333333333334\n","Epoch 149, Train Acc: 0.9437582708425232, Val Acc: 0.9503968253968254\n","Epoch 150, Train Acc: 0.9494927216585797, Val Acc: 0.9484126984126984\n","Epoch 151, Train Acc: 0.9483899426554918, Val Acc: 0.9523809523809523\n","Epoch 152, Train Acc: 0.9479488310542568, Val Acc: 0.9623015873015873\n","Epoch 153, Train Acc: 0.9505955006616674, Val Acc: 0.9603174603174603\n","Epoch 154, Train Acc: 0.9486104984561093, Val Acc: 0.9503968253968254\n","Epoch 155, Train Acc: 0.9441993824437582, Val Acc: 0.9543650793650794\n","Epoch 156, Train Acc: 0.9486104984561093, Val Acc: 0.9583333333333334\n","Epoch 157, Train Acc: 0.9419938244375827, Val Acc: 0.9464285714285714\n","Epoch 158, Train Acc: 0.9441993824437582, Val Acc: 0.9523809523809523\n","Epoch 159, Train Acc: 0.9554477282752536, Val Acc: 0.9523809523809523\n","Epoch 160, Train Acc: 0.9523599470666079, Val Acc: 0.9563492063492064\n","Epoch 161, Train Acc: 0.9576532862814292, Val Acc: 0.9523809523809523\n","Epoch 162, Train Acc: 0.9550066166740185, Val Acc: 0.9583333333333334\n","Epoch 163, Train Acc: 0.9479488310542568, Val Acc: 0.9523809523809523\n","Epoch 164, Train Acc: 0.9510366122629025, Val Acc: 0.9543650793650794\n","Epoch 165, Train Acc: 0.9501543890604323, Val Acc: 0.9523809523809523\n","Epoch 166, Train Acc: 0.9499338332598147, Val Acc: 0.9484126984126984\n","Epoch 167, Train Acc: 0.9472871636524041, Val Acc: 0.9563492063492064\n","Epoch 168, Train Acc: 0.9541243934715483, Val Acc: 0.9523809523809523\n","Epoch 169, Train Acc: 0.9497132774591972, Val Acc: 0.9464285714285714\n","Epoch 170, Train Acc: 0.9464049404499338, Val Acc: 0.9563492063492064\n","Epoch 171, Train Acc: 0.94133215703573, Val Acc: 0.9464285714285714\n","Epoch 172, Train Acc: 0.9446404940449934, Val Acc: 0.9603174603174603\n","Epoch 173, Train Acc: 0.9441993824437582, Val Acc: 0.9563492063492064\n","Epoch 174, Train Acc: 0.9552271724746361, Val Acc: 0.9523809523809523\n","Epoch 175, Train Acc: 0.9512571680635201, Val Acc: 0.9543650793650794\n","Epoch 176, Train Acc: 0.9536832818703131, Val Acc: 0.9563492063492064\n","Epoch 177, Train Acc: 0.9530216144684606, Val Acc: 0.9543650793650794\n","Epoch 178, Train Acc: 0.9561093956771063, Val Acc: 0.9543650793650794\n","Epoch 179, Train Acc: 0.942876047640053, Val Acc: 0.9583333333333334\n","Epoch 180, Train Acc: 0.9510366122629025, Val Acc: 0.9503968253968254\n","Epoch 181, Train Acc: 0.9519188354653727, Val Acc: 0.9503968253968254\n","Epoch 182, Train Acc: 0.9505955006616674, Val Acc: 0.9623015873015873\n","Epoch 183, Train Acc: 0.9576532862814292, Val Acc: 0.9583333333333334\n","Epoch 184, Train Acc: 0.9494927216585797, Val Acc: 0.9543650793650794\n","Epoch 185, Train Acc: 0.9422143802382003, Val Acc: 0.9503968253968254\n","Epoch 186, Train Acc: 0.9459638288486987, Val Acc: 0.9503968253968254\n","Epoch 187, Train Acc: 0.9503749448610499, Val Acc: 0.9583333333333334\n","Epoch 188, Train Acc: 0.9512571680635201, Val Acc: 0.9424603174603174\n","Epoch 189, Train Acc: 0.9501543890604323, Val Acc: 0.9404761904761905\n","Epoch 190, Train Acc: 0.9501543890604323, Val Acc: 0.9503968253968254\n","Epoch 191, Train Acc: 0.9521393912659903, Val Acc: 0.9642857142857143\n","Epoch 192, Train Acc: 0.954786060873401, Val Acc: 0.9583333333333334\n","Epoch 193, Train Acc: 0.9499338332598147, Val Acc: 0.9484126984126984\n","Epoch 194, Train Acc: 0.9437582708425232, Val Acc: 0.9603174603174603\n","Epoch 195, Train Acc: 0.9550066166740185, Val Acc: 0.9484126984126984\n","Epoch 196, Train Acc: 0.9479488310542568, Val Acc: 0.9484126984126984\n","Epoch 197, Train Acc: 0.9455227172474636, Val Acc: 0.9543650793650794\n","Epoch 198, Train Acc: 0.9362593736215262, Val Acc: 0.9503968253968254\n","Epoch 199, Train Acc: 0.9419938244375827, Val Acc: 0.9523809523809523\n","Epoch 200, Train Acc: 0.9446404940449934, Val Acc: 0.9503968253968254\n","Epoch 201, Train Acc: 0.9550066166740185, Val Acc: 0.9523809523809523\n","Epoch 202, Train Acc: 0.9505955006616674, Val Acc: 0.9563492063492064\n","Epoch 203, Train Acc: 0.9539038376709308, Val Acc: 0.9623015873015873\n","Epoch 204, Train Acc: 0.9576532862814292, Val Acc: 0.9563492063492064\n","Epoch 205, Train Acc: 0.9578738420820467, Val Acc: 0.9563492063492064\n","Epoch 206, Train Acc: 0.9622849580943978, Val Acc: 0.9583333333333334\n","Epoch 207, Train Acc: 0.9501543890604323, Val Acc: 0.9523809523809523\n","Epoch 208, Train Acc: 0.9426554918394354, Val Acc: 0.9503968253968254\n","Epoch 209, Train Acc: 0.9578738420820467, Val Acc: 0.9623015873015873\n","Epoch 210, Train Acc: 0.943317159241288, Val Acc: 0.9543650793650794\n","Epoch 211, Train Acc: 0.9481693868548743, Val Acc: 0.9583333333333334\n","Epoch 212, Train Acc: 0.9490516100573445, Val Acc: 0.9583333333333334\n","Epoch 213, Train Acc: 0.9510366122629025, Val Acc: 0.9603174603174603\n","Epoch 214, Train Acc: 0.9521393912659903, Val Acc: 0.9603174603174603\n","Epoch 215, Train Acc: 0.9435377150419056, Val Acc: 0.9583333333333334\n","Epoch 216, Train Acc: 0.9479488310542568, Val Acc: 0.9503968253968254\n","Epoch 217, Train Acc: 0.9477282752536391, Val Acc: 0.9444444444444444\n","Epoch 218, Train Acc: 0.9490516100573445, Val Acc: 0.9503968253968254\n","Epoch 219, Train Acc: 0.9554477282752536, Val Acc: 0.9523809523809523\n","Epoch 220, Train Acc: 0.9528010586678429, Val Acc: 0.9603174603174603\n","Epoch 221, Train Acc: 0.9614027348919276, Val Acc: 0.9642857142857143\n","Epoch 222, Train Acc: 0.9514777238641376, Val Acc: 0.9523809523809523\n","Epoch 223, Train Acc: 0.9497132774591972, Val Acc: 0.9543650793650794\n","Epoch 224, Train Acc: 0.9479488310542568, Val Acc: 0.9503968253968254\n","Epoch 225, Train Acc: 0.9550066166740185, Val Acc: 0.9543650793650794\n","Epoch 226, Train Acc: 0.9550066166740185, Val Acc: 0.9563492063492064\n","Epoch 227, Train Acc: 0.9583149536832819, Val Acc: 0.9523809523809523\n","Epoch 228, Train Acc: 0.9550066166740185, Val Acc: 0.9583333333333334\n","Epoch 229, Train Acc: 0.9578738420820467, Val Acc: 0.9484126984126984\n","Epoch 230, Train Acc: 0.9459638288486987, Val Acc: 0.9444444444444444\n","Epoch 231, Train Acc: 0.948831054256727, Val Acc: 0.9404761904761905\n","Epoch 232, Train Acc: 0.9477282752536391, Val Acc: 0.9523809523809523\n","Epoch 233, Train Acc: 0.950816056462285, Val Acc: 0.9543650793650794\n","Epoch 234, Train Acc: 0.9505955006616674, Val Acc: 0.9623015873015873\n","Epoch 235, Train Acc: 0.950816056462285, Val Acc: 0.9523809523809523\n","Epoch 236, Train Acc: 0.9494927216585797, Val Acc: 0.9523809523809523\n","Epoch 237, Train Acc: 0.9510366122629025, Val Acc: 0.9543650793650794\n","Epoch 238, Train Acc: 0.9534627260696956, Val Acc: 0.9503968253968254\n","Epoch 239, Train Acc: 0.954786060873401, Val Acc: 0.9563492063492064\n","Epoch 240, Train Acc: 0.948831054256727, Val Acc: 0.9464285714285714\n","Epoch 241, Train Acc: 0.9464049404499338, Val Acc: 0.9583333333333334\n","Epoch 242, Train Acc: 0.9472871636524041, Val Acc: 0.9503968253968254\n","Epoch 243, Train Acc: 0.9472871636524041, Val Acc: 0.9543650793650794\n","Epoch 244, Train Acc: 0.9550066166740185, Val Acc: 0.9623015873015873\n","Epoch 245, Train Acc: 0.9563299514777238, Val Acc: 0.9523809523809523\n","Epoch 246, Train Acc: 0.9472871636524041, Val Acc: 0.9543650793650794\n","Epoch 247, Train Acc: 0.9503749448610499, Val Acc: 0.9583333333333334\n","Epoch 248, Train Acc: 0.9525805028672254, Val Acc: 0.9543650793650794\n","Epoch 249, Train Acc: 0.9519188354653727, Val Acc: 0.9563492063492064\n","Best Training Accuracy for Fold 4: 0.9521393912659903\n","Best Validation Accuracy for Fold 4: 0.9642857142857143\n","Classification Report for Fold 4:\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.96      0.96       247\n","           1       0.96      0.96      0.96       257\n","\n","    accuracy                           0.96       504\n","   macro avg       0.96      0.96      0.96       504\n","weighted avg       0.96      0.96      0.96       504\n","\n","Fold 5\n","Epoch 0, Train Acc: 0.6468901632112924, Val Acc: 0.6984126984126984\n","Epoch 1, Train Acc: 0.7099691221879135, Val Acc: 0.7202380952380952\n","Epoch 2, Train Acc: 0.7267313630348479, Val Acc: 0.7380952380952381\n","Epoch 3, Train Acc: 0.7512130569033966, Val Acc: 0.7797619047619048\n","Epoch 4, Train Acc: 0.7640052933392149, Val Acc: 0.7638888888888888\n","Epoch 5, Train Acc: 0.782752536391707, Val Acc: 0.7738095238095238\n","Epoch 6, Train Acc: 0.7801058667842964, Val Acc: 0.7857142857142857\n","Epoch 7, Train Acc: 0.8006175562417291, Val Acc: 0.8015873015873016\n","Epoch 8, Train Acc: 0.8149536832818703, Val Acc: 0.8134920634920635\n","Epoch 9, Train Acc: 0.8164975738861933, Val Acc: 0.7996031746031746\n","Epoch 10, Train Acc: 0.8341420379355977, Val Acc: 0.8075396825396826\n","Epoch 11, Train Acc: 0.8403176003528893, Val Acc: 0.8432539682539683\n","Epoch 12, Train Acc: 0.8420820467578297, Val Acc: 0.8412698412698413\n","Epoch 13, Train Acc: 0.8550948389942655, Val Acc: 0.8670634920634921\n","Epoch 14, Train Acc: 0.8550948389942655, Val Acc: 0.8611111111111112\n","Epoch 15, Train Acc: 0.8612704014115571, Val Acc: 0.8214285714285714\n","Epoch 16, Train Acc: 0.8670048522276136, Val Acc: 0.8630952380952381\n","Epoch 17, Train Acc: 0.8745037494486105, Val Acc: 0.873015873015873\n","Epoch 18, Train Acc: 0.8780326422584914, Val Acc: 0.8571428571428571\n","Epoch 19, Train Acc: 0.8886193206881341, Val Acc: 0.871031746031746\n","Epoch 20, Train Acc: 0.8903837670930745, Val Acc: 0.8670634920634921\n","Epoch 21, Train Acc: 0.9027348919276577, Val Acc: 0.8908730158730159\n","Epoch 22, Train Acc: 0.890163211292457, Val Acc: 0.8948412698412699\n","Epoch 23, Train Acc: 0.894133215703573, Val Acc: 0.8829365079365079\n","Epoch 24, Train Acc: 0.8908248786943097, Val Acc: 0.8869047619047619\n","Epoch 25, Train Acc: 0.9038376709307455, Val Acc: 0.8849206349206349\n","Epoch 26, Train Acc: 0.906043228936921, Val Acc: 0.8948412698412699\n","Epoch 27, Train Acc: 0.9036171151301279, Val Acc: 0.8968253968253969\n","Epoch 28, Train Acc: 0.9113365681517424, Val Acc: 0.9007936507936508\n","Epoch 29, Train Acc: 0.905602117335686, Val Acc: 0.8849206349206349\n","Epoch 30, Train Acc: 0.9064843405381562, Val Acc: 0.9007936507936508\n","Epoch 31, Train Acc: 0.9181737979708866, Val Acc: 0.8968253968253969\n","Epoch 32, Train Acc: 0.9049404499338333, Val Acc: 0.9007936507936508\n","Epoch 33, Train Acc: 0.9142037935597707, Val Acc: 0.9206349206349206\n","Epoch 34, Train Acc: 0.9234671371857079, Val Acc: 0.9265873015873016\n","Epoch 35, Train Acc: 0.9155271283634759, Val Acc: 0.9067460317460317\n","Epoch 36, Train Acc: 0.9201588001764447, Val Acc: 0.9206349206349206\n","Epoch 37, Train Acc: 0.9228054697838554, Val Acc: 0.8869047619047619\n","Epoch 38, Train Acc: 0.9217026907807675, Val Acc: 0.9146825396825397\n","Epoch 39, Train Acc: 0.9292015880017644, Val Acc: 0.9226190476190477\n","Epoch 40, Train Acc: 0.9252315835906484, Val Acc: 0.9166666666666666\n","Epoch 41, Train Acc: 0.9243493603881782, Val Acc: 0.9146825396825397\n","Epoch 42, Train Acc: 0.9269960299955888, Val Acc: 0.9186507936507936\n","Epoch 43, Train Acc: 0.9234671371857079, Val Acc: 0.9226190476190477\n","Epoch 44, Train Acc: 0.9258932509925011, Val Acc: 0.9206349206349206\n","Epoch 45, Train Acc: 0.9307454786060874, Val Acc: 0.9206349206349206\n","Epoch 46, Train Acc: 0.9208204675782973, Val Acc: 0.9146825396825397\n","Epoch 47, Train Acc: 0.9300838112042347, Val Acc: 0.9325396825396826\n","Epoch 48, Train Acc: 0.9355977062196735, Val Acc: 0.9404761904761905\n","Epoch 49, Train Acc: 0.9311865902073224, Val Acc: 0.9226190476190477\n","Epoch 50, Train Acc: 0.925452139391266, Val Acc: 0.9146825396825397\n","Epoch 51, Train Acc: 0.9265549183943538, Val Acc: 0.9404761904761905\n","Epoch 52, Train Acc: 0.9269960299955888, Val Acc: 0.9444444444444444\n","Epoch 53, Train Acc: 0.9303043670048522, Val Acc: 0.9404761904761905\n","Epoch 54, Train Acc: 0.9261138067931186, Val Acc: 0.9226190476190477\n","Epoch 55, Train Acc: 0.9355977062196735, Val Acc: 0.9444444444444444\n","Epoch 56, Train Acc: 0.942876047640053, Val Acc: 0.9404761904761905\n","Epoch 57, Train Acc: 0.9384649316277018, Val Acc: 0.9384920634920635\n","Epoch 58, Train Acc: 0.9384649316277018, Val Acc: 0.9424603174603174\n","Epoch 59, Train Acc: 0.9446404940449934, Val Acc: 0.9265873015873016\n","Epoch 60, Train Acc: 0.9340538156153507, Val Acc: 0.9206349206349206\n","Epoch 61, Train Acc: 0.9391265990295545, Val Acc: 0.9345238095238095\n","Epoch 62, Train Acc: 0.9300838112042347, Val Acc: 0.9325396825396826\n","Epoch 63, Train Acc: 0.9400088222320248, Val Acc: 0.9285714285714286\n","Epoch 64, Train Acc: 0.9391265990295545, Val Acc: 0.9226190476190477\n","Epoch 65, Train Acc: 0.9369210410233789, Val Acc: 0.9345238095238095\n","Epoch 66, Train Acc: 0.94133215703573, Val Acc: 0.9424603174603174\n","Epoch 67, Train Acc: 0.937362152624614, Val Acc: 0.9345238095238095\n","Epoch 68, Train Acc: 0.9322893692104103, Val Acc: 0.9265873015873016\n","Epoch 69, Train Acc: 0.9384649316277018, Val Acc: 0.9285714285714286\n","Epoch 70, Train Acc: 0.9384649316277018, Val Acc: 0.9246031746031746\n","Epoch 71, Train Acc: 0.9331715924128805, Val Acc: 0.9246031746031746\n","Epoch 72, Train Acc: 0.9483899426554918, Val Acc: 0.9384920634920635\n","Epoch 73, Train Acc: 0.9444199382443759, Val Acc: 0.9424603174603174\n","Epoch 74, Train Acc: 0.9378032642258491, Val Acc: 0.9305555555555556\n","Epoch 75, Train Acc: 0.94133215703573, Val Acc: 0.9265873015873016\n","Epoch 76, Train Acc: 0.9338332598147331, Val Acc: 0.9424603174603174\n","Epoch 77, Train Acc: 0.9446404940449934, Val Acc: 0.9345238095238095\n","Epoch 78, Train Acc: 0.9422143802382003, Val Acc: 0.9464285714285714\n","Epoch 79, Train Acc: 0.949272165857962, Val Acc: 0.9484126984126984\n","Epoch 80, Train Acc: 0.940891045434495, Val Acc: 0.9384920634920635\n","Epoch 81, Train Acc: 0.9430966034406705, Val Acc: 0.9424603174603174\n","Epoch 82, Train Acc: 0.9325099250110278, Val Acc: 0.9503968253968254\n","Epoch 83, Train Acc: 0.9351565946184385, Val Acc: 0.9424603174603174\n","Epoch 84, Train Acc: 0.9466254962505514, Val Acc: 0.9444444444444444\n","Epoch 85, Train Acc: 0.9435377150419056, Val Acc: 0.9444444444444444\n","Epoch 86, Train Acc: 0.9457432730480811, Val Acc: 0.9384920634920635\n","Epoch 87, Train Acc: 0.9444199382443759, Val Acc: 0.9404761904761905\n","Epoch 88, Train Acc: 0.9426554918394354, Val Acc: 0.9345238095238095\n","Epoch 89, Train Acc: 0.9378032642258491, Val Acc: 0.9543650793650794\n","Epoch 90, Train Acc: 0.9468460520511689, Val Acc: 0.9305555555555556\n","Epoch 91, Train Acc: 0.942876047640053, Val Acc: 0.9325396825396826\n","Epoch 92, Train Acc: 0.9426554918394354, Val Acc: 0.9503968253968254\n","Epoch 93, Train Acc: 0.9446404940449934, Val Acc: 0.9424603174603174\n","Epoch 94, Train Acc: 0.9437582708425232, Val Acc: 0.9464285714285714\n","Epoch 95, Train Acc: 0.9479488310542568, Val Acc: 0.9444444444444444\n","Epoch 96, Train Acc: 0.9435377150419056, Val Acc: 0.9365079365079365\n","Epoch 97, Train Acc: 0.948831054256727, Val Acc: 0.9424603174603174\n","Epoch 98, Train Acc: 0.9468460520511689, Val Acc: 0.9305555555555556\n","Epoch 99, Train Acc: 0.942876047640053, Val Acc: 0.9484126984126984\n","Epoch 100, Train Acc: 0.9422143802382003, Val Acc: 0.9424603174603174\n","Epoch 101, Train Acc: 0.9384649316277018, Val Acc: 0.9404761904761905\n","Epoch 102, Train Acc: 0.9486104984561093, Val Acc: 0.9265873015873016\n","Epoch 103, Train Acc: 0.9402293780326423, Val Acc: 0.9444444444444444\n","Epoch 104, Train Acc: 0.948831054256727, Val Acc: 0.9484126984126984\n","Epoch 105, Train Acc: 0.94133215703573, Val Acc: 0.9424603174603174\n","Epoch 106, Train Acc: 0.9457432730480811, Val Acc: 0.9365079365079365\n","Epoch 107, Train Acc: 0.9453021614468461, Val Acc: 0.9404761904761905\n","Epoch 108, Train Acc: 0.9448610498456109, Val Acc: 0.9424603174603174\n","Epoch 109, Train Acc: 0.9468460520511689, Val Acc: 0.9404761904761905\n","Epoch 110, Train Acc: 0.9446404940449934, Val Acc: 0.9424603174603174\n","Epoch 111, Train Acc: 0.9435377150419056, Val Acc: 0.9404761904761905\n","Epoch 112, Train Acc: 0.943317159241288, Val Acc: 0.9464285714285714\n","Epoch 113, Train Acc: 0.9455227172474636, Val Acc: 0.9404761904761905\n","Epoch 114, Train Acc: 0.9481693868548743, Val Acc: 0.9404761904761905\n","Epoch 115, Train Acc: 0.9483899426554918, Val Acc: 0.9503968253968254\n","Epoch 116, Train Acc: 0.9505955006616674, Val Acc: 0.9523809523809523\n","Epoch 117, Train Acc: 0.9523599470666079, Val Acc: 0.9464285714285714\n","Epoch 118, Train Acc: 0.9541243934715483, Val Acc: 0.9503968253968254\n","Epoch 119, Train Acc: 0.9457432730480811, Val Acc: 0.9444444444444444\n","Epoch 120, Train Acc: 0.9391265990295545, Val Acc: 0.9404761904761905\n","Epoch 121, Train Acc: 0.9455227172474636, Val Acc: 0.9583333333333334\n","Epoch 122, Train Acc: 0.9503749448610499, Val Acc: 0.9523809523809523\n","Epoch 123, Train Acc: 0.9472871636524041, Val Acc: 0.9484126984126984\n","Epoch 124, Train Acc: 0.9448610498456109, Val Acc: 0.9345238095238095\n","Epoch 125, Train Acc: 0.9481693868548743, Val Acc: 0.9424603174603174\n","Epoch 126, Train Acc: 0.949272165857962, Val Acc: 0.9384920634920635\n","Epoch 127, Train Acc: 0.9545655050727834, Val Acc: 0.9583333333333334\n","Epoch 128, Train Acc: 0.950816056462285, Val Acc: 0.9523809523809523\n","Epoch 129, Train Acc: 0.9470666078517865, Val Acc: 0.9543650793650794\n","Epoch 130, Train Acc: 0.9424349360388178, Val Acc: 0.9424603174603174\n","Epoch 131, Train Acc: 0.9510366122629025, Val Acc: 0.9464285714285714\n","Epoch 132, Train Acc: 0.9378032642258491, Val Acc: 0.9345238095238095\n","Epoch 133, Train Acc: 0.9457432730480811, Val Acc: 0.9464285714285714\n","Epoch 134, Train Acc: 0.9505955006616674, Val Acc: 0.9543650793650794\n","Epoch 135, Train Acc: 0.9439788266431407, Val Acc: 0.9503968253968254\n","Epoch 136, Train Acc: 0.948831054256727, Val Acc: 0.9583333333333334\n","Epoch 137, Train Acc: 0.9514777238641376, Val Acc: 0.9563492063492064\n","Epoch 138, Train Acc: 0.958756065284517, Val Acc: 0.9484126984126984\n","Epoch 139, Train Acc: 0.9516982796647552, Val Acc: 0.9464285714285714\n","Epoch 140, Train Acc: 0.9430966034406705, Val Acc: 0.9464285714285714\n","Epoch 141, Train Acc: 0.9516982796647552, Val Acc: 0.9404761904761905\n","Epoch 142, Train Acc: 0.9481693868548743, Val Acc: 0.9543650793650794\n","Epoch 143, Train Acc: 0.9505955006616674, Val Acc: 0.9404761904761905\n","Epoch 144, Train Acc: 0.9446404940449934, Val Acc: 0.9503968253968254\n","Epoch 145, Train Acc: 0.9483899426554918, Val Acc: 0.9444444444444444\n","Epoch 146, Train Acc: 0.9552271724746361, Val Acc: 0.9543650793650794\n","Epoch 147, Train Acc: 0.9501543890604323, Val Acc: 0.9484126984126984\n","Epoch 148, Train Acc: 0.9486104984561093, Val Acc: 0.9503968253968254\n","Epoch 149, Train Acc: 0.9479488310542568, Val Acc: 0.9503968253968254\n","Epoch 150, Train Acc: 0.9514777238641376, Val Acc: 0.9464285714285714\n","Epoch 151, Train Acc: 0.956771063078959, Val Acc: 0.9543650793650794\n","Epoch 152, Train Acc: 0.9543449492721658, Val Acc: 0.9543650793650794\n","Epoch 153, Train Acc: 0.9558888398764888, Val Acc: 0.9424603174603174\n","Epoch 154, Train Acc: 0.9479488310542568, Val Acc: 0.9543650793650794\n","Epoch 155, Train Acc: 0.9521393912659903, Val Acc: 0.9543650793650794\n","Epoch 156, Train Acc: 0.9558888398764888, Val Acc: 0.9484126984126984\n","Epoch 157, Train Acc: 0.9534627260696956, Val Acc: 0.9523809523809523\n","Epoch 158, Train Acc: 0.9483899426554918, Val Acc: 0.9543650793650794\n","Epoch 159, Train Acc: 0.9430966034406705, Val Acc: 0.9404761904761905\n","Epoch 160, Train Acc: 0.9450816056462285, Val Acc: 0.9503968253968254\n","Epoch 161, Train Acc: 0.9430966034406705, Val Acc: 0.9523809523809523\n","Epoch 162, Train Acc: 0.948831054256727, Val Acc: 0.9424603174603174\n","Epoch 163, Train Acc: 0.9514777238641376, Val Acc: 0.9523809523809523\n","Epoch 164, Train Acc: 0.949272165857962, Val Acc: 0.9603174603174603\n","Epoch 165, Train Acc: 0.943317159241288, Val Acc: 0.9424603174603174\n","Epoch 166, Train Acc: 0.9479488310542568, Val Acc: 0.9404761904761905\n","Epoch 167, Train Acc: 0.9424349360388178, Val Acc: 0.9464285714285714\n","Epoch 168, Train Acc: 0.9422143802382003, Val Acc: 0.9583333333333334\n","Epoch 169, Train Acc: 0.956771063078959, Val Acc: 0.9484126984126984\n","Epoch 170, Train Acc: 0.949272165857962, Val Acc: 0.9464285714285714\n","Epoch 171, Train Acc: 0.9464049404499338, Val Acc: 0.9424603174603174\n","Epoch 172, Train Acc: 0.9464049404499338, Val Acc: 0.9563492063492064\n","Epoch 173, Train Acc: 0.9479488310542568, Val Acc: 0.9484126984126984\n","Epoch 174, Train Acc: 0.9494927216585797, Val Acc: 0.9404761904761905\n","Epoch 175, Train Acc: 0.9457432730480811, Val Acc: 0.9523809523809523\n","Epoch 176, Train Acc: 0.9510366122629025, Val Acc: 0.9543650793650794\n","Epoch 177, Train Acc: 0.949272165857962, Val Acc: 0.9503968253968254\n","Epoch 178, Train Acc: 0.9486104984561093, Val Acc: 0.9424603174603174\n","Epoch 179, Train Acc: 0.9552271724746361, Val Acc: 0.9384920634920635\n","Epoch 180, Train Acc: 0.9539038376709308, Val Acc: 0.9464285714285714\n","Epoch 181, Train Acc: 0.9552271724746361, Val Acc: 0.9444444444444444\n","Epoch 182, Train Acc: 0.9543449492721658, Val Acc: 0.9404761904761905\n","Epoch 183, Train Acc: 0.9450816056462285, Val Acc: 0.9523809523809523\n","Epoch 184, Train Acc: 0.9503749448610499, Val Acc: 0.9603174603174603\n","Epoch 185, Train Acc: 0.9499338332598147, Val Acc: 0.9444444444444444\n","Epoch 186, Train Acc: 0.9554477282752536, Val Acc: 0.9563492063492064\n","Epoch 187, Train Acc: 0.9523599470666079, Val Acc: 0.9603174603174603\n","Epoch 188, Train Acc: 0.9541243934715483, Val Acc: 0.9563492063492064\n","Epoch 189, Train Acc: 0.9503749448610499, Val Acc: 0.9484126984126984\n","Epoch 190, Train Acc: 0.9512571680635201, Val Acc: 0.9444444444444444\n","Epoch 191, Train Acc: 0.9536832818703131, Val Acc: 0.9563492063492064\n","Epoch 192, Train Acc: 0.9490516100573445, Val Acc: 0.9424603174603174\n","Epoch 193, Train Acc: 0.9503749448610499, Val Acc: 0.9503968253968254\n","Epoch 194, Train Acc: 0.9497132774591972, Val Acc: 0.9503968253968254\n","Epoch 195, Train Acc: 0.9532421702690781, Val Acc: 0.9503968253968254\n","Epoch 196, Train Acc: 0.9521393912659903, Val Acc: 0.9404761904761905\n","Epoch 197, Train Acc: 0.9552271724746361, Val Acc: 0.9444444444444444\n","Epoch 198, Train Acc: 0.9477282752536391, Val Acc: 0.9563492063492064\n","Epoch 199, Train Acc: 0.9483899426554918, Val Acc: 0.9503968253968254\n","Epoch 200, Train Acc: 0.9417732686369652, Val Acc: 0.9583333333333334\n","Epoch 201, Train Acc: 0.9501543890604323, Val Acc: 0.9444444444444444\n","Epoch 202, Train Acc: 0.9563299514777238, Val Acc: 0.9523809523809523\n","Epoch 203, Train Acc: 0.9528010586678429, Val Acc: 0.9464285714285714\n","Epoch 204, Train Acc: 0.9521393912659903, Val Acc: 0.9523809523809523\n","Epoch 205, Train Acc: 0.9479488310542568, Val Acc: 0.9503968253968254\n","Epoch 206, Train Acc: 0.9580943978826643, Val Acc: 0.9503968253968254\n","Epoch 207, Train Acc: 0.9512571680635201, Val Acc: 0.9424603174603174\n","Epoch 208, Train Acc: 0.9543449492721658, Val Acc: 0.9404761904761905\n","Epoch 209, Train Acc: 0.948831054256727, Val Acc: 0.9464285714285714\n","Epoch 210, Train Acc: 0.9486104984561093, Val Acc: 0.9464285714285714\n","Epoch 211, Train Acc: 0.9466254962505514, Val Acc: 0.9603174603174603\n","Epoch 212, Train Acc: 0.9466254962505514, Val Acc: 0.9503968253968254\n","Epoch 213, Train Acc: 0.9523599470666079, Val Acc: 0.9464285714285714\n","Epoch 214, Train Acc: 0.9516982796647552, Val Acc: 0.9484126984126984\n","Epoch 215, Train Acc: 0.9539038376709308, Val Acc: 0.9623015873015873\n","Epoch 216, Train Acc: 0.9561093956771063, Val Acc: 0.9623015873015873\n","Epoch 217, Train Acc: 0.954786060873401, Val Acc: 0.9484126984126984\n","Epoch 218, Train Acc: 0.9505955006616674, Val Acc: 0.9503968253968254\n","Epoch 219, Train Acc: 0.9510366122629025, Val Acc: 0.9603174603174603\n","Epoch 220, Train Acc: 0.9490516100573445, Val Acc: 0.9603174603174603\n","Epoch 221, Train Acc: 0.9545655050727834, Val Acc: 0.9444444444444444\n","Epoch 222, Train Acc: 0.949272165857962, Val Acc: 0.9484126984126984\n","Epoch 223, Train Acc: 0.9556682840758712, Val Acc: 0.9543650793650794\n","Epoch 224, Train Acc: 0.957212174680194, Val Acc: 0.9503968253968254\n","Epoch 225, Train Acc: 0.9536832818703131, Val Acc: 0.9583333333333334\n","Epoch 226, Train Acc: 0.9424349360388178, Val Acc: 0.9623015873015873\n","Epoch 227, Train Acc: 0.9574327304808117, Val Acc: 0.9563492063492064\n","Epoch 228, Train Acc: 0.956771063078959, Val Acc: 0.9583333333333334\n","Epoch 229, Train Acc: 0.9611821790913101, Val Acc: 0.9563492063492064\n","Epoch 230, Train Acc: 0.9494927216585797, Val Acc: 0.9543650793650794\n","Epoch 231, Train Acc: 0.9470666078517865, Val Acc: 0.9484126984126984\n","Epoch 232, Train Acc: 0.9501543890604323, Val Acc: 0.9503968253968254\n","Epoch 233, Train Acc: 0.9543449492721658, Val Acc: 0.9503968253968254\n","Epoch 234, Train Acc: 0.9545655050727834, Val Acc: 0.9444444444444444\n","Epoch 235, Train Acc: 0.9516982796647552, Val Acc: 0.9543650793650794\n","Epoch 236, Train Acc: 0.9378032642258491, Val Acc: 0.9424603174603174\n","Epoch 237, Train Acc: 0.9534627260696956, Val Acc: 0.9444444444444444\n","Epoch 238, Train Acc: 0.9501543890604323, Val Acc: 0.9543650793650794\n","Epoch 239, Train Acc: 0.949272165857962, Val Acc: 0.9424603174603174\n","Epoch 240, Train Acc: 0.9530216144684606, Val Acc: 0.9503968253968254\n","Epoch 241, Train Acc: 0.9481693868548743, Val Acc: 0.9523809523809523\n","Epoch 242, Train Acc: 0.9589766210851345, Val Acc: 0.9543650793650794\n","Epoch 243, Train Acc: 0.9594177326863697, Val Acc: 0.9603174603174603\n","Epoch 244, Train Acc: 0.956771063078959, Val Acc: 0.9583333333333334\n","Epoch 245, Train Acc: 0.9530216144684606, Val Acc: 0.9603174603174603\n","Epoch 246, Train Acc: 0.9583149536832819, Val Acc: 0.9543650793650794\n","Epoch 247, Train Acc: 0.9459638288486987, Val Acc: 0.9642857142857143\n","Epoch 248, Train Acc: 0.9422143802382003, Val Acc: 0.9404761904761905\n","Epoch 249, Train Acc: 0.9528010586678429, Val Acc: 0.9603174603174603\n","Best Training Accuracy for Fold 5: 0.9459638288486987\n","Best Validation Accuracy for Fold 5: 0.9642857142857143\n","Classification Report for Fold 5:\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.97      0.96       266\n","           1       0.96      0.95      0.96       238\n","\n","    accuracy                           0.96       504\n","   macro avg       0.96      0.96      0.96       504\n","weighted avg       0.96      0.96      0.96       504\n","\n","Fold 6\n","Epoch 0, Train Acc: 0.6440229378032643, Val Acc: 0.7261904761904762\n","Epoch 1, Train Acc: 0.7075430083811204, Val Acc: 0.7321428571428571\n","Epoch 2, Train Acc: 0.7366563740626378, Val Acc: 0.7182539682539683\n","Epoch 3, Train Acc: 0.7602558447287163, Val Acc: 0.7380952380952381\n","Epoch 4, Train Acc: 0.7655491839435378, Val Acc: 0.7440476190476191\n","Epoch 5, Train Acc: 0.7836347595941773, Val Acc: 0.746031746031746\n","Epoch 6, Train Acc: 0.8017203352448169, Val Acc: 0.7619047619047619\n","Epoch 7, Train Acc: 0.8087781208645788, Val Acc: 0.7738095238095238\n","Epoch 8, Train Acc: 0.8162770180855756, Val Acc: 0.748015873015873\n","Epoch 9, Train Acc: 0.8270842523158359, Val Acc: 0.7956349206349206\n","Epoch 10, Train Acc: 0.8378914865460961, Val Acc: 0.7916666666666666\n","Epoch 11, Train Acc: 0.8416409351565947, Val Acc: 0.8055555555555556\n","Epoch 12, Train Acc: 0.8478164975738862, Val Acc: 0.8174603174603174\n","Epoch 13, Train Acc: 0.8539920599911778, Val Acc: 0.8075396825396826\n","Epoch 14, Train Acc: 0.8535509483899426, Val Acc: 0.8392857142857143\n","Epoch 15, Train Acc: 0.8634759594177327, Val Acc: 0.8234126984126984\n","Epoch 16, Train Acc: 0.8630348478164975, Val Acc: 0.8392857142857143\n","Epoch 17, Train Acc: 0.8751654168504631, Val Acc: 0.8472222222222222\n","Epoch 18, Train Acc: 0.878253198059109, Val Acc: 0.8373015873015873\n","Epoch 19, Train Acc: 0.8835465372739303, Val Acc: 0.8551587301587301\n","Epoch 20, Train Acc: 0.8928098808998677, Val Acc: 0.8412698412698413\n","Epoch 21, Train Acc: 0.8872959858844287, Val Acc: 0.871031746031746\n","Epoch 22, Train Acc: 0.8877370974856639, Val Acc: 0.8511904761904762\n","Epoch 23, Train Acc: 0.8930304367004852, Val Acc: 0.8511904761904762\n","Epoch 24, Train Acc: 0.8906043228936921, Val Acc: 0.8611111111111112\n","Epoch 25, Train Acc: 0.9009704455227172, Val Acc: 0.8571428571428571\n","Epoch 26, Train Acc: 0.9018526687251874, Val Acc: 0.8869047619047619\n","Epoch 27, Train Acc: 0.9038376709307455, Val Acc: 0.8928571428571429\n","Epoch 28, Train Acc: 0.9086898985443317, Val Acc: 0.9007936507936508\n","Epoch 29, Train Acc: 0.9049404499338333, Val Acc: 0.9067460317460317\n","Epoch 30, Train Acc: 0.908028231142479, Val Acc: 0.9107142857142857\n","Epoch 31, Train Acc: 0.9086898985443317, Val Acc: 0.8968253968253969\n","Epoch 32, Train Acc: 0.9161887957653286, Val Acc: 0.9087301587301587\n","Epoch 33, Train Acc: 0.9097926775474195, Val Acc: 0.9206349206349206\n","Epoch 34, Train Acc: 0.9144243493603882, Val Acc: 0.9107142857142857\n","Epoch 35, Train Acc: 0.9170710189677989, Val Acc: 0.8829365079365079\n","Epoch 36, Train Acc: 0.9208204675782973, Val Acc: 0.9166666666666666\n","Epoch 37, Train Acc: 0.9212615791795324, Val Acc: 0.9107142857142857\n","Epoch 38, Train Acc: 0.9170710189677989, Val Acc: 0.9166666666666666\n","Epoch 39, Train Acc: 0.9186149095721218, Val Acc: 0.9246031746031746\n","Epoch 40, Train Acc: 0.9232465813850904, Val Acc: 0.9226190476190477\n","Epoch 41, Train Acc: 0.9265549183943538, Val Acc: 0.9226190476190477\n","Epoch 42, Train Acc: 0.9269960299955888, Val Acc: 0.9285714285714286\n","Epoch 43, Train Acc: 0.9285399205999118, Val Acc: 0.9186507936507936\n","Epoch 44, Train Acc: 0.9358182620202912, Val Acc: 0.9305555555555556\n","Epoch 45, Train Acc: 0.9283193647992942, Val Acc: 0.9424603174603174\n","Epoch 46, Train Acc: 0.9316277018085576, Val Acc: 0.9265873015873016\n","Epoch 47, Train Acc: 0.9305249228054698, Val Acc: 0.9166666666666666\n","Epoch 48, Train Acc: 0.9283193647992942, Val Acc: 0.9444444444444444\n","Epoch 49, Train Acc: 0.933392148213498, Val Acc: 0.9464285714285714\n","Epoch 50, Train Acc: 0.9210410233789149, Val Acc: 0.9285714285714286\n","Epoch 51, Train Acc: 0.9247904719894133, Val Acc: 0.9246031746031746\n","Epoch 52, Train Acc: 0.9311865902073224, Val Acc: 0.9265873015873016\n","Epoch 53, Train Acc: 0.927437141596824, Val Acc: 0.9404761904761905\n","Epoch 54, Train Acc: 0.9283193647992942, Val Acc: 0.9464285714285714\n","Epoch 55, Train Acc: 0.9360388178209087, Val Acc: 0.9265873015873016\n","Epoch 56, Train Acc: 0.934936038817821, Val Acc: 0.9384920634920635\n","Epoch 57, Train Acc: 0.9371415968239964, Val Acc: 0.9246031746031746\n","Epoch 58, Train Acc: 0.9316277018085576, Val Acc: 0.9365079365079365\n","Epoch 59, Train Acc: 0.9386854874283194, Val Acc: 0.9523809523809523\n","Epoch 60, Train Acc: 0.9316277018085576, Val Acc: 0.9325396825396826\n","Epoch 61, Train Acc: 0.9417732686369652, Val Acc: 0.9384920634920635\n","Epoch 62, Train Acc: 0.9331715924128805, Val Acc: 0.9484126984126984\n","Epoch 63, Train Acc: 0.9397882664314071, Val Acc: 0.9345238095238095\n","Epoch 64, Train Acc: 0.94133215703573, Val Acc: 0.9365079365079365\n","Epoch 65, Train Acc: 0.9344949272165858, Val Acc: 0.9424603174603174\n","Epoch 66, Train Acc: 0.9347154830172033, Val Acc: 0.9583333333333334\n","Epoch 67, Train Acc: 0.9364799294221438, Val Acc: 0.9325396825396826\n","Epoch 68, Train Acc: 0.9351565946184385, Val Acc: 0.9365079365079365\n","Epoch 69, Train Acc: 0.9347154830172033, Val Acc: 0.9484126984126984\n","Epoch 70, Train Acc: 0.9331715924128805, Val Acc: 0.9384920634920635\n","Epoch 71, Train Acc: 0.9316277018085576, Val Acc: 0.9365079365079365\n","Epoch 72, Train Acc: 0.9362593736215262, Val Acc: 0.9603174603174603\n","Epoch 73, Train Acc: 0.9397882664314071, Val Acc: 0.9543650793650794\n","Epoch 74, Train Acc: 0.937362152624614, Val Acc: 0.9444444444444444\n","Epoch 75, Train Acc: 0.9307454786060874, Val Acc: 0.9444444444444444\n","Epoch 76, Train Acc: 0.9351565946184385, Val Acc: 0.9563492063492064\n","Epoch 77, Train Acc: 0.9479488310542568, Val Acc: 0.9523809523809523\n","Epoch 78, Train Acc: 0.94133215703573, Val Acc: 0.9464285714285714\n","Epoch 79, Train Acc: 0.9457432730480811, Val Acc: 0.9642857142857143\n","Epoch 80, Train Acc: 0.9393471548301721, Val Acc: 0.9484126984126984\n","Epoch 81, Train Acc: 0.9459638288486987, Val Acc: 0.9484126984126984\n","Epoch 82, Train Acc: 0.943317159241288, Val Acc: 0.9484126984126984\n","Epoch 83, Train Acc: 0.9457432730480811, Val Acc: 0.9543650793650794\n","Epoch 84, Train Acc: 0.9453021614468461, Val Acc: 0.9523809523809523\n","Epoch 85, Train Acc: 0.9426554918394354, Val Acc: 0.9484126984126984\n","Epoch 86, Train Acc: 0.9459638288486987, Val Acc: 0.9365079365079365\n","Epoch 87, Train Acc: 0.9347154830172033, Val Acc: 0.9523809523809523\n","Epoch 88, Train Acc: 0.9404499338332598, Val Acc: 0.9563492063492064\n","Epoch 89, Train Acc: 0.9430966034406705, Val Acc: 0.9444444444444444\n","Epoch 90, Train Acc: 0.9457432730480811, Val Acc: 0.9484126984126984\n","Epoch 91, Train Acc: 0.9439788266431407, Val Acc: 0.9325396825396826\n","Epoch 92, Train Acc: 0.9393471548301721, Val Acc: 0.9503968253968254\n","Epoch 93, Train Acc: 0.9461843846493163, Val Acc: 0.9464285714285714\n","Epoch 94, Train Acc: 0.9358182620202912, Val Acc: 0.9484126984126984\n","Epoch 95, Train Acc: 0.9415527128363476, Val Acc: 0.9603174603174603\n","Epoch 96, Train Acc: 0.9481693868548743, Val Acc: 0.9503968253968254\n","Epoch 97, Train Acc: 0.9426554918394354, Val Acc: 0.9523809523809523\n","Epoch 98, Train Acc: 0.9457432730480811, Val Acc: 0.9543650793650794\n","Epoch 99, Train Acc: 0.9450816056462285, Val Acc: 0.9642857142857143\n","Epoch 100, Train Acc: 0.9477282752536391, Val Acc: 0.9503968253968254\n","Epoch 101, Train Acc: 0.9457432730480811, Val Acc: 0.9603174603174603\n","Epoch 102, Train Acc: 0.940891045434495, Val Acc: 0.9424603174603174\n","Epoch 103, Train Acc: 0.9481693868548743, Val Acc: 0.9623015873015873\n","Epoch 104, Train Acc: 0.9351565946184385, Val Acc: 0.9285714285714286\n","Epoch 105, Train Acc: 0.9424349360388178, Val Acc: 0.9424603174603174\n","Epoch 106, Train Acc: 0.9472871636524041, Val Acc: 0.9484126984126984\n","Epoch 107, Train Acc: 0.9472871636524041, Val Acc: 0.9484126984126984\n","Epoch 108, Train Acc: 0.9552271724746361, Val Acc: 0.9464285714285714\n","Epoch 109, Train Acc: 0.9481693868548743, Val Acc: 0.9523809523809523\n","Epoch 110, Train Acc: 0.9411116012351125, Val Acc: 0.9583333333333334\n","Epoch 111, Train Acc: 0.9439788266431407, Val Acc: 0.9583333333333334\n","Epoch 112, Train Acc: 0.9419938244375827, Val Acc: 0.9464285714285714\n","Epoch 113, Train Acc: 0.9470666078517865, Val Acc: 0.9325396825396826\n","Epoch 114, Train Acc: 0.933392148213498, Val Acc: 0.9484126984126984\n","Epoch 115, Train Acc: 0.9435377150419056, Val Acc: 0.9563492063492064\n","Epoch 116, Train Acc: 0.9450816056462285, Val Acc: 0.9583333333333334\n","Epoch 117, Train Acc: 0.9483899426554918, Val Acc: 0.9543650793650794\n","Epoch 118, Train Acc: 0.9457432730480811, Val Acc: 0.9642857142857143\n","Epoch 119, Train Acc: 0.9534627260696956, Val Acc: 0.9642857142857143\n","Epoch 120, Train Acc: 0.9523599470666079, Val Acc: 0.9444444444444444\n","Epoch 121, Train Acc: 0.9404499338332598, Val Acc: 0.9563492063492064\n","Epoch 122, Train Acc: 0.949272165857962, Val Acc: 0.9642857142857143\n","Epoch 123, Train Acc: 0.950816056462285, Val Acc: 0.9523809523809523\n","Epoch 124, Train Acc: 0.9541243934715483, Val Acc: 0.9523809523809523\n","Epoch 125, Train Acc: 0.9457432730480811, Val Acc: 0.9583333333333334\n","Epoch 126, Train Acc: 0.9523599470666079, Val Acc: 0.9523809523809523\n","Epoch 127, Train Acc: 0.9505955006616674, Val Acc: 0.9444444444444444\n","Epoch 128, Train Acc: 0.9424349360388178, Val Acc: 0.9642857142857143\n","Epoch 129, Train Acc: 0.9483899426554918, Val Acc: 0.9603174603174603\n","Epoch 130, Train Acc: 0.9439788266431407, Val Acc: 0.9583333333333334\n","Epoch 131, Train Acc: 0.9448610498456109, Val Acc: 0.9583333333333334\n","Epoch 132, Train Acc: 0.9435377150419056, Val Acc: 0.9623015873015873\n","Epoch 133, Train Acc: 0.9486104984561093, Val Acc: 0.9543650793650794\n","Epoch 134, Train Acc: 0.9516982796647552, Val Acc: 0.9583333333333334\n","Epoch 135, Train Acc: 0.9393471548301721, Val Acc: 0.9503968253968254\n","Epoch 136, Train Acc: 0.9439788266431407, Val Acc: 0.9642857142857143\n","Epoch 137, Train Acc: 0.9481693868548743, Val Acc: 0.9484126984126984\n","Epoch 138, Train Acc: 0.9525805028672254, Val Acc: 0.9603174603174603\n","Epoch 139, Train Acc: 0.9505955006616674, Val Acc: 0.9623015873015873\n","Epoch 140, Train Acc: 0.9505955006616674, Val Acc: 0.9543650793650794\n","Epoch 141, Train Acc: 0.9552271724746361, Val Acc: 0.9523809523809523\n","Epoch 142, Train Acc: 0.9528010586678429, Val Acc: 0.9642857142857143\n","Epoch 143, Train Acc: 0.9543449492721658, Val Acc: 0.9464285714285714\n","Epoch 144, Train Acc: 0.9459638288486987, Val Acc: 0.9404761904761905\n","Epoch 145, Train Acc: 0.948831054256727, Val Acc: 0.9503968253968254\n","Epoch 146, Train Acc: 0.957212174680194, Val Acc: 0.9543650793650794\n","Epoch 147, Train Acc: 0.9541243934715483, Val Acc: 0.9503968253968254\n","Epoch 148, Train Acc: 0.9457432730480811, Val Acc: 0.9543650793650794\n","Epoch 149, Train Acc: 0.9479488310542568, Val Acc: 0.9523809523809523\n","Epoch 150, Train Acc: 0.9404499338332598, Val Acc: 0.9484126984126984\n","Epoch 151, Train Acc: 0.9497132774591972, Val Acc: 0.9523809523809523\n","Epoch 152, Train Acc: 0.9554477282752536, Val Acc: 0.9523809523809523\n","Epoch 153, Train Acc: 0.9516982796647552, Val Acc: 0.9603174603174603\n","Epoch 154, Train Acc: 0.9501543890604323, Val Acc: 0.9484126984126984\n","Epoch 155, Train Acc: 0.9525805028672254, Val Acc: 0.9563492063492064\n","Epoch 156, Train Acc: 0.9477282752536391, Val Acc: 0.9702380952380952\n","Epoch 157, Train Acc: 0.9499338332598147, Val Acc: 0.9583333333333334\n","Epoch 158, Train Acc: 0.9514777238641376, Val Acc: 0.9642857142857143\n","Epoch 159, Train Acc: 0.9490516100573445, Val Acc: 0.9563492063492064\n","Epoch 160, Train Acc: 0.9558888398764888, Val Acc: 0.9642857142857143\n","Epoch 161, Train Acc: 0.9563299514777238, Val Acc: 0.9424603174603174\n","Epoch 162, Train Acc: 0.9455227172474636, Val Acc: 0.9642857142857143\n","Epoch 163, Train Acc: 0.9446404940449934, Val Acc: 0.9563492063492064\n","Epoch 164, Train Acc: 0.9543449492721658, Val Acc: 0.9484126984126984\n","Epoch 165, Train Acc: 0.9503749448610499, Val Acc: 0.9464285714285714\n","Epoch 166, Train Acc: 0.9528010586678429, Val Acc: 0.9543650793650794\n","Epoch 167, Train Acc: 0.9505955006616674, Val Acc: 0.9563492063492064\n","Epoch 168, Train Acc: 0.948831054256727, Val Acc: 0.9523809523809523\n","Epoch 169, Train Acc: 0.9483899426554918, Val Acc: 0.9623015873015873\n","Epoch 170, Train Acc: 0.949272165857962, Val Acc: 0.9543650793650794\n","Epoch 171, Train Acc: 0.9461843846493163, Val Acc: 0.9563492063492064\n","Epoch 172, Train Acc: 0.9437582708425232, Val Acc: 0.9444444444444444\n","Epoch 173, Train Acc: 0.9477282752536391, Val Acc: 0.9662698412698413\n","Epoch 174, Train Acc: 0.9380238200264667, Val Acc: 0.9563492063492064\n","Epoch 175, Train Acc: 0.9453021614468461, Val Acc: 0.9563492063492064\n","Epoch 176, Train Acc: 0.9545655050727834, Val Acc: 0.9682539682539683\n","Epoch 177, Train Acc: 0.9578738420820467, Val Acc: 0.9583333333333334\n","Epoch 178, Train Acc: 0.9525805028672254, Val Acc: 0.9583333333333334\n","Epoch 179, Train Acc: 0.9448610498456109, Val Acc: 0.9603174603174603\n","Epoch 180, Train Acc: 0.9516982796647552, Val Acc: 0.9523809523809523\n","Epoch 181, Train Acc: 0.9574327304808117, Val Acc: 0.9484126984126984\n","Epoch 182, Train Acc: 0.9525805028672254, Val Acc: 0.9523809523809523\n","Epoch 183, Train Acc: 0.9453021614468461, Val Acc: 0.9642857142857143\n","Epoch 184, Train Acc: 0.9521393912659903, Val Acc: 0.9563492063492064\n","Epoch 185, Train Acc: 0.9494927216585797, Val Acc: 0.9325396825396826\n","Epoch 186, Train Acc: 0.9426554918394354, Val Acc: 0.9484126984126984\n","Epoch 187, Train Acc: 0.9501543890604323, Val Acc: 0.9623015873015873\n","Epoch 188, Train Acc: 0.9400088222320248, Val Acc: 0.9603174603174603\n","Epoch 189, Train Acc: 0.9499338332598147, Val Acc: 0.9444444444444444\n","Epoch 190, Train Acc: 0.9494927216585797, Val Acc: 0.9523809523809523\n","Epoch 191, Train Acc: 0.942876047640053, Val Acc: 0.9563492063492064\n","Epoch 192, Train Acc: 0.9521393912659903, Val Acc: 0.9642857142857143\n","Epoch 193, Train Acc: 0.9490516100573445, Val Acc: 0.9563492063492064\n","Epoch 194, Train Acc: 0.9532421702690781, Val Acc: 0.9464285714285714\n","Epoch 195, Train Acc: 0.9554477282752536, Val Acc: 0.9484126984126984\n","Epoch 196, Train Acc: 0.9461843846493163, Val Acc: 0.9523809523809523\n","Epoch 197, Train Acc: 0.94133215703573, Val Acc: 0.9563492063492064\n","Epoch 198, Train Acc: 0.9503749448610499, Val Acc: 0.9662698412698413\n","Epoch 199, Train Acc: 0.9521393912659903, Val Acc: 0.9464285714285714\n","Epoch 200, Train Acc: 0.9530216144684606, Val Acc: 0.9503968253968254\n","Epoch 201, Train Acc: 0.9494927216585797, Val Acc: 0.9603174603174603\n","Epoch 202, Train Acc: 0.9439788266431407, Val Acc: 0.9484126984126984\n","Epoch 203, Train Acc: 0.9497132774591972, Val Acc: 0.9603174603174603\n","Epoch 204, Train Acc: 0.9512571680635201, Val Acc: 0.9603174603174603\n","Epoch 205, Train Acc: 0.9521393912659903, Val Acc: 0.9523809523809523\n","Epoch 206, Train Acc: 0.9490516100573445, Val Acc: 0.9503968253968254\n","Epoch 207, Train Acc: 0.9464049404499338, Val Acc: 0.9444444444444444\n","Epoch 208, Train Acc: 0.9490516100573445, Val Acc: 0.9603174603174603\n","Epoch 209, Train Acc: 0.9565505072783415, Val Acc: 0.9603174603174603\n","Epoch 210, Train Acc: 0.9541243934715483, Val Acc: 0.9603174603174603\n","Epoch 211, Train Acc: 0.9539038376709308, Val Acc: 0.9503968253968254\n","Epoch 212, Train Acc: 0.9468460520511689, Val Acc: 0.9583333333333334\n","Epoch 213, Train Acc: 0.9481693868548743, Val Acc: 0.9543650793650794\n","Epoch 214, Train Acc: 0.9523599470666079, Val Acc: 0.9484126984126984\n","Epoch 215, Train Acc: 0.9516982796647552, Val Acc: 0.9603174603174603\n","Epoch 216, Train Acc: 0.9530216144684606, Val Acc: 0.9464285714285714\n","Epoch 217, Train Acc: 0.9466254962505514, Val Acc: 0.9484126984126984\n","Epoch 218, Train Acc: 0.9543449492721658, Val Acc: 0.9583333333333334\n","Epoch 219, Train Acc: 0.9525805028672254, Val Acc: 0.9603174603174603\n","Epoch 220, Train Acc: 0.957212174680194, Val Acc: 0.9583333333333334\n","Epoch 221, Train Acc: 0.9528010586678429, Val Acc: 0.9523809523809523\n","Epoch 222, Train Acc: 0.9525805028672254, Val Acc: 0.9523809523809523\n","Epoch 223, Train Acc: 0.9539038376709308, Val Acc: 0.9484126984126984\n","Epoch 224, Train Acc: 0.9574327304808117, Val Acc: 0.9583333333333334\n","Epoch 225, Train Acc: 0.943317159241288, Val Acc: 0.9603174603174603\n","Epoch 226, Train Acc: 0.9468460520511689, Val Acc: 0.9523809523809523\n","Epoch 227, Train Acc: 0.9453021614468461, Val Acc: 0.9404761904761905\n","Epoch 228, Train Acc: 0.9472871636524041, Val Acc: 0.9722222222222222\n","Epoch 229, Train Acc: 0.9481693868548743, Val Acc: 0.9662698412698413\n","Epoch 230, Train Acc: 0.9512571680635201, Val Acc: 0.9623015873015873\n","Epoch 231, Train Acc: 0.9574327304808117, Val Acc: 0.9484126984126984\n","Epoch 232, Train Acc: 0.9505955006616674, Val Acc: 0.9583333333333334\n","Epoch 233, Train Acc: 0.9534627260696956, Val Acc: 0.9583333333333334\n","Epoch 234, Train Acc: 0.9490516100573445, Val Acc: 0.9503968253968254\n","Epoch 235, Train Acc: 0.9541243934715483, Val Acc: 0.9484126984126984\n","Epoch 236, Train Acc: 0.9532421702690781, Val Acc: 0.9543650793650794\n","Epoch 237, Train Acc: 0.9481693868548743, Val Acc: 0.9503968253968254\n","Epoch 238, Train Acc: 0.9545655050727834, Val Acc: 0.9503968253968254\n","Epoch 239, Train Acc: 0.9554477282752536, Val Acc: 0.9563492063492064\n","Epoch 240, Train Acc: 0.9578738420820467, Val Acc: 0.9503968253968254\n","Epoch 241, Train Acc: 0.9494927216585797, Val Acc: 0.9682539682539683\n","Epoch 242, Train Acc: 0.9516982796647552, Val Acc: 0.9623015873015873\n","Epoch 243, Train Acc: 0.9512571680635201, Val Acc: 0.9583333333333334\n","Epoch 244, Train Acc: 0.9459638288486987, Val Acc: 0.9702380952380952\n","Epoch 245, Train Acc: 0.954786060873401, Val Acc: 0.9642857142857143\n","Epoch 246, Train Acc: 0.9543449492721658, Val Acc: 0.9603174603174603\n","Epoch 247, Train Acc: 0.949272165857962, Val Acc: 0.9682539682539683\n","Epoch 248, Train Acc: 0.9541243934715483, Val Acc: 0.9623015873015873\n","Epoch 249, Train Acc: 0.9543449492721658, Val Acc: 0.9563492063492064\n","Best Training Accuracy for Fold 6: 0.9472871636524041\n","Best Validation Accuracy for Fold 6: 0.9722222222222222\n","Classification Report for Fold 6:\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.96      0.96       253\n","           1       0.96      0.95      0.96       251\n","\n","    accuracy                           0.96       504\n","   macro avg       0.96      0.96      0.96       504\n","weighted avg       0.96      0.96      0.96       504\n","\n","Fold 7\n","Epoch 0, Train Acc: 0.6517423908248787, Val Acc: 0.6607142857142857\n","Epoch 1, Train Acc: 0.7130569033965594, Val Acc: 0.7063492063492064\n","Epoch 2, Train Acc: 0.7353330392589326, Val Acc: 0.7182539682539683\n","Epoch 3, Train Acc: 0.7571680635200706, Val Acc: 0.7341269841269841\n","Epoch 4, Train Acc: 0.7655491839435378, Val Acc: 0.7599206349206349\n","Epoch 5, Train Acc: 0.7785619761799736, Val Acc: 0.7579365079365079\n","Epoch 6, Train Acc: 0.7893692104102338, Val Acc: 0.7797619047619048\n","Epoch 7, Train Acc: 0.7988531098367887, Val Acc: 0.8055555555555556\n","Epoch 8, Train Acc: 0.8127481252756947, Val Acc: 0.8055555555555556\n","Epoch 9, Train Acc: 0.8268636965152184, Val Acc: 0.8134920634920635\n","Epoch 10, Train Acc: 0.8407587119541244, Val Acc: 0.8134920634920635\n","Epoch 11, Train Acc: 0.8442876047640053, Val Acc: 0.8373015873015873\n","Epoch 12, Train Acc: 0.8475959417732687, Val Acc: 0.8293650793650794\n","Epoch 13, Train Acc: 0.8511248345831496, Val Acc: 0.8373015873015873\n","Epoch 14, Train Acc: 0.8575209528010587, Val Acc: 0.8234126984126984\n","Epoch 15, Train Acc: 0.8656815174239082, Val Acc: 0.8313492063492064\n","Epoch 16, Train Acc: 0.8692104102337892, Val Acc: 0.8650793650793651\n","Epoch 17, Train Acc: 0.8813409792677548, Val Acc: 0.8551587301587301\n","Epoch 18, Train Acc: 0.8753859726510808, Val Acc: 0.8472222222222222\n","Epoch 19, Train Acc: 0.8850904278782532, Val Acc: 0.878968253968254\n","Epoch 20, Train Acc: 0.886193206881341, Val Acc: 0.8472222222222222\n","Epoch 21, Train Acc: 0.8899426554918395, Val Acc: 0.8849206349206349\n","Epoch 22, Train Acc: 0.8919276576973975, Val Acc: 0.8809523809523809\n","Epoch 23, Train Acc: 0.8970004411116013, Val Acc: 0.873015873015873\n","Epoch 24, Train Acc: 0.8919276576973975, Val Acc: 0.876984126984127\n","Epoch 25, Train Acc: 0.9014115571239524, Val Acc: 0.8809523809523809\n","Epoch 26, Train Acc: 0.9082487869430966, Val Acc: 0.8670634920634921\n","Epoch 27, Train Acc: 0.9020732245258051, Val Acc: 0.8650793650793651\n","Epoch 28, Train Acc: 0.9084693427437142, Val Acc: 0.9027777777777778\n","Epoch 29, Train Acc: 0.9117776797529775, Val Acc: 0.8928571428571429\n","Epoch 30, Train Acc: 0.9126599029554477, Val Acc: 0.876984126984127\n","Epoch 31, Train Acc: 0.9117776797529775, Val Acc: 0.9027777777777778\n","Epoch 32, Train Acc: 0.9104543449492721, Val Acc: 0.9067460317460317\n","Epoch 33, Train Acc: 0.9179532421702691, Val Acc: 0.8988095238095238\n","Epoch 34, Train Acc: 0.9168504631671813, Val Acc: 0.8968253968253969\n","Epoch 35, Train Acc: 0.9188354653727393, Val Acc: 0.8928571428571429\n","Epoch 36, Train Acc: 0.9208204675782973, Val Acc: 0.9146825396825397\n","Epoch 37, Train Acc: 0.9188354653727393, Val Acc: 0.9027777777777778\n","Epoch 38, Train Acc: 0.9234671371857079, Val Acc: 0.8988095238095238\n","Epoch 39, Train Acc: 0.9272165857962065, Val Acc: 0.9047619047619048\n","Epoch 40, Train Acc: 0.9307454786060874, Val Acc: 0.8988095238095238\n","Epoch 41, Train Acc: 0.9190560211733568, Val Acc: 0.9047619047619048\n","Epoch 42, Train Acc: 0.9186149095721218, Val Acc: 0.9027777777777778\n","Epoch 43, Train Acc: 0.9228054697838554, Val Acc: 0.9087301587301587\n","Epoch 44, Train Acc: 0.9307454786060874, Val Acc: 0.9087301587301587\n","Epoch 45, Train Acc: 0.9344949272165858, Val Acc: 0.9087301587301587\n","Epoch 46, Train Acc: 0.9245699161887958, Val Acc: 0.9067460317460317\n","Epoch 47, Train Acc: 0.927878253198059, Val Acc: 0.9087301587301587\n","Epoch 48, Train Acc: 0.9265549183943538, Val Acc: 0.9246031746031746\n","Epoch 49, Train Acc: 0.9325099250110278, Val Acc: 0.9107142857142857\n","Epoch 50, Train Acc: 0.9351565946184385, Val Acc: 0.9285714285714286\n","Epoch 51, Train Acc: 0.9318482576091751, Val Acc: 0.9126984126984127\n","Epoch 52, Train Acc: 0.9347154830172033, Val Acc: 0.9246031746031746\n","Epoch 53, Train Acc: 0.9331715924128805, Val Acc: 0.9186507936507936\n","Epoch 54, Train Acc: 0.9375827084252316, Val Acc: 0.9146825396825397\n","Epoch 55, Train Acc: 0.9300838112042347, Val Acc: 0.9246031746031746\n","Epoch 56, Train Acc: 0.9400088222320248, Val Acc: 0.9186507936507936\n","Epoch 57, Train Acc: 0.9437582708425232, Val Acc: 0.9226190476190477\n","Epoch 58, Train Acc: 0.9382443758270842, Val Acc: 0.9186507936507936\n","Epoch 59, Train Acc: 0.9360388178209087, Val Acc: 0.9166666666666666\n","Epoch 60, Train Acc: 0.9406704896338773, Val Acc: 0.9226190476190477\n","Epoch 61, Train Acc: 0.9395677106307896, Val Acc: 0.9126984126984127\n","Epoch 62, Train Acc: 0.9450816056462285, Val Acc: 0.9146825396825397\n","Epoch 63, Train Acc: 0.9422143802382003, Val Acc: 0.9345238095238095\n","Epoch 64, Train Acc: 0.9378032642258491, Val Acc: 0.9246031746031746\n","Epoch 65, Train Acc: 0.9400088222320248, Val Acc: 0.9146825396825397\n","Epoch 66, Train Acc: 0.9351565946184385, Val Acc: 0.9226190476190477\n","Epoch 67, Train Acc: 0.9338332598147331, Val Acc: 0.9285714285714286\n","Epoch 68, Train Acc: 0.9424349360388178, Val Acc: 0.9325396825396826\n","Epoch 69, Train Acc: 0.9375827084252316, Val Acc: 0.9265873015873016\n","Epoch 70, Train Acc: 0.9327304808116453, Val Acc: 0.9345238095238095\n","Epoch 71, Train Acc: 0.9247904719894133, Val Acc: 0.9166666666666666\n","Epoch 72, Train Acc: 0.9327304808116453, Val Acc: 0.9325396825396826\n","Epoch 73, Train Acc: 0.940891045434495, Val Acc: 0.9285714285714286\n","Epoch 74, Train Acc: 0.9450816056462285, Val Acc: 0.9285714285714286\n","Epoch 75, Train Acc: 0.9402293780326423, Val Acc: 0.9166666666666666\n","Epoch 76, Train Acc: 0.9424349360388178, Val Acc: 0.9285714285714286\n","Epoch 77, Train Acc: 0.9402293780326423, Val Acc: 0.9246031746031746\n","Epoch 78, Train Acc: 0.9419938244375827, Val Acc: 0.9464285714285714\n","Epoch 79, Train Acc: 0.9499338332598147, Val Acc: 0.9265873015873016\n","Epoch 80, Train Acc: 0.9453021614468461, Val Acc: 0.9325396825396826\n","Epoch 81, Train Acc: 0.9411116012351125, Val Acc: 0.9285714285714286\n","Epoch 82, Train Acc: 0.9435377150419056, Val Acc: 0.9305555555555556\n","Epoch 83, Train Acc: 0.9481693868548743, Val Acc: 0.9365079365079365\n","Epoch 84, Train Acc: 0.9483899426554918, Val Acc: 0.9325396825396826\n","Epoch 85, Train Acc: 0.9446404940449934, Val Acc: 0.9265873015873016\n","Epoch 86, Train Acc: 0.9481693868548743, Val Acc: 0.9404761904761905\n","Epoch 87, Train Acc: 0.943317159241288, Val Acc: 0.9404761904761905\n","Epoch 88, Train Acc: 0.9525805028672254, Val Acc: 0.9365079365079365\n","Epoch 89, Train Acc: 0.9455227172474636, Val Acc: 0.9384920634920635\n","Epoch 90, Train Acc: 0.9406704896338773, Val Acc: 0.9265873015873016\n","Epoch 91, Train Acc: 0.9435377150419056, Val Acc: 0.9265873015873016\n","Epoch 92, Train Acc: 0.9426554918394354, Val Acc: 0.9246031746031746\n","Epoch 93, Train Acc: 0.9481693868548743, Val Acc: 0.9345238095238095\n","Epoch 94, Train Acc: 0.9490516100573445, Val Acc: 0.9365079365079365\n","Epoch 95, Train Acc: 0.9505955006616674, Val Acc: 0.9285714285714286\n","Epoch 96, Train Acc: 0.950816056462285, Val Acc: 0.9384920634920635\n","Epoch 97, Train Acc: 0.9510366122629025, Val Acc: 0.9365079365079365\n","Epoch 98, Train Acc: 0.9457432730480811, Val Acc: 0.9345238095238095\n","Epoch 99, Train Acc: 0.9424349360388178, Val Acc: 0.9325396825396826\n","Epoch 100, Train Acc: 0.9358182620202912, Val Acc: 0.9365079365079365\n","Epoch 101, Train Acc: 0.948831054256727, Val Acc: 0.9365079365079365\n","Epoch 102, Train Acc: 0.9400088222320248, Val Acc: 0.9265873015873016\n","Epoch 103, Train Acc: 0.9446404940449934, Val Acc: 0.9265873015873016\n","Epoch 104, Train Acc: 0.9497132774591972, Val Acc: 0.9305555555555556\n","Epoch 105, Train Acc: 0.9475077194530216, Val Acc: 0.9424603174603174\n","Epoch 106, Train Acc: 0.9481693868548743, Val Acc: 0.9226190476190477\n","Epoch 107, Train Acc: 0.9494927216585797, Val Acc: 0.9384920634920635\n","Epoch 108, Train Acc: 0.9486104984561093, Val Acc: 0.9325396825396826\n","Epoch 109, Train Acc: 0.9516982796647552, Val Acc: 0.9484126984126984\n","Epoch 110, Train Acc: 0.950816056462285, Val Acc: 0.9404761904761905\n","Epoch 111, Train Acc: 0.9481693868548743, Val Acc: 0.9365079365079365\n","Epoch 112, Train Acc: 0.9514777238641376, Val Acc: 0.9345238095238095\n","Epoch 113, Train Acc: 0.9512571680635201, Val Acc: 0.9404761904761905\n","Epoch 114, Train Acc: 0.9475077194530216, Val Acc: 0.9285714285714286\n","Epoch 115, Train Acc: 0.9501543890604323, Val Acc: 0.9365079365079365\n","Epoch 116, Train Acc: 0.9550066166740185, Val Acc: 0.9404761904761905\n","Epoch 117, Train Acc: 0.9525805028672254, Val Acc: 0.9345238095238095\n","Epoch 118, Train Acc: 0.9424349360388178, Val Acc: 0.9384920634920635\n","Epoch 119, Train Acc: 0.9464049404499338, Val Acc: 0.9365079365079365\n","Epoch 120, Train Acc: 0.9543449492721658, Val Acc: 0.9365079365079365\n","Epoch 121, Train Acc: 0.956771063078959, Val Acc: 0.9265873015873016\n","Epoch 122, Train Acc: 0.9521393912659903, Val Acc: 0.9404761904761905\n","Epoch 123, Train Acc: 0.9556682840758712, Val Acc: 0.9464285714285714\n","Epoch 124, Train Acc: 0.9455227172474636, Val Acc: 0.9285714285714286\n","Epoch 125, Train Acc: 0.9510366122629025, Val Acc: 0.9365079365079365\n","Epoch 126, Train Acc: 0.9494927216585797, Val Acc: 0.9365079365079365\n","Epoch 127, Train Acc: 0.9539038376709308, Val Acc: 0.9384920634920635\n","Epoch 128, Train Acc: 0.949272165857962, Val Acc: 0.9444444444444444\n","Epoch 129, Train Acc: 0.9536832818703131, Val Acc: 0.9265873015873016\n","Epoch 130, Train Acc: 0.9574327304808117, Val Acc: 0.9226190476190477\n","Epoch 131, Train Acc: 0.9512571680635201, Val Acc: 0.9444444444444444\n","Epoch 132, Train Acc: 0.9503749448610499, Val Acc: 0.9384920634920635\n","Epoch 133, Train Acc: 0.9470666078517865, Val Acc: 0.9325396825396826\n","Epoch 134, Train Acc: 0.9521393912659903, Val Acc: 0.9285714285714286\n","Epoch 135, Train Acc: 0.9510366122629025, Val Acc: 0.9424603174603174\n","Epoch 136, Train Acc: 0.948831054256727, Val Acc: 0.9424603174603174\n","Epoch 137, Train Acc: 0.9479488310542568, Val Acc: 0.9444444444444444\n","Epoch 138, Train Acc: 0.954786060873401, Val Acc: 0.9523809523809523\n","Epoch 139, Train Acc: 0.9541243934715483, Val Acc: 0.9464285714285714\n","Epoch 140, Train Acc: 0.9523599470666079, Val Acc: 0.9444444444444444\n","Epoch 141, Train Acc: 0.9497132774591972, Val Acc: 0.9464285714285714\n","Epoch 142, Train Acc: 0.9494927216585797, Val Acc: 0.9464285714285714\n","Epoch 143, Train Acc: 0.9550066166740185, Val Acc: 0.9484126984126984\n","Epoch 144, Train Acc: 0.9611821790913101, Val Acc: 0.9464285714285714\n","Epoch 145, Train Acc: 0.9477282752536391, Val Acc: 0.9404761904761905\n","Epoch 146, Train Acc: 0.9464049404499338, Val Acc: 0.9424603174603174\n","Epoch 147, Train Acc: 0.9523599470666079, Val Acc: 0.9523809523809523\n","Epoch 148, Train Acc: 0.9558888398764888, Val Acc: 0.9464285714285714\n","Epoch 149, Train Acc: 0.9556682840758712, Val Acc: 0.9444444444444444\n","Epoch 150, Train Acc: 0.9605205116894574, Val Acc: 0.9444444444444444\n","Epoch 151, Train Acc: 0.9580943978826643, Val Acc: 0.9384920634920635\n","Epoch 152, Train Acc: 0.9499338332598147, Val Acc: 0.9583333333333334\n","Epoch 153, Train Acc: 0.9530216144684606, Val Acc: 0.9404761904761905\n","Epoch 154, Train Acc: 0.9536832818703131, Val Acc: 0.9345238095238095\n","Epoch 155, Train Acc: 0.9558888398764888, Val Acc: 0.9384920634920635\n","Epoch 156, Train Acc: 0.9625055138950155, Val Acc: 0.9365079365079365\n","Epoch 157, Train Acc: 0.950816056462285, Val Acc: 0.9404761904761905\n","Epoch 158, Train Acc: 0.9499338332598147, Val Acc: 0.9523809523809523\n","Epoch 159, Train Acc: 0.9545655050727834, Val Acc: 0.9424603174603174\n","Epoch 160, Train Acc: 0.9605205116894574, Val Acc: 0.9384920634920635\n","Epoch 161, Train Acc: 0.9475077194530216, Val Acc: 0.9444444444444444\n","Epoch 162, Train Acc: 0.9375827084252316, Val Acc: 0.9484126984126984\n","Epoch 163, Train Acc: 0.9439788266431407, Val Acc: 0.9424603174603174\n","Epoch 164, Train Acc: 0.948831054256727, Val Acc: 0.9345238095238095\n","Epoch 165, Train Acc: 0.9589766210851345, Val Acc: 0.9523809523809523\n","Epoch 166, Train Acc: 0.9580943978826643, Val Acc: 0.9404761904761905\n","Epoch 167, Train Acc: 0.9499338332598147, Val Acc: 0.9424603174603174\n","Epoch 168, Train Acc: 0.9514777238641376, Val Acc: 0.9384920634920635\n","Epoch 169, Train Acc: 0.949272165857962, Val Acc: 0.9464285714285714\n","Epoch 170, Train Acc: 0.9521393912659903, Val Acc: 0.9285714285714286\n","Epoch 171, Train Acc: 0.9510366122629025, Val Acc: 0.9384920634920635\n","Epoch 172, Train Acc: 0.9424349360388178, Val Acc: 0.9484126984126984\n","Epoch 173, Train Acc: 0.950816056462285, Val Acc: 0.9305555555555556\n","Epoch 174, Train Acc: 0.9475077194530216, Val Acc: 0.9464285714285714\n","Epoch 175, Train Acc: 0.9561093956771063, Val Acc: 0.9305555555555556\n","Epoch 176, Train Acc: 0.9565505072783415, Val Acc: 0.9325396825396826\n","Epoch 177, Train Acc: 0.9565505072783415, Val Acc: 0.9444444444444444\n","Epoch 178, Train Acc: 0.9576532862814292, Val Acc: 0.9464285714285714\n","Epoch 179, Train Acc: 0.956771063078959, Val Acc: 0.9285714285714286\n","Epoch 180, Train Acc: 0.957212174680194, Val Acc: 0.9265873015873016\n","Epoch 181, Train Acc: 0.9550066166740185, Val Acc: 0.9325396825396826\n","Epoch 182, Train Acc: 0.958756065284517, Val Acc: 0.9444444444444444\n","Epoch 183, Train Acc: 0.9457432730480811, Val Acc: 0.9384920634920635\n","Epoch 184, Train Acc: 0.9528010586678429, Val Acc: 0.9444444444444444\n","Epoch 185, Train Acc: 0.9397882664314071, Val Acc: 0.9345238095238095\n","Epoch 186, Train Acc: 0.9499338332598147, Val Acc: 0.9325396825396826\n","Epoch 187, Train Acc: 0.9510366122629025, Val Acc: 0.9424603174603174\n","Epoch 188, Train Acc: 0.9483899426554918, Val Acc: 0.9365079365079365\n","Epoch 189, Train Acc: 0.954786060873401, Val Acc: 0.9444444444444444\n","Epoch 190, Train Acc: 0.9532421702690781, Val Acc: 0.9206349206349206\n","Epoch 191, Train Acc: 0.9554477282752536, Val Acc: 0.9404761904761905\n","Epoch 192, Train Acc: 0.948831054256727, Val Acc: 0.9424603174603174\n","Epoch 193, Train Acc: 0.9532421702690781, Val Acc: 0.9404761904761905\n","Epoch 194, Train Acc: 0.9505955006616674, Val Acc: 0.9464285714285714\n","Epoch 195, Train Acc: 0.9583149536832819, Val Acc: 0.9444444444444444\n","Epoch 196, Train Acc: 0.9501543890604323, Val Acc: 0.9226190476190477\n","Epoch 197, Train Acc: 0.950816056462285, Val Acc: 0.9543650793650794\n","Epoch 198, Train Acc: 0.9561093956771063, Val Acc: 0.9384920634920635\n","Epoch 199, Train Acc: 0.9611821790913101, Val Acc: 0.9464285714285714\n","Epoch 200, Train Acc: 0.9528010586678429, Val Acc: 0.9424603174603174\n","Epoch 201, Train Acc: 0.9594177326863697, Val Acc: 0.9404761904761905\n","Epoch 202, Train Acc: 0.956771063078959, Val Acc: 0.9345238095238095\n","Epoch 203, Train Acc: 0.9552271724746361, Val Acc: 0.9424603174603174\n","Epoch 204, Train Acc: 0.9609616232906926, Val Acc: 0.9444444444444444\n","Epoch 205, Train Acc: 0.9528010586678429, Val Acc: 0.9384920634920635\n","Epoch 206, Train Acc: 0.9563299514777238, Val Acc: 0.9384920634920635\n","Epoch 207, Train Acc: 0.9499338332598147, Val Acc: 0.9285714285714286\n","Epoch 208, Train Acc: 0.9490516100573445, Val Acc: 0.9305555555555556\n","Epoch 209, Train Acc: 0.9534627260696956, Val Acc: 0.9325396825396826\n","Epoch 210, Train Acc: 0.9516982796647552, Val Acc: 0.9424603174603174\n","Epoch 211, Train Acc: 0.9574327304808117, Val Acc: 0.9384920634920635\n","Epoch 212, Train Acc: 0.9580943978826643, Val Acc: 0.9424603174603174\n","Epoch 213, Train Acc: 0.9490516100573445, Val Acc: 0.9444444444444444\n","Epoch 214, Train Acc: 0.9523599470666079, Val Acc: 0.9444444444444444\n","Epoch 215, Train Acc: 0.9574327304808117, Val Acc: 0.9384920634920635\n","Epoch 216, Train Acc: 0.9574327304808117, Val Acc: 0.9384920634920635\n","Epoch 217, Train Acc: 0.9611821790913101, Val Acc: 0.9384920634920635\n","Epoch 218, Train Acc: 0.9516982796647552, Val Acc: 0.9444444444444444\n","Epoch 219, Train Acc: 0.9554477282752536, Val Acc: 0.9523809523809523\n","Epoch 220, Train Acc: 0.9591971768857521, Val Acc: 0.9503968253968254\n","Epoch 221, Train Acc: 0.9653727393030437, Val Acc: 0.9384920634920635\n","Epoch 222, Train Acc: 0.9618438464931628, Val Acc: 0.9404761904761905\n","Epoch 223, Train Acc: 0.9530216144684606, Val Acc: 0.9603174603174603\n","Epoch 224, Train Acc: 0.9483899426554918, Val Acc: 0.9424603174603174\n","Epoch 225, Train Acc: 0.957212174680194, Val Acc: 0.9444444444444444\n","Epoch 226, Train Acc: 0.958756065284517, Val Acc: 0.9345238095238095\n","Epoch 227, Train Acc: 0.9521393912659903, Val Acc: 0.9464285714285714\n","Epoch 228, Train Acc: 0.9539038376709308, Val Acc: 0.9484126984126984\n","Epoch 229, Train Acc: 0.9519188354653727, Val Acc: 0.9424603174603174\n","Epoch 230, Train Acc: 0.9600794000882223, Val Acc: 0.9424603174603174\n","Epoch 231, Train Acc: 0.9510366122629025, Val Acc: 0.9484126984126984\n","Epoch 232, Train Acc: 0.9483899426554918, Val Acc: 0.9365079365079365\n","Epoch 233, Train Acc: 0.9521393912659903, Val Acc: 0.9484126984126984\n","Epoch 234, Train Acc: 0.9512571680635201, Val Acc: 0.9464285714285714\n","Epoch 235, Train Acc: 0.9583149536832819, Val Acc: 0.9424603174603174\n","Epoch 236, Train Acc: 0.9525805028672254, Val Acc: 0.9464285714285714\n","Epoch 237, Train Acc: 0.9510366122629025, Val Acc: 0.9444444444444444\n","Epoch 238, Train Acc: 0.9600794000882223, Val Acc: 0.9523809523809523\n","Epoch 239, Train Acc: 0.9576532862814292, Val Acc: 0.9444444444444444\n","Epoch 240, Train Acc: 0.9631671812968681, Val Acc: 0.9484126984126984\n","Epoch 241, Train Acc: 0.9501543890604323, Val Acc: 0.9384920634920635\n","Epoch 242, Train Acc: 0.950816056462285, Val Acc: 0.9563492063492064\n","Epoch 243, Train Acc: 0.9611821790913101, Val Acc: 0.9424603174603174\n","Epoch 244, Train Acc: 0.9638288486987208, Val Acc: 0.9523809523809523\n","Epoch 245, Train Acc: 0.9602999558888399, Val Acc: 0.9503968253968254\n","Epoch 246, Train Acc: 0.9521393912659903, Val Acc: 0.9345238095238095\n","Epoch 247, Train Acc: 0.954786060873401, Val Acc: 0.9484126984126984\n","Epoch 248, Train Acc: 0.9618438464931628, Val Acc: 0.9404761904761905\n","Epoch 249, Train Acc: 0.9558888398764888, Val Acc: 0.9523809523809523\n","Best Training Accuracy for Fold 7: 0.9530216144684606\n","Best Validation Accuracy for Fold 7: 0.9603174603174603\n","Classification Report for Fold 7:\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.95      0.95       249\n","           1       0.95      0.95      0.95       255\n","\n","    accuracy                           0.95       504\n","   macro avg       0.95      0.95      0.95       504\n","weighted avg       0.95      0.95      0.95       504\n","\n","Fold 8\n","Epoch 0, Train Acc: 0.6490957212174681, Val Acc: 0.6666666666666666\n","Epoch 1, Train Acc: 0.7007057785619761, Val Acc: 0.7182539682539683\n","Epoch 2, Train Acc: 0.7344508160564622, Val Acc: 0.7281746031746031\n","Epoch 3, Train Acc: 0.7573886193206881, Val Acc: 0.7440476190476191\n","Epoch 4, Train Acc: 0.7554036171151302, Val Acc: 0.7400793650793651\n","Epoch 5, Train Acc: 0.7765769739744155, Val Acc: 0.746031746031746\n","Epoch 6, Train Acc: 0.7900308778120865, Val Acc: 0.7718253968253969\n","Epoch 7, Train Acc: 0.7953242170269078, Val Acc: 0.7599206349206349\n","Epoch 8, Train Acc: 0.8107631230701368, Val Acc: 0.7916666666666666\n","Epoch 9, Train Acc: 0.8187031318923688, Val Acc: 0.7956349206349206\n","Epoch 10, Train Acc: 0.8217909131010146, Val Acc: 0.8154761904761905\n","Epoch 11, Train Acc: 0.8295103661226291, Val Acc: 0.8095238095238095\n","Epoch 12, Train Acc: 0.8425231583590649, Val Acc: 0.8035714285714286\n","Epoch 13, Train Acc: 0.8385531539479488, Val Acc: 0.7876984126984127\n","Epoch 14, Train Acc: 0.8546537273930305, Val Acc: 0.8055555555555556\n","Epoch 15, Train Acc: 0.8603881782090869, Val Acc: 0.8194444444444444\n","Epoch 16, Train Acc: 0.8678870754300838, Val Acc: 0.8392857142857143\n","Epoch 17, Train Acc: 0.8641376268195854, Val Acc: 0.8531746031746031\n","Epoch 18, Train Acc: 0.8720776356418174, Val Acc: 0.8333333333333334\n","Epoch 19, Train Acc: 0.8806793118659021, Val Acc: 0.8392857142857143\n","Epoch 20, Train Acc: 0.8749448610498456, Val Acc: 0.8511904761904762\n","Epoch 21, Train Acc: 0.8868548742831937, Val Acc: 0.8591269841269841\n","Epoch 22, Train Acc: 0.8833259814733128, Val Acc: 0.8630952380952381\n","Epoch 23, Train Acc: 0.8943537715041906, Val Acc: 0.8571428571428571\n","Epoch 24, Train Acc: 0.8930304367004852, Val Acc: 0.8650793650793651\n","Epoch 25, Train Acc: 0.8892809880899868, Val Acc: 0.8888888888888888\n","Epoch 26, Train Acc: 0.8974415527128363, Val Acc: 0.8670634920634921\n","Epoch 27, Train Acc: 0.8945743273048081, Val Acc: 0.8690476190476191\n","Epoch 28, Train Acc: 0.8925893250992502, Val Acc: 0.8888888888888888\n","Epoch 29, Train Acc: 0.9049404499338333, Val Acc: 0.876984126984127\n","Epoch 30, Train Acc: 0.898103220114689, Val Acc: 0.8630952380952381\n","Epoch 31, Train Acc: 0.9044993383325981, Val Acc: 0.9007936507936508\n","Epoch 32, Train Acc: 0.8970004411116013, Val Acc: 0.8829365079365079\n","Epoch 33, Train Acc: 0.9073665637406264, Val Acc: 0.873015873015873\n","Epoch 34, Train Acc: 0.9049404499338333, Val Acc: 0.8928571428571429\n","Epoch 35, Train Acc: 0.9133215703573004, Val Acc: 0.8988095238095238\n","Epoch 36, Train Acc: 0.9157476841640935, Val Acc: 0.8968253968253969\n","Epoch 37, Train Acc: 0.9223643581826202, Val Acc: 0.8888888888888888\n","Epoch 38, Train Acc: 0.9111160123511248, Val Acc: 0.9126984126984127\n","Epoch 39, Train Acc: 0.9102337891486546, Val Acc: 0.8928571428571429\n","Epoch 40, Train Acc: 0.9230260255844729, Val Acc: 0.8948412698412699\n","Epoch 41, Train Acc: 0.9188354653727393, Val Acc: 0.9087301587301587\n","Epoch 42, Train Acc: 0.9177326863696516, Val Acc: 0.8869047619047619\n","Epoch 43, Train Acc: 0.9208204675782973, Val Acc: 0.9146825396825397\n","Epoch 44, Train Acc: 0.9223643581826202, Val Acc: 0.8968253968253969\n","Epoch 45, Train Acc: 0.9217026907807675, Val Acc: 0.8928571428571429\n","Epoch 46, Train Acc: 0.925452139391266, Val Acc: 0.8988095238095238\n","Epoch 47, Train Acc: 0.9247904719894133, Val Acc: 0.9047619047619048\n","Epoch 48, Train Acc: 0.9234671371857079, Val Acc: 0.8968253968253969\n","Epoch 49, Train Acc: 0.9325099250110278, Val Acc: 0.8968253968253969\n","Epoch 50, Train Acc: 0.9340538156153507, Val Acc: 0.9186507936507936\n","Epoch 51, Train Acc: 0.9289810322011469, Val Acc: 0.8968253968253969\n","Epoch 52, Train Acc: 0.9276576973974415, Val Acc: 0.9146825396825397\n","Epoch 53, Train Acc: 0.9192765769739745, Val Acc: 0.9246031746031746\n","Epoch 54, Train Acc: 0.9351565946184385, Val Acc: 0.9186507936507936\n","Epoch 55, Train Acc: 0.9340538156153507, Val Acc: 0.9166666666666666\n","Epoch 56, Train Acc: 0.9322893692104103, Val Acc: 0.9265873015873016\n","Epoch 57, Train Acc: 0.927878253198059, Val Acc: 0.9226190476190477\n","Epoch 58, Train Acc: 0.9391265990295545, Val Acc: 0.9365079365079365\n","Epoch 59, Train Acc: 0.9272165857962065, Val Acc: 0.8988095238095238\n","Epoch 60, Train Acc: 0.9338332598147331, Val Acc: 0.9265873015873016\n","Epoch 61, Train Acc: 0.9404499338332598, Val Acc: 0.9226190476190477\n","Epoch 62, Train Acc: 0.9371415968239964, Val Acc: 0.9325396825396826\n","Epoch 63, Train Acc: 0.9340538156153507, Val Acc: 0.9027777777777778\n","Epoch 64, Train Acc: 0.9391265990295545, Val Acc: 0.9265873015873016\n","Epoch 65, Train Acc: 0.9378032642258491, Val Acc: 0.9087301587301587\n","Epoch 66, Train Acc: 0.9261138067931186, Val Acc: 0.9265873015873016\n","Epoch 67, Train Acc: 0.940891045434495, Val Acc: 0.9226190476190477\n","Epoch 68, Train Acc: 0.9327304808116453, Val Acc: 0.9325396825396826\n","Epoch 69, Train Acc: 0.9325099250110278, Val Acc: 0.9186507936507936\n","Epoch 70, Train Acc: 0.9406704896338773, Val Acc: 0.9384920634920635\n","Epoch 71, Train Acc: 0.9296426996029996, Val Acc: 0.9087301587301587\n","Epoch 72, Train Acc: 0.9276576973974415, Val Acc: 0.9087301587301587\n","Epoch 73, Train Acc: 0.9331715924128805, Val Acc: 0.9126984126984127\n","Epoch 74, Train Acc: 0.9360388178209087, Val Acc: 0.9206349206349206\n","Epoch 75, Train Acc: 0.9325099250110278, Val Acc: 0.9226190476190477\n","Epoch 76, Train Acc: 0.9400088222320248, Val Acc: 0.9206349206349206\n","Epoch 77, Train Acc: 0.934936038817821, Val Acc: 0.9146825396825397\n","Epoch 78, Train Acc: 0.9378032642258491, Val Acc: 0.9305555555555556\n","Epoch 79, Train Acc: 0.9367004852227614, Val Acc: 0.9166666666666666\n","Epoch 80, Train Acc: 0.9375827084252316, Val Acc: 0.9146825396825397\n","Epoch 81, Train Acc: 0.9336127040141156, Val Acc: 0.9047619047619048\n","Epoch 82, Train Acc: 0.937362152624614, Val Acc: 0.9206349206349206\n","Epoch 83, Train Acc: 0.9400088222320248, Val Acc: 0.9246031746031746\n","Epoch 84, Train Acc: 0.9393471548301721, Val Acc: 0.9206349206349206\n","Epoch 85, Train Acc: 0.935377150419056, Val Acc: 0.9246031746031746\n","Epoch 86, Train Acc: 0.9378032642258491, Val Acc: 0.9186507936507936\n","Epoch 87, Train Acc: 0.9404499338332598, Val Acc: 0.9345238095238095\n","Epoch 88, Train Acc: 0.9371415968239964, Val Acc: 0.9246031746031746\n","Epoch 89, Train Acc: 0.9384649316277018, Val Acc: 0.9265873015873016\n","Epoch 90, Train Acc: 0.9369210410233789, Val Acc: 0.9246031746031746\n","Epoch 91, Train Acc: 0.9369210410233789, Val Acc: 0.9365079365079365\n","Epoch 92, Train Acc: 0.9402293780326423, Val Acc: 0.9226190476190477\n","Epoch 93, Train Acc: 0.9464049404499338, Val Acc: 0.9265873015873016\n","Epoch 94, Train Acc: 0.935377150419056, Val Acc: 0.9285714285714286\n","Epoch 95, Train Acc: 0.9461843846493163, Val Acc: 0.9384920634920635\n","Epoch 96, Train Acc: 0.9497132774591972, Val Acc: 0.9424603174603174\n","Epoch 97, Train Acc: 0.9415527128363476, Val Acc: 0.9305555555555556\n","Epoch 98, Train Acc: 0.9419938244375827, Val Acc: 0.9305555555555556\n","Epoch 99, Train Acc: 0.9510366122629025, Val Acc: 0.9325396825396826\n","Epoch 100, Train Acc: 0.9477282752536391, Val Acc: 0.9444444444444444\n","Epoch 101, Train Acc: 0.9468460520511689, Val Acc: 0.9186507936507936\n","Epoch 102, Train Acc: 0.9457432730480811, Val Acc: 0.9246031746031746\n","Epoch 103, Train Acc: 0.940891045434495, Val Acc: 0.9265873015873016\n","Epoch 104, Train Acc: 0.9424349360388178, Val Acc: 0.9206349206349206\n","Epoch 105, Train Acc: 0.9344949272165858, Val Acc: 0.9285714285714286\n","Epoch 106, Train Acc: 0.9464049404499338, Val Acc: 0.9226190476190477\n","Epoch 107, Train Acc: 0.9435377150419056, Val Acc: 0.9365079365079365\n","Epoch 108, Train Acc: 0.9505955006616674, Val Acc: 0.9206349206349206\n","Epoch 109, Train Acc: 0.943317159241288, Val Acc: 0.9325396825396826\n","Epoch 110, Train Acc: 0.9415527128363476, Val Acc: 0.9325396825396826\n","Epoch 111, Train Acc: 0.9497132774591972, Val Acc: 0.9246031746031746\n","Epoch 112, Train Acc: 0.9512571680635201, Val Acc: 0.9345238095238095\n","Epoch 113, Train Acc: 0.9457432730480811, Val Acc: 0.9325396825396826\n","Epoch 114, Train Acc: 0.942876047640053, Val Acc: 0.9365079365079365\n","Epoch 115, Train Acc: 0.9444199382443759, Val Acc: 0.9285714285714286\n","Epoch 116, Train Acc: 0.9468460520511689, Val Acc: 0.9305555555555556\n","Epoch 117, Train Acc: 0.9406704896338773, Val Acc: 0.9265873015873016\n","Epoch 118, Train Acc: 0.9448610498456109, Val Acc: 0.9523809523809523\n","Epoch 119, Train Acc: 0.9453021614468461, Val Acc: 0.9523809523809523\n","Epoch 120, Train Acc: 0.9481693868548743, Val Acc: 0.9444444444444444\n","Epoch 121, Train Acc: 0.9497132774591972, Val Acc: 0.9365079365079365\n","Epoch 122, Train Acc: 0.9481693868548743, Val Acc: 0.9404761904761905\n","Epoch 123, Train Acc: 0.942876047640053, Val Acc: 0.9563492063492064\n","Epoch 124, Train Acc: 0.9486104984561093, Val Acc: 0.9285714285714286\n","Epoch 125, Train Acc: 0.9472871636524041, Val Acc: 0.9285714285714286\n","Epoch 126, Train Acc: 0.9437582708425232, Val Acc: 0.9424603174603174\n","Epoch 127, Train Acc: 0.9501543890604323, Val Acc: 0.9523809523809523\n","Epoch 128, Train Acc: 0.9486104984561093, Val Acc: 0.9206349206349206\n","Epoch 129, Train Acc: 0.9406704896338773, Val Acc: 0.9285714285714286\n","Epoch 130, Train Acc: 0.9516982796647552, Val Acc: 0.9325396825396826\n","Epoch 131, Train Acc: 0.9393471548301721, Val Acc: 0.9226190476190477\n","Epoch 132, Train Acc: 0.9459638288486987, Val Acc: 0.9325396825396826\n","Epoch 133, Train Acc: 0.9430966034406705, Val Acc: 0.9444444444444444\n","Epoch 134, Train Acc: 0.9411116012351125, Val Acc: 0.9305555555555556\n","Epoch 135, Train Acc: 0.9340538156153507, Val Acc: 0.9166666666666666\n","Epoch 136, Train Acc: 0.9523599470666079, Val Acc: 0.9384920634920635\n","Epoch 137, Train Acc: 0.9448610498456109, Val Acc: 0.9345238095238095\n","Epoch 138, Train Acc: 0.9501543890604323, Val Acc: 0.9384920634920635\n","Epoch 139, Train Acc: 0.9497132774591972, Val Acc: 0.9384920634920635\n","Epoch 140, Train Acc: 0.948831054256727, Val Acc: 0.9424603174603174\n","Epoch 141, Train Acc: 0.9512571680635201, Val Acc: 0.9384920634920635\n","Epoch 142, Train Acc: 0.9499338332598147, Val Acc: 0.9345238095238095\n","Epoch 143, Train Acc: 0.9364799294221438, Val Acc: 0.9404761904761905\n","Epoch 144, Train Acc: 0.9404499338332598, Val Acc: 0.9384920634920635\n","Epoch 145, Train Acc: 0.940891045434495, Val Acc: 0.9543650793650794\n","Epoch 146, Train Acc: 0.9516982796647552, Val Acc: 0.9464285714285714\n","Epoch 147, Train Acc: 0.9468460520511689, Val Acc: 0.9484126984126984\n","Epoch 148, Train Acc: 0.9393471548301721, Val Acc: 0.9623015873015873\n","Epoch 149, Train Acc: 0.9464049404499338, Val Acc: 0.9583333333333334\n","Epoch 150, Train Acc: 0.954786060873401, Val Acc: 0.9523809523809523\n","Epoch 151, Train Acc: 0.950816056462285, Val Acc: 0.9384920634920635\n","Epoch 152, Train Acc: 0.9521393912659903, Val Acc: 0.9523809523809523\n","Epoch 153, Train Acc: 0.950816056462285, Val Acc: 0.9543650793650794\n","Epoch 154, Train Acc: 0.9541243934715483, Val Acc: 0.9345238095238095\n","Epoch 155, Train Acc: 0.9393471548301721, Val Acc: 0.9305555555555556\n","Epoch 156, Train Acc: 0.9378032642258491, Val Acc: 0.9424603174603174\n","Epoch 157, Train Acc: 0.9479488310542568, Val Acc: 0.9345238095238095\n","Epoch 158, Train Acc: 0.9466254962505514, Val Acc: 0.9444444444444444\n","Epoch 159, Train Acc: 0.9466254962505514, Val Acc: 0.9444444444444444\n","Epoch 160, Train Acc: 0.9483899426554918, Val Acc: 0.9464285714285714\n","Epoch 161, Train Acc: 0.9494927216585797, Val Acc: 0.9424603174603174\n","Epoch 162, Train Acc: 0.9497132774591972, Val Acc: 0.9484126984126984\n","Epoch 163, Train Acc: 0.9437582708425232, Val Acc: 0.9424603174603174\n","Epoch 164, Train Acc: 0.9501543890604323, Val Acc: 0.9305555555555556\n","Epoch 165, Train Acc: 0.9510366122629025, Val Acc: 0.9404761904761905\n","Epoch 166, Train Acc: 0.9510366122629025, Val Acc: 0.9404761904761905\n","Epoch 167, Train Acc: 0.9512571680635201, Val Acc: 0.9384920634920635\n","Epoch 168, Train Acc: 0.9497132774591972, Val Acc: 0.9444444444444444\n","Epoch 169, Train Acc: 0.9521393912659903, Val Acc: 0.9503968253968254\n","Epoch 170, Train Acc: 0.9479488310542568, Val Acc: 0.9444444444444444\n","Epoch 171, Train Acc: 0.9516982796647552, Val Acc: 0.9543650793650794\n","Epoch 172, Train Acc: 0.9569916188795765, Val Acc: 0.9404761904761905\n","Epoch 173, Train Acc: 0.9497132774591972, Val Acc: 0.9484126984126984\n","Epoch 174, Train Acc: 0.9505955006616674, Val Acc: 0.9484126984126984\n","Epoch 175, Train Acc: 0.943317159241288, Val Acc: 0.9285714285714286\n","Epoch 176, Train Acc: 0.9415527128363476, Val Acc: 0.9563492063492064\n","Epoch 177, Train Acc: 0.9503749448610499, Val Acc: 0.9404761904761905\n","Epoch 178, Train Acc: 0.9435377150419056, Val Acc: 0.9345238095238095\n","Epoch 179, Train Acc: 0.9525805028672254, Val Acc: 0.9484126984126984\n","Epoch 180, Train Acc: 0.9563299514777238, Val Acc: 0.9285714285714286\n","Epoch 181, Train Acc: 0.9539038376709308, Val Acc: 0.9345238095238095\n","Epoch 182, Train Acc: 0.9446404940449934, Val Acc: 0.9404761904761905\n","Epoch 183, Train Acc: 0.9536832818703131, Val Acc: 0.9424603174603174\n","Epoch 184, Train Acc: 0.9554477282752536, Val Acc: 0.9285714285714286\n","Epoch 185, Train Acc: 0.9477282752536391, Val Acc: 0.9444444444444444\n","Epoch 186, Train Acc: 0.9483899426554918, Val Acc: 0.9444444444444444\n","Epoch 187, Train Acc: 0.9468460520511689, Val Acc: 0.9484126984126984\n","Epoch 188, Train Acc: 0.9490516100573445, Val Acc: 0.9424603174603174\n","Epoch 189, Train Acc: 0.9481693868548743, Val Acc: 0.9404761904761905\n","Epoch 190, Train Acc: 0.9497132774591972, Val Acc: 0.9404761904761905\n","Epoch 191, Train Acc: 0.9563299514777238, Val Acc: 0.9404761904761905\n","Epoch 192, Train Acc: 0.9439788266431407, Val Acc: 0.9365079365079365\n","Epoch 193, Train Acc: 0.9466254962505514, Val Acc: 0.9424603174603174\n","Epoch 194, Train Acc: 0.9530216144684606, Val Acc: 0.9424603174603174\n","Epoch 195, Train Acc: 0.9602999558888399, Val Acc: 0.9503968253968254\n","Epoch 196, Train Acc: 0.9578738420820467, Val Acc: 0.9384920634920635\n","Epoch 197, Train Acc: 0.9591971768857521, Val Acc: 0.9345238095238095\n","Epoch 198, Train Acc: 0.9514777238641376, Val Acc: 0.9424603174603174\n","Epoch 199, Train Acc: 0.9479488310542568, Val Acc: 0.9345238095238095\n","Epoch 200, Train Acc: 0.9453021614468461, Val Acc: 0.9384920634920635\n","Epoch 201, Train Acc: 0.9435377150419056, Val Acc: 0.9424603174603174\n","Epoch 202, Train Acc: 0.9536832818703131, Val Acc: 0.9444444444444444\n","Epoch 203, Train Acc: 0.9554477282752536, Val Acc: 0.9444444444444444\n","Epoch 204, Train Acc: 0.9600794000882223, Val Acc: 0.9424603174603174\n","Epoch 205, Train Acc: 0.9583149536832819, Val Acc: 0.9503968253968254\n","Epoch 206, Train Acc: 0.948831054256727, Val Acc: 0.9404761904761905\n","Epoch 207, Train Acc: 0.9453021614468461, Val Acc: 0.9503968253968254\n","Epoch 208, Train Acc: 0.9457432730480811, Val Acc: 0.9543650793650794\n","Epoch 209, Train Acc: 0.9486104984561093, Val Acc: 0.9384920634920635\n","Epoch 210, Train Acc: 0.9331715924128805, Val Acc: 0.9365079365079365\n","Epoch 211, Train Acc: 0.9320688134097926, Val Acc: 0.9384920634920635\n","Epoch 212, Train Acc: 0.9521393912659903, Val Acc: 0.9424603174603174\n","Epoch 213, Train Acc: 0.9450816056462285, Val Acc: 0.9246031746031746\n","Epoch 214, Train Acc: 0.9459638288486987, Val Acc: 0.9523809523809523\n","Epoch 215, Train Acc: 0.954786060873401, Val Acc: 0.9424603174603174\n","Epoch 216, Train Acc: 0.9483899426554918, Val Acc: 0.9325396825396826\n","Epoch 217, Train Acc: 0.9554477282752536, Val Acc: 0.9384920634920635\n","Epoch 218, Train Acc: 0.9532421702690781, Val Acc: 0.9464285714285714\n","Epoch 219, Train Acc: 0.950816056462285, Val Acc: 0.9404761904761905\n","Epoch 220, Train Acc: 0.9534627260696956, Val Acc: 0.9444444444444444\n","Epoch 221, Train Acc: 0.9483899426554918, Val Acc: 0.9424603174603174\n","Epoch 222, Train Acc: 0.9563299514777238, Val Acc: 0.9365079365079365\n","Epoch 223, Train Acc: 0.9483899426554918, Val Acc: 0.9404761904761905\n","Epoch 224, Train Acc: 0.949272165857962, Val Acc: 0.9365079365079365\n","Epoch 225, Train Acc: 0.9415527128363476, Val Acc: 0.9424603174603174\n","Epoch 226, Train Acc: 0.9528010586678429, Val Acc: 0.9384920634920635\n","Epoch 227, Train Acc: 0.9477282752536391, Val Acc: 0.9424603174603174\n","Epoch 228, Train Acc: 0.9470666078517865, Val Acc: 0.9404761904761905\n","Epoch 229, Train Acc: 0.9536832818703131, Val Acc: 0.9384920634920635\n","Epoch 230, Train Acc: 0.957212174680194, Val Acc: 0.9503968253968254\n","Epoch 231, Train Acc: 0.9523599470666079, Val Acc: 0.9484126984126984\n","Epoch 232, Train Acc: 0.9505955006616674, Val Acc: 0.9424603174603174\n","Epoch 233, Train Acc: 0.948831054256727, Val Acc: 0.9464285714285714\n","Epoch 234, Train Acc: 0.943317159241288, Val Acc: 0.9543650793650794\n","Epoch 235, Train Acc: 0.9550066166740185, Val Acc: 0.9345238095238095\n","Epoch 236, Train Acc: 0.9550066166740185, Val Acc: 0.9365079365079365\n","Epoch 237, Train Acc: 0.9516982796647552, Val Acc: 0.9404761904761905\n","Epoch 238, Train Acc: 0.9497132774591972, Val Acc: 0.9384920634920635\n","Epoch 239, Train Acc: 0.9497132774591972, Val Acc: 0.9365079365079365\n","Epoch 240, Train Acc: 0.9446404940449934, Val Acc: 0.9444444444444444\n","Epoch 241, Train Acc: 0.9424349360388178, Val Acc: 0.9464285714285714\n","Epoch 242, Train Acc: 0.9475077194530216, Val Acc: 0.9503968253968254\n","Epoch 243, Train Acc: 0.9472871636524041, Val Acc: 0.9404761904761905\n","Epoch 244, Train Acc: 0.948831054256727, Val Acc: 0.9384920634920635\n","Epoch 245, Train Acc: 0.9561093956771063, Val Acc: 0.9444444444444444\n","Epoch 246, Train Acc: 0.9563299514777238, Val Acc: 0.9384920634920635\n","Epoch 247, Train Acc: 0.9541243934715483, Val Acc: 0.9404761904761905\n","Epoch 248, Train Acc: 0.948831054256727, Val Acc: 0.9384920634920635\n","Epoch 249, Train Acc: 0.9448610498456109, Val Acc: 0.9404761904761905\n","Best Training Accuracy for Fold 8: 0.9393471548301721\n","Best Validation Accuracy for Fold 8: 0.9623015873015873\n","Classification Report for Fold 8:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.90      0.94       262\n","           1       0.90      0.98      0.94       242\n","\n","    accuracy                           0.94       504\n","   macro avg       0.94      0.94      0.94       504\n","weighted avg       0.94      0.94      0.94       504\n","\n","Fold 9\n","Epoch 0, Train Acc: 0.6460859977949284, Val Acc: 0.7176938369781312\n","Epoch 1, Train Acc: 0.7020948180815877, Val Acc: 0.731610337972167\n","Epoch 2, Train Acc: 0.7272326350606395, Val Acc: 0.7335984095427436\n","Epoch 3, Train Acc: 0.738478500551268, Val Acc: 0.7614314115308151\n","Epoch 4, Train Acc: 0.7464167585446527, Val Acc: 0.7495029821073559\n","Epoch 5, Train Acc: 0.7647188533627343, Val Acc: 0.757455268389662\n","Epoch 6, Train Acc: 0.782800441014333, Val Acc: 0.7733598409542743\n","Epoch 7, Train Acc: 0.7916207276736494, Val Acc: 0.7773359840954275\n","Epoch 8, Train Acc: 0.804851157662624, Val Acc: 0.8011928429423459\n","Epoch 9, Train Acc: 0.8090407938257993, Val Acc: 0.7793240556660039\n","Epoch 10, Train Acc: 0.822271223814774, Val Acc: 0.8091451292246521\n","Epoch 11, Train Acc: 0.8229327453142227, Val Acc: 0.805168986083499\n","Epoch 12, Train Acc: 0.8231532524807056, Val Acc: 0.8190854870775348\n","Epoch 13, Train Acc: 0.8330760749724366, Val Acc: 0.8290258449304175\n","Epoch 14, Train Acc: 0.8449834619625137, Val Acc: 0.8469184890656064\n","Epoch 15, Train Acc: 0.8511576626240352, Val Acc: 0.827037773359841\n","Epoch 16, Train Acc: 0.8624035281146637, Val Acc: 0.8389662027833003\n","Epoch 17, Train Acc: 0.8540242557883131, Val Acc: 0.8151093439363817\n","Epoch 18, Train Acc: 0.8650496141124586, Val Acc: 0.852882703777336\n","Epoch 19, Train Acc: 0.8756339581036384, Val Acc: 0.8707753479125249\n","Epoch 20, Train Acc: 0.8721058434399118, Val Acc: 0.8707753479125249\n","Epoch 21, Train Acc: 0.8811466372657112, Val Acc: 0.8648111332007953\n","Epoch 22, Train Acc: 0.8762954796030871, Val Acc: 0.8747514910536779\n","Epoch 23, Train Acc: 0.8822491730981257, Val Acc: 0.8866799204771372\n","Epoch 24, Train Acc: 0.8773980154355017, Val Acc: 0.8866799204771372\n","Epoch 25, Train Acc: 0.8875413450937155, Val Acc: 0.8926441351888668\n","Epoch 26, Train Acc: 0.8950385887541346, Val Acc: 0.8846918489065606\n","Epoch 27, Train Acc: 0.896361631753032, Val Acc: 0.8767395626242545\n","Epoch 28, Train Acc: 0.8928335170893054, Val Acc: 0.9005964214711729\n","Epoch 29, Train Acc: 0.9034178610804852, Val Acc: 0.8866799204771372\n","Epoch 30, Train Acc: 0.893715545755237, Val Acc: 0.8866799204771372\n","Epoch 31, Train Acc: 0.8871003307607497, Val Acc: 0.8926441351888668\n","Epoch 32, Train Acc: 0.9023153252480706, Val Acc: 0.9065606361829026\n","Epoch 33, Train Acc: 0.9104740904079383, Val Acc: 0.9105367793240556\n","Epoch 34, Train Acc: 0.9095920617420066, Val Acc: 0.9085487077534792\n","Epoch 35, Train Acc: 0.9056229327453142, Val Acc: 0.9085487077534792\n","Epoch 36, Train Acc: 0.9122381477398015, Val Acc: 0.9125248508946322\n","Epoch 37, Train Acc: 0.9157662624035281, Val Acc: 0.9125248508946322\n","Epoch 38, Train Acc: 0.9071664829106946, Val Acc: 0.9105367793240556\n","Epoch 39, Train Acc: 0.9153252480705623, Val Acc: 0.8926441351888668\n","Epoch 40, Train Acc: 0.9195148842337376, Val Acc: 0.9105367793240556\n","Epoch 41, Train Acc: 0.9195148842337376, Val Acc: 0.8986083499005965\n","Epoch 42, Train Acc: 0.9186328555678059, Val Acc: 0.9244532803180915\n","Epoch 43, Train Acc: 0.9195148842337376, Val Acc: 0.9125248508946322\n","Epoch 44, Train Acc: 0.9155457552370452, Val Acc: 0.9184890656063618\n","Epoch 45, Train Acc: 0.9098125689084895, Val Acc: 0.9145129224652088\n","Epoch 46, Train Acc: 0.9177508269018743, Val Acc: 0.9324055666003976\n","Epoch 47, Train Acc: 0.9076074972436604, Val Acc: 0.9005964214711729\n","Epoch 48, Train Acc: 0.9131201764057332, Val Acc: 0.9184890656063618\n","Epoch 49, Train Acc: 0.9303197353914002, Val Acc: 0.9065606361829026\n","Epoch 50, Train Acc: 0.9259095920617421, Val Acc: 0.9204771371769384\n","Epoch 51, Train Acc: 0.9298787210584344, Val Acc: 0.9224652087475149\n","Epoch 52, Train Acc: 0.9162072767364939, Val Acc: 0.9145129224652088\n","Epoch 53, Train Acc: 0.9281146637265711, Val Acc: 0.8986083499005965\n","Epoch 54, Train Acc: 0.9248070562293275, Val Acc: 0.9085487077534792\n","Epoch 55, Train Acc: 0.9197353914002205, Val Acc: 0.9284294234592445\n","Epoch 56, Train Acc: 0.9263506063947078, Val Acc: 0.9224652087475149\n","Epoch 57, Train Acc: 0.9274531422271224, Val Acc: 0.9204771371769384\n","Epoch 58, Train Acc: 0.9303197353914002, Val Acc: 0.9264413518886679\n","Epoch 59, Train Acc: 0.9289966923925027, Val Acc: 0.9264413518886679\n","Epoch 60, Train Acc: 0.938257993384785, Val Acc: 0.9145129224652088\n","Epoch 61, Train Acc: 0.930981256890849, Val Acc: 0.9244532803180915\n","Epoch 62, Train Acc: 0.923263506063947, Val Acc: 0.9284294234592445\n","Epoch 63, Train Acc: 0.9371554575523704, Val Acc: 0.9284294234592445\n","Epoch 64, Train Acc: 0.9210584343991179, Val Acc: 0.9304174950298211\n","Epoch 65, Train Acc: 0.9281146637265711, Val Acc: 0.9343936381709742\n","Epoch 66, Train Acc: 0.9402425578831312, Val Acc: 0.9343936381709742\n","Epoch 67, Train Acc: 0.9259095920617421, Val Acc: 0.9165009940357853\n","Epoch 68, Train Acc: 0.9320837927232635, Val Acc: 0.9324055666003976\n","Epoch 69, Train Acc: 0.9369349503858876, Val Acc: 0.9284294234592445\n","Epoch 70, Train Acc: 0.9329658213891951, Val Acc: 0.9085487077534792\n","Epoch 71, Train Acc: 0.9316427783902976, Val Acc: 0.9343936381709742\n","Epoch 72, Train Acc: 0.9298787210584344, Val Acc: 0.9184890656063618\n","Epoch 73, Train Acc: 0.9292171995589856, Val Acc: 0.9284294234592445\n","Epoch 74, Train Acc: 0.9360529217199559, Val Acc: 0.9264413518886679\n","Epoch 75, Train Acc: 0.9367144432194047, Val Acc: 0.9284294234592445\n","Epoch 76, Train Acc: 0.9342888643880927, Val Acc: 0.9224652087475149\n","Epoch 77, Train Acc: 0.9263506063947078, Val Acc: 0.9264413518886679\n","Epoch 78, Train Acc: 0.9338478500551268, Val Acc: 0.9304174950298211\n","Epoch 79, Train Acc: 0.9327453142227122, Val Acc: 0.9224652087475149\n","Epoch 80, Train Acc: 0.9298787210584344, Val Acc: 0.9184890656063618\n","Epoch 81, Train Acc: 0.9353914002205072, Val Acc: 0.9403578528827038\n","Epoch 82, Train Acc: 0.9364939360529217, Val Acc: 0.9383697813121272\n","Epoch 83, Train Acc: 0.9347298787210584, Val Acc: 0.9264413518886679\n","Epoch 84, Train Acc: 0.9442116868798236, Val Acc: 0.9304174950298211\n","Epoch 85, Train Acc: 0.9353914002205072, Val Acc: 0.9105367793240556\n","Epoch 86, Train Acc: 0.9367144432194047, Val Acc: 0.9264413518886679\n","Epoch 87, Train Acc: 0.9353914002205072, Val Acc: 0.9324055666003976\n","Epoch 88, Train Acc: 0.9389195148842338, Val Acc: 0.9204771371769384\n","Epoch 89, Train Acc: 0.9373759647188533, Val Acc: 0.9324055666003976\n","Epoch 90, Train Acc: 0.938257993384785, Val Acc: 0.9304174950298211\n","Epoch 91, Train Acc: 0.9349503858875413, Val Acc: 0.9184890656063618\n","Epoch 92, Train Acc: 0.9314222712238148, Val Acc: 0.9224652087475149\n","Epoch 93, Train Acc: 0.9327453142227122, Val Acc: 0.9204771371769384\n","Epoch 94, Train Acc: 0.9303197353914002, Val Acc: 0.9145129224652088\n","Epoch 95, Train Acc: 0.9292171995589856, Val Acc: 0.9244532803180915\n","Epoch 96, Train Acc: 0.930981256890849, Val Acc: 0.9224652087475149\n","Epoch 97, Train Acc: 0.935832414553473, Val Acc: 0.9184890656063618\n","Epoch 98, Train Acc: 0.9369349503858876, Val Acc: 0.9304174950298211\n","Epoch 99, Train Acc: 0.9298787210584344, Val Acc: 0.9324055666003976\n","Epoch 100, Train Acc: 0.9307607497243661, Val Acc: 0.9304174950298211\n","Epoch 101, Train Acc: 0.940683572216097, Val Acc: 0.9224652087475149\n","Epoch 102, Train Acc: 0.9413450937155458, Val Acc: 0.9264413518886679\n","Epoch 103, Train Acc: 0.9386990077177508, Val Acc: 0.9224652087475149\n","Epoch 104, Train Acc: 0.9393605292171996, Val Acc: 0.9264413518886679\n","Epoch 105, Train Acc: 0.9444321940463065, Val Acc: 0.9244532803180915\n","Epoch 106, Train Acc: 0.9468577728776185, Val Acc: 0.9363817097415507\n","Epoch 107, Train Acc: 0.9345093715545755, Val Acc: 0.9304174950298211\n","Epoch 108, Train Acc: 0.9428886438809261, Val Acc: 0.9264413518886679\n","Epoch 109, Train Acc: 0.9466372657111356, Val Acc: 0.9324055666003976\n","Epoch 110, Train Acc: 0.9422271223814774, Val Acc: 0.9224652087475149\n","Epoch 111, Train Acc: 0.9378169790518192, Val Acc: 0.9324055666003976\n","Epoch 112, Train Acc: 0.9433296582138919, Val Acc: 0.9184890656063618\n","Epoch 113, Train Acc: 0.9402425578831312, Val Acc: 0.9264413518886679\n","Epoch 114, Train Acc: 0.9316427783902976, Val Acc: 0.9025844930417495\n","Epoch 115, Train Acc: 0.9386990077177508, Val Acc: 0.9264413518886679\n","Epoch 116, Train Acc: 0.938257993384785, Val Acc: 0.9443339960238568\n","Epoch 117, Train Acc: 0.9386990077177508, Val Acc: 0.9383697813121272\n","Epoch 118, Train Acc: 0.9404630650496141, Val Acc: 0.9343936381709742\n","Epoch 119, Train Acc: 0.9369349503858876, Val Acc: 0.9304174950298211\n","Epoch 120, Train Acc: 0.9347298787210584, Val Acc: 0.9324055666003976\n","Epoch 121, Train Acc: 0.9446527012127894, Val Acc: 0.9244532803180915\n","Epoch 122, Train Acc: 0.9422271223814774, Val Acc: 0.9423459244532804\n","Epoch 123, Train Acc: 0.9439911797133407, Val Acc: 0.9403578528827038\n","Epoch 124, Train Acc: 0.9457552370452039, Val Acc: 0.9363817097415507\n","Epoch 125, Train Acc: 0.9417861080485116, Val Acc: 0.9343936381709742\n","Epoch 126, Train Acc: 0.9303197353914002, Val Acc: 0.9184890656063618\n","Epoch 127, Train Acc: 0.9424476295479604, Val Acc: 0.9383697813121272\n","Epoch 128, Train Acc: 0.9435501653803748, Val Acc: 0.9343936381709742\n","Epoch 129, Train Acc: 0.9404630650496141, Val Acc: 0.9284294234592445\n","Epoch 130, Train Acc: 0.9398015435501654, Val Acc: 0.9403578528827038\n","Epoch 131, Train Acc: 0.9442116868798236, Val Acc: 0.9443339960238568\n","Epoch 132, Train Acc: 0.9464167585446527, Val Acc: 0.9224652087475149\n","Epoch 133, Train Acc: 0.9470782800441014, Val Acc: 0.9324055666003976\n","Epoch 134, Train Acc: 0.9466372657111356, Val Acc: 0.9165009940357853\n","Epoch 135, Train Acc: 0.9402425578831312, Val Acc: 0.9244532803180915\n","Epoch 136, Train Acc: 0.9442116868798236, Val Acc: 0.9423459244532804\n","Epoch 137, Train Acc: 0.9466372657111356, Val Acc: 0.9304174950298211\n","Epoch 138, Train Acc: 0.9362734288864388, Val Acc: 0.9403578528827038\n","Epoch 139, Train Acc: 0.943109151047409, Val Acc: 0.9324055666003976\n","Epoch 140, Train Acc: 0.9371554575523704, Val Acc: 0.9383697813121272\n","Epoch 141, Train Acc: 0.940683572216097, Val Acc: 0.9324055666003976\n","Epoch 142, Train Acc: 0.9444321940463065, Val Acc: 0.94831013916501\n","Epoch 143, Train Acc: 0.9464167585446527, Val Acc: 0.9403578528827038\n","Epoch 144, Train Acc: 0.9398015435501654, Val Acc: 0.9383697813121272\n","Epoch 145, Train Acc: 0.943109151047409, Val Acc: 0.9184890656063618\n","Epoch 146, Train Acc: 0.9424476295479604, Val Acc: 0.9403578528827038\n","Epoch 147, Train Acc: 0.9468577728776185, Val Acc: 0.94831013916501\n","Epoch 148, Train Acc: 0.948180815876516, Val Acc: 0.9423459244532804\n","Epoch 149, Train Acc: 0.9424476295479604, Val Acc: 0.9403578528827038\n","Epoch 150, Train Acc: 0.9461962513781698, Val Acc: 0.9324055666003976\n","Epoch 151, Train Acc: 0.9448732083792724, Val Acc: 0.9443339960238568\n","Epoch 152, Train Acc: 0.9437706725468578, Val Acc: 0.9463220675944334\n","Epoch 153, Train Acc: 0.9384785005512679, Val Acc: 0.9403578528827038\n","Epoch 154, Train Acc: 0.9448732083792724, Val Acc: 0.9443339960238568\n","Epoch 155, Train Acc: 0.9488423373759647, Val Acc: 0.9383697813121272\n","Epoch 156, Train Acc: 0.9536934950385888, Val Acc: 0.94831013916501\n","Epoch 157, Train Acc: 0.9420066152149945, Val Acc: 0.9423459244532804\n","Epoch 158, Train Acc: 0.95303197353914, Val Acc: 0.9343936381709742\n","Epoch 159, Train Acc: 0.9404630650496141, Val Acc: 0.9304174950298211\n","Epoch 160, Train Acc: 0.9402425578831312, Val Acc: 0.9184890656063618\n","Epoch 161, Train Acc: 0.940683572216097, Val Acc: 0.9463220675944334\n","Epoch 162, Train Acc: 0.9400220507166482, Val Acc: 0.9224652087475149\n","Epoch 163, Train Acc: 0.9457552370452039, Val Acc: 0.94831013916501\n","Epoch 164, Train Acc: 0.9453142227122382, Val Acc: 0.9403578528827038\n","Epoch 165, Train Acc: 0.9420066152149945, Val Acc: 0.9264413518886679\n","Epoch 166, Train Acc: 0.9428886438809261, Val Acc: 0.9383697813121272\n","Epoch 167, Train Acc: 0.9453142227122382, Val Acc: 0.9304174950298211\n","Epoch 168, Train Acc: 0.9435501653803748, Val Acc: 0.9343936381709742\n","Epoch 169, Train Acc: 0.9395810363836825, Val Acc: 0.9423459244532804\n","Epoch 170, Train Acc: 0.9488423373759647, Val Acc: 0.9383697813121272\n","Epoch 171, Train Acc: 0.9470782800441014, Val Acc: 0.9443339960238568\n","Epoch 172, Train Acc: 0.948180815876516, Val Acc: 0.9324055666003976\n","Epoch 173, Train Acc: 0.9437706725468578, Val Acc: 0.9324055666003976\n","Epoch 174, Train Acc: 0.9521499448732084, Val Acc: 0.9244532803180915\n","Epoch 175, Train Acc: 0.9534729878721059, Val Acc: 0.9383697813121272\n","Epoch 176, Train Acc: 0.9514884233737596, Val Acc: 0.9284294234592445\n","Epoch 177, Train Acc: 0.9517089305402425, Val Acc: 0.9343936381709742\n","Epoch 178, Train Acc: 0.9472987872105844, Val Acc: 0.9324055666003976\n","Epoch 179, Train Acc: 0.948180815876516, Val Acc: 0.9363817097415507\n","Epoch 180, Train Acc: 0.9435501653803748, Val Acc: 0.9363817097415507\n","Epoch 181, Train Acc: 0.9400220507166482, Val Acc: 0.9284294234592445\n","Epoch 182, Train Acc: 0.9448732083792724, Val Acc: 0.9363817097415507\n","Epoch 183, Train Acc: 0.9470782800441014, Val Acc: 0.9423459244532804\n","Epoch 184, Train Acc: 0.9448732083792724, Val Acc: 0.9403578528827038\n","Epoch 185, Train Acc: 0.9437706725468578, Val Acc: 0.9463220675944334\n","Epoch 186, Train Acc: 0.945534729878721, Val Acc: 0.9423459244532804\n","Epoch 187, Train Acc: 0.9371554575523704, Val Acc: 0.9383697813121272\n","Epoch 188, Train Acc: 0.9457552370452039, Val Acc: 0.9363817097415507\n","Epoch 189, Train Acc: 0.9373759647188533, Val Acc: 0.9324055666003976\n","Epoch 190, Train Acc: 0.9464167585446527, Val Acc: 0.9463220675944334\n","Epoch 191, Train Acc: 0.948180815876516, Val Acc: 0.9383697813121272\n","Epoch 192, Train Acc: 0.9517089305402425, Val Acc: 0.9383697813121272\n","Epoch 193, Train Acc: 0.9444321940463065, Val Acc: 0.9383697813121272\n","Epoch 194, Train Acc: 0.9411245865490628, Val Acc: 0.9343936381709742\n","Epoch 195, Train Acc: 0.9393605292171996, Val Acc: 0.9343936381709742\n","Epoch 196, Train Acc: 0.943109151047409, Val Acc: 0.9304174950298211\n","Epoch 197, Train Acc: 0.9453142227122382, Val Acc: 0.9224652087475149\n","Epoch 198, Train Acc: 0.9472987872105844, Val Acc: 0.9443339960238568\n","Epoch 199, Train Acc: 0.9437706725468578, Val Acc: 0.9423459244532804\n","Epoch 200, Train Acc: 0.9442116868798236, Val Acc: 0.9324055666003976\n","Epoch 201, Train Acc: 0.9409040793825799, Val Acc: 0.9383697813121272\n","Epoch 202, Train Acc: 0.950606394707828, Val Acc: 0.9443339960238568\n","Epoch 203, Train Acc: 0.9495038588754134, Val Acc: 0.9403578528827038\n","Epoch 204, Train Acc: 0.9523704520396913, Val Acc: 0.9403578528827038\n","Epoch 205, Train Acc: 0.9497243660418964, Val Acc: 0.9463220675944334\n","Epoch 206, Train Acc: 0.9499448732083793, Val Acc: 0.9363817097415507\n","Epoch 207, Train Acc: 0.950826901874311, Val Acc: 0.9502982107355865\n","Epoch 208, Train Acc: 0.9497243660418964, Val Acc: 0.9403578528827038\n","Epoch 209, Train Acc: 0.9470782800441014, Val Acc: 0.94831013916501\n","Epoch 210, Train Acc: 0.9501653803748622, Val Acc: 0.9304174950298211\n","Epoch 211, Train Acc: 0.9420066152149945, Val Acc: 0.94831013916501\n","Epoch 212, Train Acc: 0.9400220507166482, Val Acc: 0.9403578528827038\n","Epoch 213, Train Acc: 0.9464167585446527, Val Acc: 0.9383697813121272\n","Epoch 214, Train Acc: 0.955678059536935, Val Acc: 0.9423459244532804\n","Epoch 215, Train Acc: 0.9424476295479604, Val Acc: 0.9443339960238568\n","Epoch 216, Train Acc: 0.9468577728776185, Val Acc: 0.9324055666003976\n","Epoch 217, Train Acc: 0.9475192943770673, Val Acc: 0.9423459244532804\n","Epoch 218, Train Acc: 0.9486218302094818, Val Acc: 0.9423459244532804\n","Epoch 219, Train Acc: 0.9459757442116868, Val Acc: 0.9443339960238568\n","Epoch 220, Train Acc: 0.9437706725468578, Val Acc: 0.9324055666003976\n","Epoch 221, Train Acc: 0.9510474090407939, Val Acc: 0.9324055666003976\n","Epoch 222, Train Acc: 0.9497243660418964, Val Acc: 0.9383697813121272\n","Epoch 223, Train Acc: 0.9444321940463065, Val Acc: 0.94831013916501\n","Epoch 224, Train Acc: 0.9446527012127894, Val Acc: 0.9264413518886679\n","Epoch 225, Train Acc: 0.950826901874311, Val Acc: 0.9443339960238568\n","Epoch 226, Train Acc: 0.9519294377067254, Val Acc: 0.9383697813121272\n","Epoch 227, Train Acc: 0.9592061742006616, Val Acc: 0.9463220675944334\n","Epoch 228, Train Acc: 0.9510474090407939, Val Acc: 0.9443339960238568\n","Epoch 229, Train Acc: 0.9510474090407939, Val Acc: 0.9284294234592445\n","Epoch 230, Train Acc: 0.948180815876516, Val Acc: 0.9383697813121272\n","Epoch 231, Train Acc: 0.9519294377067254, Val Acc: 0.9403578528827038\n","Epoch 232, Train Acc: 0.9477398015435502, Val Acc: 0.9443339960238568\n","Epoch 233, Train Acc: 0.9514884233737596, Val Acc: 0.94831013916501\n","Epoch 234, Train Acc: 0.9519294377067254, Val Acc: 0.9324055666003976\n","Epoch 235, Train Acc: 0.9475192943770673, Val Acc: 0.9343936381709742\n","Epoch 236, Train Acc: 0.9521499448732084, Val Acc: 0.9343936381709742\n","Epoch 237, Train Acc: 0.95303197353914, Val Acc: 0.9443339960238568\n","Epoch 238, Train Acc: 0.9545755237045204, Val Acc: 0.9383697813121272\n","Epoch 239, Train Acc: 0.9517089305402425, Val Acc: 0.9304174950298211\n","Epoch 240, Train Acc: 0.9528114663726571, Val Acc: 0.9383697813121272\n","Epoch 241, Train Acc: 0.9442116868798236, Val Acc: 0.9383697813121272\n","Epoch 242, Train Acc: 0.9409040793825799, Val Acc: 0.9403578528827038\n","Epoch 243, Train Acc: 0.9519294377067254, Val Acc: 0.9343936381709742\n","Epoch 244, Train Acc: 0.9486218302094818, Val Acc: 0.9423459244532804\n","Epoch 245, Train Acc: 0.9521499448732084, Val Acc: 0.9403578528827038\n","Epoch 246, Train Acc: 0.948180815876516, Val Acc: 0.9463220675944334\n","Epoch 247, Train Acc: 0.9536934950385888, Val Acc: 0.9423459244532804\n","Epoch 248, Train Acc: 0.9437706725468578, Val Acc: 0.9443339960238568\n","Epoch 249, Train Acc: 0.950606394707828, Val Acc: 0.9443339960238568\n","Best Training Accuracy for Fold 9: 0.950826901874311\n","Best Validation Accuracy for Fold 9: 0.9502982107355865\n","Classification Report for Fold 9:\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.95      0.95       260\n","           1       0.95      0.94      0.94       243\n","\n","    accuracy                           0.94       503\n","   macro avg       0.94      0.94      0.94       503\n","weighted avg       0.94      0.94      0.94       503\n","\n","Fold 10\n","Epoch 0, Train Acc: 0.6436604189636164, Val Acc: 0.7296222664015904\n","Epoch 1, Train Acc: 0.7122381477398015, Val Acc: 0.7196819085487077\n","Epoch 2, Train Acc: 0.7252480705622932, Val Acc: 0.7335984095427436\n","Epoch 3, Train Acc: 0.7464167585446527, Val Acc: 0.731610337972167\n","Epoch 4, Train Acc: 0.7536934950385887, Val Acc: 0.7435387673956262\n","Epoch 5, Train Acc: 0.7671444321940463, Val Acc: 0.7793240556660039\n","Epoch 6, Train Acc: 0.785226019845645, Val Acc: 0.7833001988071571\n","Epoch 7, Train Acc: 0.7902976846747519, Val Acc: 0.7932405566600398\n","Epoch 8, Train Acc: 0.8022050716648291, Val Acc: 0.7833001988071571\n","Epoch 9, Train Acc: 0.8149944873208379, Val Acc: 0.8091451292246521\n","Epoch 10, Train Acc: 0.8242557883131202, Val Acc: 0.7892644135188867\n","Epoch 11, Train Acc: 0.834399117971334, Val Acc: 0.8091451292246521\n","Epoch 12, Train Acc: 0.8341786108048511, Val Acc: 0.8111332007952287\n","Epoch 13, Train Acc: 0.8434399117971334, Val Acc: 0.8389662027833003\n","Epoch 14, Train Acc: 0.8482910694597574, Val Acc: 0.8230616302186878\n","Epoch 15, Train Acc: 0.8579933847850055, Val Acc: 0.8429423459244533\n","Epoch 16, Train Acc: 0.8584343991179714, Val Acc: 0.8330019880715706\n","Epoch 17, Train Acc: 0.8654906284454245, Val Acc: 0.8349900596421471\n","Epoch 18, Train Acc: 0.8683572216097023, Val Acc: 0.8409542743538767\n","Epoch 19, Train Acc: 0.8674751929437706, Val Acc: 0.8727634194831014\n","Epoch 20, Train Acc: 0.8785005512679162, Val Acc: 0.8449304174950298\n","Epoch 21, Train Acc: 0.8758544652701212, Val Acc: 0.8608349900596421\n","Epoch 22, Train Acc: 0.8818081587651598, Val Acc: 0.8648111332007953\n","Epoch 23, Train Acc: 0.8820286659316428, Val Acc: 0.8727634194831014\n","Epoch 24, Train Acc: 0.8871003307607497, Val Acc: 0.8747514910536779\n","Epoch 25, Train Acc: 0.8957001102535832, Val Acc: 0.8846918489065606\n","Epoch 26, Train Acc: 0.9054024255788313, Val Acc: 0.8906560636182903\n","Epoch 27, Train Acc: 0.8798235942668137, Val Acc: 0.8707753479125249\n","Epoch 28, Train Acc: 0.889084895259096, Val Acc: 0.8966202783300199\n","Epoch 29, Train Acc: 0.8998897464167586, Val Acc: 0.9065606361829026\n","Epoch 30, Train Acc: 0.9047409040793826, Val Acc: 0.8926441351888668\n","Epoch 31, Train Acc: 0.903638368246968, Val Acc: 0.9224652087475149\n","Epoch 32, Train Acc: 0.9146637265711136, Val Acc: 0.9184890656063618\n","Epoch 33, Train Acc: 0.9098125689084895, Val Acc: 0.9105367793240556\n","Epoch 34, Train Acc: 0.9029768467475193, Val Acc: 0.8946322067594433\n","Epoch 35, Train Acc: 0.9117971334068358, Val Acc: 0.9224652087475149\n","Epoch 36, Train Acc: 0.9060639470782801, Val Acc: 0.9125248508946322\n","Epoch 37, Train Acc: 0.9168687982359427, Val Acc: 0.9165009940357853\n","Epoch 38, Train Acc: 0.9093715545755237, Val Acc: 0.9125248508946322\n","Epoch 39, Train Acc: 0.9056229327453142, Val Acc: 0.9224652087475149\n","Epoch 40, Train Acc: 0.9098125689084895, Val Acc: 0.904572564612326\n","Epoch 41, Train Acc: 0.9186328555678059, Val Acc: 0.9204771371769384\n","Epoch 42, Train Acc: 0.9192943770672547, Val Acc: 0.9324055666003976\n","Epoch 43, Train Acc: 0.9237045203969129, Val Acc: 0.9204771371769384\n","Epoch 44, Train Acc: 0.920837927232635, Val Acc: 0.9244532803180915\n","Epoch 45, Train Acc: 0.9170893054024256, Val Acc: 0.9403578528827038\n","Epoch 46, Train Acc: 0.9300992282249173, Val Acc: 0.9383697813121272\n","Epoch 47, Train Acc: 0.9265711135611907, Val Acc: 0.9204771371769384\n","Epoch 48, Train Acc: 0.9248070562293275, Val Acc: 0.9224652087475149\n","Epoch 49, Train Acc: 0.9212789415656009, Val Acc: 0.9343936381709742\n","Epoch 50, Train Acc: 0.9287761852260198, Val Acc: 0.9383697813121272\n","Epoch 51, Train Acc: 0.9287761852260198, Val Acc: 0.9542743538767395\n","Epoch 52, Train Acc: 0.9252480705622933, Val Acc: 0.9383697813121272\n","Epoch 53, Train Acc: 0.9316427783902976, Val Acc: 0.9383697813121272\n","Epoch 54, Train Acc: 0.9298787210584344, Val Acc: 0.9423459244532804\n","Epoch 55, Train Acc: 0.9325248070562293, Val Acc: 0.9502982107355865\n","Epoch 56, Train Acc: 0.9283351708930541, Val Acc: 0.9423459244532804\n","Epoch 57, Train Acc: 0.9338478500551268, Val Acc: 0.9463220675944334\n","Epoch 58, Train Acc: 0.9276736493936053, Val Acc: 0.9284294234592445\n","Epoch 59, Train Acc: 0.9303197353914002, Val Acc: 0.94831013916501\n","Epoch 60, Train Acc: 0.9371554575523704, Val Acc: 0.94831013916501\n","Epoch 61, Train Acc: 0.9312017640573319, Val Acc: 0.9383697813121272\n","Epoch 62, Train Acc: 0.9272326350606395, Val Acc: 0.9542743538767395\n","Epoch 63, Train Acc: 0.9283351708930541, Val Acc: 0.9343936381709742\n","Epoch 64, Train Acc: 0.9320837927232635, Val Acc: 0.9542743538767395\n","Epoch 65, Train Acc: 0.9373759647188533, Val Acc: 0.9343936381709742\n","Epoch 66, Train Acc: 0.938257993384785, Val Acc: 0.9403578528827038\n","Epoch 67, Train Acc: 0.9373759647188533, Val Acc: 0.9403578528827038\n","Epoch 68, Train Acc: 0.9248070562293275, Val Acc: 0.9602385685884692\n","Epoch 69, Train Acc: 0.9395810363836825, Val Acc: 0.952286282306163\n","Epoch 70, Train Acc: 0.9391400220507167, Val Acc: 0.9463220675944334\n","Epoch 71, Train Acc: 0.9464167585446527, Val Acc: 0.94831013916501\n","Epoch 72, Train Acc: 0.935832414553473, Val Acc: 0.9562624254473161\n","Epoch 73, Train Acc: 0.940683572216097, Val Acc: 0.9582504970178927\n","Epoch 74, Train Acc: 0.9395810363836825, Val Acc: 0.94831013916501\n","Epoch 75, Train Acc: 0.9402425578831312, Val Acc: 0.952286282306163\n","Epoch 76, Train Acc: 0.9384785005512679, Val Acc: 0.952286282306163\n","Epoch 77, Train Acc: 0.9391400220507167, Val Acc: 0.94831013916501\n","Epoch 78, Train Acc: 0.9336273428886439, Val Acc: 0.9622266401590457\n","Epoch 79, Train Acc: 0.9378169790518192, Val Acc: 0.9443339960238568\n","Epoch 80, Train Acc: 0.9413450937155458, Val Acc: 0.9542743538767395\n","Epoch 81, Train Acc: 0.9393605292171996, Val Acc: 0.9403578528827038\n","Epoch 82, Train Acc: 0.9444321940463065, Val Acc: 0.9463220675944334\n","Epoch 83, Train Acc: 0.933406835722161, Val Acc: 0.9343936381709742\n","Epoch 84, Train Acc: 0.9351708930540242, Val Acc: 0.9443339960238568\n","Epoch 85, Train Acc: 0.9398015435501654, Val Acc: 0.9423459244532804\n","Epoch 86, Train Acc: 0.9404630650496141, Val Acc: 0.952286282306163\n","Epoch 87, Train Acc: 0.9426681367144433, Val Acc: 0.9542743538767395\n","Epoch 88, Train Acc: 0.9373759647188533, Val Acc: 0.9423459244532804\n","Epoch 89, Train Acc: 0.9384785005512679, Val Acc: 0.9562624254473161\n","Epoch 90, Train Acc: 0.9433296582138919, Val Acc: 0.9662027833001988\n","Epoch 91, Train Acc: 0.9497243660418964, Val Acc: 0.9502982107355865\n","Epoch 92, Train Acc: 0.9386990077177508, Val Acc: 0.9542743538767395\n","Epoch 93, Train Acc: 0.9433296582138919, Val Acc: 0.9383697813121272\n","Epoch 94, Train Acc: 0.9371554575523704, Val Acc: 0.9642147117296223\n","Epoch 95, Train Acc: 0.9437706725468578, Val Acc: 0.9622266401590457\n","Epoch 96, Train Acc: 0.9426681367144433, Val Acc: 0.9502982107355865\n","Epoch 97, Train Acc: 0.9468577728776185, Val Acc: 0.9602385685884692\n","Epoch 98, Train Acc: 0.9398015435501654, Val Acc: 0.9542743538767395\n","Epoch 99, Train Acc: 0.9351708930540242, Val Acc: 0.952286282306163\n","Epoch 100, Train Acc: 0.9415656008820287, Val Acc: 0.9582504970178927\n","Epoch 101, Train Acc: 0.9435501653803748, Val Acc: 0.9542743538767395\n","Epoch 102, Train Acc: 0.9435501653803748, Val Acc: 0.9403578528827038\n","Epoch 103, Train Acc: 0.9457552370452039, Val Acc: 0.9602385685884692\n","Epoch 104, Train Acc: 0.9459757442116868, Val Acc: 0.9542743538767395\n","Epoch 105, Train Acc: 0.9415656008820287, Val Acc: 0.9642147117296223\n","Epoch 106, Train Acc: 0.9411245865490628, Val Acc: 0.9502982107355865\n","Epoch 107, Train Acc: 0.9415656008820287, Val Acc: 0.94831013916501\n","Epoch 108, Train Acc: 0.9411245865490628, Val Acc: 0.9463220675944334\n","Epoch 109, Train Acc: 0.9395810363836825, Val Acc: 0.9582504970178927\n","Epoch 110, Train Acc: 0.9422271223814774, Val Acc: 0.9582504970178927\n","Epoch 111, Train Acc: 0.9528114663726571, Val Acc: 0.952286282306163\n","Epoch 112, Train Acc: 0.9503858875413451, Val Acc: 0.9502982107355865\n","Epoch 113, Train Acc: 0.9450937155457553, Val Acc: 0.9542743538767395\n","Epoch 114, Train Acc: 0.9424476295479604, Val Acc: 0.94831013916501\n","Epoch 115, Train Acc: 0.9428886438809261, Val Acc: 0.9642147117296223\n","Epoch 116, Train Acc: 0.9426681367144433, Val Acc: 0.94831013916501\n","Epoch 117, Train Acc: 0.9424476295479604, Val Acc: 0.9602385685884692\n","Epoch 118, Train Acc: 0.9415656008820287, Val Acc: 0.9542743538767395\n","Epoch 119, Train Acc: 0.9400220507166482, Val Acc: 0.9622266401590457\n","Epoch 120, Train Acc: 0.9373759647188533, Val Acc: 0.9542743538767395\n","Epoch 121, Train Acc: 0.9453142227122382, Val Acc: 0.9622266401590457\n","Epoch 122, Train Acc: 0.9475192943770673, Val Acc: 0.9562624254473161\n","Epoch 123, Train Acc: 0.9472987872105844, Val Acc: 0.9602385685884692\n","Epoch 124, Train Acc: 0.9479603087100331, Val Acc: 0.9463220675944334\n","Epoch 125, Train Acc: 0.9492833517089305, Val Acc: 0.9582504970178927\n","Epoch 126, Train Acc: 0.950826901874311, Val Acc: 0.952286282306163\n","Epoch 127, Train Acc: 0.9461962513781698, Val Acc: 0.9582504970178927\n","Epoch 128, Train Acc: 0.9404630650496141, Val Acc: 0.9542743538767395\n","Epoch 129, Train Acc: 0.9495038588754134, Val Acc: 0.9642147117296223\n","Epoch 130, Train Acc: 0.9492833517089305, Val Acc: 0.9542743538767395\n","Epoch 131, Train Acc: 0.9488423373759647, Val Acc: 0.9642147117296223\n","Epoch 132, Train Acc: 0.9453142227122382, Val Acc: 0.9662027833001988\n","Epoch 133, Train Acc: 0.9499448732083793, Val Acc: 0.9602385685884692\n","Epoch 134, Train Acc: 0.9444321940463065, Val Acc: 0.9562624254473161\n","Epoch 135, Train Acc: 0.9435501653803748, Val Acc: 0.9582504970178927\n","Epoch 136, Train Acc: 0.9428886438809261, Val Acc: 0.9642147117296223\n","Epoch 137, Train Acc: 0.9417861080485116, Val Acc: 0.94831013916501\n","Epoch 138, Train Acc: 0.9466372657111356, Val Acc: 0.9542743538767395\n","Epoch 139, Train Acc: 0.9475192943770673, Val Acc: 0.9582504970178927\n","Epoch 140, Train Acc: 0.9519294377067254, Val Acc: 0.9622266401590457\n","Epoch 141, Train Acc: 0.9501653803748622, Val Acc: 0.9582504970178927\n","Epoch 142, Train Acc: 0.9446527012127894, Val Acc: 0.9562624254473161\n","Epoch 143, Train Acc: 0.9461962513781698, Val Acc: 0.9642147117296223\n","Epoch 144, Train Acc: 0.9464167585446527, Val Acc: 0.9542743538767395\n","Epoch 145, Train Acc: 0.945534729878721, Val Acc: 0.94831013916501\n","Epoch 146, Train Acc: 0.9448732083792724, Val Acc: 0.9324055666003976\n","Epoch 147, Train Acc: 0.9453142227122382, Val Acc: 0.9542743538767395\n","Epoch 148, Train Acc: 0.9424476295479604, Val Acc: 0.952286282306163\n","Epoch 149, Train Acc: 0.9428886438809261, Val Acc: 0.9403578528827038\n","Epoch 150, Train Acc: 0.945534729878721, Val Acc: 0.9721669980119284\n","Epoch 151, Train Acc: 0.9453142227122382, Val Acc: 0.9642147117296223\n","Epoch 152, Train Acc: 0.9398015435501654, Val Acc: 0.9642147117296223\n","Epoch 153, Train Acc: 0.9433296582138919, Val Acc: 0.9662027833001988\n","Epoch 154, Train Acc: 0.9497243660418964, Val Acc: 0.9582504970178927\n","Epoch 155, Train Acc: 0.9517089305402425, Val Acc: 0.9681908548707754\n","Epoch 156, Train Acc: 0.9492833517089305, Val Acc: 0.9681908548707754\n","Epoch 157, Train Acc: 0.9488423373759647, Val Acc: 0.9662027833001988\n","Epoch 158, Train Acc: 0.9459757442116868, Val Acc: 0.9622266401590457\n","Epoch 159, Train Acc: 0.9492833517089305, Val Acc: 0.9582504970178927\n","Epoch 160, Train Acc: 0.9510474090407939, Val Acc: 0.9622266401590457\n","Epoch 161, Train Acc: 0.9552370452039691, Val Acc: 0.9681908548707754\n","Epoch 162, Train Acc: 0.9514884233737596, Val Acc: 0.952286282306163\n","Epoch 163, Train Acc: 0.9547960308710033, Val Acc: 0.9542743538767395\n","Epoch 164, Train Acc: 0.9484013230429988, Val Acc: 0.9582504970178927\n","Epoch 165, Train Acc: 0.9499448732083793, Val Acc: 0.9681908548707754\n","Epoch 166, Train Acc: 0.9499448732083793, Val Acc: 0.9642147117296223\n","Epoch 167, Train Acc: 0.9503858875413451, Val Acc: 0.9622266401590457\n","Epoch 168, Train Acc: 0.9402425578831312, Val Acc: 0.9502982107355865\n","Epoch 169, Train Acc: 0.9475192943770673, Val Acc: 0.94831013916501\n","Epoch 170, Train Acc: 0.9521499448732084, Val Acc: 0.9602385685884692\n","Epoch 171, Train Acc: 0.9448732083792724, Val Acc: 0.9642147117296223\n","Epoch 172, Train Acc: 0.9468577728776185, Val Acc: 0.9542743538767395\n","Epoch 173, Train Acc: 0.9468577728776185, Val Acc: 0.9602385685884692\n","Epoch 174, Train Acc: 0.9444321940463065, Val Acc: 0.9542743538767395\n","Epoch 175, Train Acc: 0.9490628445424476, Val Acc: 0.9701789264413518\n","Epoch 176, Train Acc: 0.9492833517089305, Val Acc: 0.9662027833001988\n","Epoch 177, Train Acc: 0.9442116868798236, Val Acc: 0.9602385685884692\n","Epoch 178, Train Acc: 0.9477398015435502, Val Acc: 0.9582504970178927\n","Epoch 179, Train Acc: 0.9521499448732084, Val Acc: 0.9662027833001988\n","Epoch 180, Train Acc: 0.9479603087100331, Val Acc: 0.9602385685884692\n","Epoch 181, Train Acc: 0.9550165380374862, Val Acc: 0.9681908548707754\n","Epoch 182, Train Acc: 0.950826901874311, Val Acc: 0.9642147117296223\n","Epoch 183, Train Acc: 0.9453142227122382, Val Acc: 0.9622266401590457\n","Epoch 184, Train Acc: 0.9422271223814774, Val Acc: 0.9622266401590457\n","Epoch 185, Train Acc: 0.9395810363836825, Val Acc: 0.9662027833001988\n","Epoch 186, Train Acc: 0.950826901874311, Val Acc: 0.9681908548707754\n","Epoch 187, Train Acc: 0.9565600882028666, Val Acc: 0.9681908548707754\n","Epoch 188, Train Acc: 0.9501653803748622, Val Acc: 0.9721669980119284\n","Epoch 189, Train Acc: 0.9503858875413451, Val Acc: 0.9542743538767395\n","Epoch 190, Train Acc: 0.9552370452039691, Val Acc: 0.9642147117296223\n","Epoch 191, Train Acc: 0.9541345093715545, Val Acc: 0.9622266401590457\n","Epoch 192, Train Acc: 0.9539140022050716, Val Acc: 0.952286282306163\n","Epoch 193, Train Acc: 0.9486218302094818, Val Acc: 0.9582504970178927\n","Epoch 194, Train Acc: 0.9470782800441014, Val Acc: 0.9582504970178927\n","Epoch 195, Train Acc: 0.9499448732083793, Val Acc: 0.9821073558648111\n","Epoch 196, Train Acc: 0.9514884233737596, Val Acc: 0.9662027833001988\n","Epoch 197, Train Acc: 0.9550165380374862, Val Acc: 0.9622266401590457\n","Epoch 198, Train Acc: 0.9543550165380374, Val Acc: 0.9502982107355865\n","Epoch 199, Train Acc: 0.9501653803748622, Val Acc: 0.9562624254473161\n","Epoch 200, Train Acc: 0.9547960308710033, Val Acc: 0.94831013916501\n","Epoch 201, Train Acc: 0.9411245865490628, Val Acc: 0.9622266401590457\n","Epoch 202, Train Acc: 0.9444321940463065, Val Acc: 0.9662027833001988\n","Epoch 203, Train Acc: 0.9521499448732084, Val Acc: 0.9622266401590457\n","Epoch 204, Train Acc: 0.948180815876516, Val Acc: 0.9662027833001988\n","Epoch 205, Train Acc: 0.9475192943770673, Val Acc: 0.9562624254473161\n","Epoch 206, Train Acc: 0.9528114663726571, Val Acc: 0.9701789264413518\n","Epoch 207, Train Acc: 0.9567805953693495, Val Acc: 0.9502982107355865\n","Epoch 208, Train Acc: 0.9558985667034179, Val Acc: 0.9602385685884692\n","Epoch 209, Train Acc: 0.950606394707828, Val Acc: 0.9443339960238568\n","Epoch 210, Train Acc: 0.9541345093715545, Val Acc: 0.9662027833001988\n","Epoch 211, Train Acc: 0.9512679162072767, Val Acc: 0.9681908548707754\n","Epoch 212, Train Acc: 0.9464167585446527, Val Acc: 0.9701789264413518\n","Epoch 213, Train Acc: 0.9472987872105844, Val Acc: 0.9602385685884692\n","Epoch 214, Train Acc: 0.9525909592061742, Val Acc: 0.9602385685884692\n","Epoch 215, Train Acc: 0.9402425578831312, Val Acc: 0.9582504970178927\n","Epoch 216, Train Acc: 0.9470782800441014, Val Acc: 0.9562624254473161\n","Epoch 217, Train Acc: 0.9450937155457553, Val Acc: 0.9721669980119284\n","Epoch 218, Train Acc: 0.9561190738699008, Val Acc: 0.9662027833001988\n","Epoch 219, Train Acc: 0.9499448732083793, Val Acc: 0.9681908548707754\n","Epoch 220, Train Acc: 0.9563395810363837, Val Acc: 0.9542743538767395\n","Epoch 221, Train Acc: 0.9499448732083793, Val Acc: 0.9642147117296223\n","Epoch 222, Train Acc: 0.9547960308710033, Val Acc: 0.9602385685884692\n","Epoch 223, Train Acc: 0.953252480705623, Val Acc: 0.9602385685884692\n","Epoch 224, Train Acc: 0.945534729878721, Val Acc: 0.9662027833001988\n","Epoch 225, Train Acc: 0.9488423373759647, Val Acc: 0.9642147117296223\n","Epoch 226, Train Acc: 0.95303197353914, Val Acc: 0.9701789264413518\n","Epoch 227, Train Acc: 0.9517089305402425, Val Acc: 0.952286282306163\n","Epoch 228, Train Acc: 0.948180815876516, Val Acc: 0.9701789264413518\n","Epoch 229, Train Acc: 0.955678059536935, Val Acc: 0.9681908548707754\n","Epoch 230, Train Acc: 0.955457552370452, Val Acc: 0.9701789264413518\n","Epoch 231, Train Acc: 0.9539140022050716, Val Acc: 0.9622266401590457\n","Epoch 232, Train Acc: 0.9525909592061742, Val Acc: 0.9582504970178927\n","Epoch 233, Train Acc: 0.9475192943770673, Val Acc: 0.9582504970178927\n","Epoch 234, Train Acc: 0.9466372657111356, Val Acc: 0.9761431411530815\n","Epoch 235, Train Acc: 0.9468577728776185, Val Acc: 0.9662027833001988\n","Epoch 236, Train Acc: 0.9517089305402425, Val Acc: 0.9701789264413518\n","Epoch 237, Train Acc: 0.9574421168687982, Val Acc: 0.9681908548707754\n","Epoch 238, Train Acc: 0.9510474090407939, Val Acc: 0.9761431411530815\n","Epoch 239, Train Acc: 0.9424476295479604, Val Acc: 0.9701789264413518\n","Epoch 240, Train Acc: 0.9453142227122382, Val Acc: 0.9582504970178927\n","Epoch 241, Train Acc: 0.9492833517089305, Val Acc: 0.9602385685884692\n","Epoch 242, Train Acc: 0.9490628445424476, Val Acc: 0.9602385685884692\n","Epoch 243, Train Acc: 0.9567805953693495, Val Acc: 0.9622266401590457\n","Epoch 244, Train Acc: 0.9550165380374862, Val Acc: 0.9602385685884692\n","Epoch 245, Train Acc: 0.9567805953693495, Val Acc: 0.9622266401590457\n","Epoch 246, Train Acc: 0.95303197353914, Val Acc: 0.9701789264413518\n","Epoch 247, Train Acc: 0.9539140022050716, Val Acc: 0.9562624254473161\n","Epoch 248, Train Acc: 0.9470782800441014, Val Acc: 0.9562624254473161\n","Epoch 249, Train Acc: 0.9459757442116868, Val Acc: 0.9681908548707754\n","Best Training Accuracy for Fold 10: 0.9499448732083793\n","Best Validation Accuracy for Fold 10: 0.9821073558648111\n","Classification Report for Fold 10:\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.97      0.97       261\n","           1       0.96      0.97      0.97       242\n","\n","    accuracy                           0.97       503\n","   macro avg       0.97      0.97      0.97       503\n","weighted avg       0.97      0.97      0.97       503\n","\n","Overall Mean of Highest Validation Accuracies: 0.9648675407870237\n","Overall Mean of Weighted Average Precision: 0.9529041918339954\n","Overall Mean of Weighted Average Recall: 0.952562008898987\n","Overall Mean of Weighted Average F1-Score: 0.9525625131917161\n"]}],"source":["from sklearn.metrics import accuracy_score\n","from torch_geometric.data import Data, DataLoader\n","from sklearn.model_selection import KFold\n","import numpy as np\n","from sklearn.metrics import classification_report\n","\n","\n","def train(loader, model, criterion, optimizer):\n","    model.train()\n","    total_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch in loader:\n","        batch.to(device)\n","        optimizer.zero_grad()\n","        out = model(batch)\n","        loss = criterion(out, batch.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","        # Calculate accuracy\n","        _, predicted = torch.max(out, 1)\n","        correct += (predicted == batch.y).sum().item()\n","        total += batch.y.size(0)\n","\n","    train_loss = total_loss / len(loader.dataset)\n","    train_accuracy = correct / total\n","    return train_loss, train_accuracy\n","\n","def evaluate(loader, model):\n","    model.eval()\n","    total_correct = 0\n","    total = 0\n","    all_preds = []\n","    all_labels = []\n","    for batch in loader:\n","        batch.to(device)\n","        out = model(batch)\n","        _, pred = torch.max(out, dim=1)\n","        all_preds.extend(pred.cpu().numpy())\n","        all_labels.extend(batch.y.cpu().numpy())\n","        total_correct += int(pred.eq(batch.y).sum().item())\n","        total += batch.num_graphs\n","    return total_correct / total, all_preds, all_labels\n","\n","\n","kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n","batch_size = 32  # Define your batch size\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","highest_val_accuracies = []  # List to store the highest validation accuracy for each fold\n","weighted_precisions = []\n","weighted_recalls = []\n","weighted_f1_scores = []\n","\n","for fold, (train_idx, val_idx) in enumerate(kfold.split(graph_list)):\n","    print(f\"Fold {fold + 1}\")\n","\n","    train_subset = torch.utils.data.Subset(graph_list, train_idx)\n","    val_subset = torch.utils.data.Subset(graph_list, val_idx)\n","\n","    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n","\n","    model = GCNModel(bert_embedding_size=768, hidden_channels=64, num_classes=len(set(data_set['Label']))).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay = 5e-4)\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","    fold_best_val_accuracy = 0  # Variable to track the best accuracy for the current fold\n","    fold_best_train_accuracy = 0\n","\n","    for epoch in range(250):  # Adjust the number of epochs as needed\n","        train_loss, train_acc = train(train_loader, model, criterion, optimizer)\n","        val_acc, val_preds, val_labels = evaluate(val_loader, model)\n","\n","        if val_acc > fold_best_val_accuracy:\n","            fold_best_val_accuracy = val_acc\n","            fold_best_train_accuracy = train_acc\n","\n","        print(f'Epoch {epoch}, Train Acc: {train_acc}, Val Acc: {val_acc}')\n","\n","    highest_val_accuracies.append(fold_best_val_accuracy)\n","    print(f\"Best Training Accuracy for Fold {fold + 1}: {fold_best_train_accuracy}\")\n","    print(f\"Best Validation Accuracy for Fold {fold + 1}: {fold_best_val_accuracy}\")\n","\n","    # Classification report\n","    print(f\"Classification Report for Fold {fold + 1}:\\n{classification_report(val_labels, val_preds)}\")\n","    report = classification_report(val_labels, val_preds, output_dict=True)\n","    weighted_precisions.append(report['weighted avg']['precision'])\n","    weighted_recalls.append(report['weighted avg']['recall'])\n","    weighted_f1_scores.append(report['weighted avg']['f1-score'])\n","\n","\n","\n","    # Store and print classification report...\n","\n","# Calculate and print the overall mean of the highest validation accuracies...\n","overall_mean_precision = np.mean(weighted_precisions)\n","overall_mean_recall = np.mean(weighted_recalls)\n","overall_mean_f1 = np.mean(weighted_f1_scores)\n","# Compute the overall mean of the highest validation accuracies across all folds\n","overall_mean_highest_val_accuracy = np.mean(highest_val_accuracies)\n","print(f\"Overall Mean of Highest Validation Accuracies: {overall_mean_highest_val_accuracy}\")\n","print(f\"Overall Mean of Weighted Average Precision: {overall_mean_precision}\")\n","print(f\"Overall Mean of Weighted Average Recall: {overall_mean_recall}\")\n","print(f\"Overall Mean of Weighted Average F1-Score: {overall_mean_f1}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10sqg6nTna2G","executionInfo":{"status":"ok","timestamp":1706024343249,"user_tz":-360,"elapsed":15,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"b5b610a9-2117-4cd1-a721-5d88045d3ce4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overall Mean of Highest Validation Accuracies: 0.9648675407870237\n","Overall Mean of Weighted Average Precision: 0.9529041918339954\n","Overall Mean of Weighted Average Recall: 0.952562008898987\n","Overall Mean of Weighted Average F1-Score: 0.9525625131917161\n"]}],"source":["overall_mean_highest_val_accuracy = np.mean(highest_val_accuracies)\n","print(f\"Overall Mean of Highest Validation Accuracies: {overall_mean_highest_val_accuracy}\")\n","print(f\"Overall Mean of Weighted Average Precision: {overall_mean_precision}\")\n","print(f\"Overall Mean of Weighted Average Recall: {overall_mean_recall}\")\n","print(f\"Overall Mean of Weighted Average F1-Score: {overall_mean_f1}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"LD2tr7_9WcVs","executionInfo":{"status":"ok","timestamp":1706024636084,"user_tz":-360,"elapsed":292845,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"2dfcaf80-b729-458f-b408-e2e4e443c0f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Train Acc: 0.6387295985884429, Val Acc: 0.6984126984126984\n","Epoch 1, Train Acc: 0.7137185707984119, Val Acc: 0.7341269841269841\n","Epoch 2, Train Acc: 0.7322452580502867, Val Acc: 0.751984126984127\n","Epoch 3, Train Acc: 0.7525363917071018, Val Acc: 0.751984126984127\n","Epoch 4, Train Acc: 0.7657697397441553, Val Acc: 0.7738095238095238\n","Epoch 5, Train Acc: 0.7715041905602117, Val Acc: 0.7837301587301587\n","Epoch 6, Train Acc: 0.782311424790472, Val Acc: 0.7757936507936508\n","Epoch 7, Train Acc: 0.7995147772386414, Val Acc: 0.7757936507936508\n","Epoch 8, Train Acc: 0.8074547860608734, Val Acc: 0.7777777777777778\n","Epoch 9, Train Acc: 0.8180414644905161, Val Acc: 0.7916666666666666\n","Epoch 10, Train Acc: 0.8118659020732245, Val Acc: 0.7341269841269841\n","Epoch 11, Train Acc: 0.8284075871195412, Val Acc: 0.8095238095238095\n","Epoch 12, Train Acc: 0.8480370533745037, Val Acc: 0.8115079365079365\n","Epoch 13, Train Acc: 0.8392148213498015, Val Acc: 0.8373015873015873\n","Epoch 14, Train Acc: 0.8539920599911778, Val Acc: 0.8115079365079365\n","Epoch 15, Train Acc: 0.8535509483899426, Val Acc: 0.8412698412698413\n","Epoch 16, Train Acc: 0.8581826202029114, Val Acc: 0.8373015873015873\n","Epoch 17, Train Acc: 0.8617115130127923, Val Acc: 0.8253968253968254\n","Epoch 18, Train Acc: 0.882223202470225, Val Acc: 0.8353174603174603\n","Epoch 19, Train Acc: 0.8789148654609616, Val Acc: 0.8432539682539683\n","Epoch 20, Train Acc: 0.8820026466696074, Val Acc: 0.873015873015873\n","Epoch 21, Train Acc: 0.8850904278782532, Val Acc: 0.8373015873015873\n","Epoch 22, Train Acc: 0.886193206881341, Val Acc: 0.8650793650793651\n","Epoch 23, Train Acc: 0.8833259814733128, Val Acc: 0.8988095238095238\n","Epoch 24, Train Acc: 0.894133215703573, Val Acc: 0.8829365079365079\n","Epoch 25, Train Acc: 0.9022937803264226, Val Acc: 0.875\n","Epoch 26, Train Acc: 0.9009704455227172, Val Acc: 0.8948412698412699\n","Epoch 27, Train Acc: 0.9020732245258051, Val Acc: 0.9027777777777778\n","Epoch 28, Train Acc: 0.9042787825319806, Val Acc: 0.8690476190476191\n","Epoch 29, Train Acc: 0.9027348919276577, Val Acc: 0.873015873015873\n","Epoch 30, Train Acc: 0.9106749007498898, Val Acc: 0.9067460317460317\n","Epoch 31, Train Acc: 0.911998235553595, Val Acc: 0.8888888888888888\n","Epoch 32, Train Acc: 0.9113365681517424, Val Acc: 0.9166666666666666\n","Epoch 33, Train Acc: 0.9142037935597707, Val Acc: 0.9087301587301587\n","Epoch 34, Train Acc: 0.9170710189677989, Val Acc: 0.9206349206349206\n","Epoch 35, Train Acc: 0.913542126157918, Val Acc: 0.9166666666666666\n","Epoch 36, Train Acc: 0.9210410233789149, Val Acc: 0.9107142857142857\n","Epoch 37, Train Acc: 0.9157476841640935, Val Acc: 0.9126984126984127\n","Epoch 38, Train Acc: 0.9188354653727393, Val Acc: 0.9246031746031746\n","Epoch 39, Train Acc: 0.9239082487869431, Val Acc: 0.9067460317460317\n","Epoch 40, Train Acc: 0.9228054697838554, Val Acc: 0.9246031746031746\n","Epoch 41, Train Acc: 0.9232465813850904, Val Acc: 0.9285714285714286\n","Epoch 42, Train Acc: 0.9232465813850904, Val Acc: 0.9305555555555556\n","Epoch 43, Train Acc: 0.919497132774592, Val Acc: 0.9186507936507936\n","Epoch 44, Train Acc: 0.9252315835906484, Val Acc: 0.9404761904761905\n","Epoch 45, Train Acc: 0.9232465813850904, Val Acc: 0.9444444444444444\n","Epoch 46, Train Acc: 0.9296426996029996, Val Acc: 0.9246031746031746\n","Epoch 47, Train Acc: 0.9305249228054698, Val Acc: 0.9424603174603174\n","Epoch 48, Train Acc: 0.9320688134097926, Val Acc: 0.9265873015873016\n","Epoch 49, Train Acc: 0.9236876929863256, Val Acc: 0.9404761904761905\n","Epoch 50, Train Acc: 0.9300838112042347, Val Acc: 0.9503968253968254\n","Epoch 51, Train Acc: 0.927437141596824, Val Acc: 0.9365079365079365\n","Epoch 52, Train Acc: 0.9325099250110278, Val Acc: 0.9464285714285714\n","Epoch 53, Train Acc: 0.9289810322011469, Val Acc: 0.9226190476190477\n","Epoch 54, Train Acc: 0.927878253198059, Val Acc: 0.9325396825396826\n","Epoch 55, Train Acc: 0.9192765769739745, Val Acc: 0.9226190476190477\n","Epoch 56, Train Acc: 0.9298632554036171, Val Acc: 0.9384920634920635\n","Epoch 57, Train Acc: 0.9344949272165858, Val Acc: 0.9126984126984127\n","Epoch 58, Train Acc: 0.9369210410233789, Val Acc: 0.9365079365079365\n","Epoch 59, Train Acc: 0.9367004852227614, Val Acc: 0.9246031746031746\n","Epoch 60, Train Acc: 0.9280988089986767, Val Acc: 0.9345238095238095\n","Epoch 61, Train Acc: 0.9351565946184385, Val Acc: 0.9345238095238095\n","Epoch 62, Train Acc: 0.9362593736215262, Val Acc: 0.9424603174603174\n","Epoch 63, Train Acc: 0.9338332598147331, Val Acc: 0.9464285714285714\n","Epoch 64, Train Acc: 0.9342743714159683, Val Acc: 0.9265873015873016\n","Epoch 65, Train Acc: 0.9338332598147331, Val Acc: 0.9404761904761905\n","Epoch 66, Train Acc: 0.9378032642258491, Val Acc: 0.9345238095238095\n","Epoch 67, Train Acc: 0.9393471548301721, Val Acc: 0.9503968253968254\n","Epoch 68, Train Acc: 0.9395677106307896, Val Acc: 0.9503968253968254\n","Epoch 69, Train Acc: 0.940891045434495, Val Acc: 0.9523809523809523\n","Epoch 70, Train Acc: 0.9415527128363476, Val Acc: 0.9384920634920635\n","Epoch 71, Train Acc: 0.9369210410233789, Val Acc: 0.9404761904761905\n","Epoch 72, Train Acc: 0.9437582708425232, Val Acc: 0.9305555555555556\n","Epoch 73, Train Acc: 0.9455227172474636, Val Acc: 0.9464285714285714\n","Epoch 74, Train Acc: 0.9355977062196735, Val Acc: 0.9345238095238095\n","Epoch 75, Train Acc: 0.9329510366122629, Val Acc: 0.9623015873015873\n","Epoch 76, Train Acc: 0.9329510366122629, Val Acc: 0.9424603174603174\n","Epoch 77, Train Acc: 0.9439788266431407, Val Acc: 0.9623015873015873\n","Epoch 78, Train Acc: 0.9472871636524041, Val Acc: 0.9444444444444444\n","Epoch 79, Train Acc: 0.9336127040141156, Val Acc: 0.9424603174603174\n","Epoch 80, Train Acc: 0.9322893692104103, Val Acc: 0.9384920634920635\n","Epoch 81, Train Acc: 0.9305249228054698, Val Acc: 0.9503968253968254\n","Epoch 82, Train Acc: 0.9397882664314071, Val Acc: 0.9484126984126984\n","Epoch 83, Train Acc: 0.9417732686369652, Val Acc: 0.9603174603174603\n","Epoch 84, Train Acc: 0.9419938244375827, Val Acc: 0.9484126984126984\n","Epoch 85, Train Acc: 0.9477282752536391, Val Acc: 0.9484126984126984\n","Epoch 86, Train Acc: 0.9437582708425232, Val Acc: 0.9603174603174603\n","Epoch 87, Train Acc: 0.9437582708425232, Val Acc: 0.9642857142857143\n","Epoch 88, Train Acc: 0.9391265990295545, Val Acc: 0.9444444444444444\n","Epoch 89, Train Acc: 0.9397882664314071, Val Acc: 0.9523809523809523\n","Epoch 90, Train Acc: 0.9415527128363476, Val Acc: 0.9603174603174603\n","Epoch 91, Train Acc: 0.9386854874283194, Val Acc: 0.9484126984126984\n","Epoch 92, Train Acc: 0.9395677106307896, Val Acc: 0.9484126984126984\n","Epoch 93, Train Acc: 0.9419938244375827, Val Acc: 0.9642857142857143\n","Epoch 94, Train Acc: 0.9400088222320248, Val Acc: 0.9444444444444444\n","Epoch 95, Train Acc: 0.942876047640053, Val Acc: 0.9543650793650794\n","Epoch 96, Train Acc: 0.9371415968239964, Val Acc: 0.9563492063492064\n","Epoch 97, Train Acc: 0.9439788266431407, Val Acc: 0.9305555555555556\n","Epoch 98, Train Acc: 0.9439788266431407, Val Acc: 0.9603174603174603\n","Epoch 99, Train Acc: 0.9499338332598147, Val Acc: 0.9265873015873016\n","Epoch 100, Train Acc: 0.9439788266431407, Val Acc: 0.9345238095238095\n","Epoch 101, Train Acc: 0.9470666078517865, Val Acc: 0.9404761904761905\n","Epoch 102, Train Acc: 0.9481693868548743, Val Acc: 0.9305555555555556\n","Epoch 103, Train Acc: 0.942876047640053, Val Acc: 0.9503968253968254\n","Epoch 104, Train Acc: 0.9444199382443759, Val Acc: 0.9444444444444444\n","Epoch 105, Train Acc: 0.9503749448610499, Val Acc: 0.9583333333333334\n","Epoch 106, Train Acc: 0.9499338332598147, Val Acc: 0.9523809523809523\n","Epoch 107, Train Acc: 0.9468460520511689, Val Acc: 0.9404761904761905\n","Epoch 108, Train Acc: 0.9441993824437582, Val Acc: 0.9484126984126984\n","Epoch 109, Train Acc: 0.9483899426554918, Val Acc: 0.9543650793650794\n","Epoch 110, Train Acc: 0.9437582708425232, Val Acc: 0.9563492063492064\n","Epoch 111, Train Acc: 0.9477282752536391, Val Acc: 0.9563492063492064\n","Epoch 112, Train Acc: 0.9545655050727834, Val Acc: 0.9503968253968254\n","Epoch 113, Train Acc: 0.9459638288486987, Val Acc: 0.9543650793650794\n","Epoch 114, Train Acc: 0.9424349360388178, Val Acc: 0.9523809523809523\n","Epoch 115, Train Acc: 0.9444199382443759, Val Acc: 0.9503968253968254\n","Epoch 116, Train Acc: 0.948831054256727, Val Acc: 0.9623015873015873\n","Epoch 117, Train Acc: 0.940891045434495, Val Acc: 0.9603174603174603\n","Epoch 118, Train Acc: 0.9415527128363476, Val Acc: 0.9543650793650794\n","Epoch 119, Train Acc: 0.9528010586678429, Val Acc: 0.9484126984126984\n","Epoch 120, Train Acc: 0.9397882664314071, Val Acc: 0.9702380952380952\n","Epoch 121, Train Acc: 0.9466254962505514, Val Acc: 0.9563492063492064\n","Epoch 122, Train Acc: 0.9501543890604323, Val Acc: 0.9206349206349206\n","Epoch 123, Train Acc: 0.9439788266431407, Val Acc: 0.9523809523809523\n","Epoch 124, Train Acc: 0.9378032642258491, Val Acc: 0.9503968253968254\n","Epoch 125, Train Acc: 0.9450816056462285, Val Acc: 0.9583333333333334\n","Epoch 126, Train Acc: 0.942876047640053, Val Acc: 0.9543650793650794\n","Epoch 127, Train Acc: 0.9404499338332598, Val Acc: 0.9523809523809523\n","Epoch 128, Train Acc: 0.950816056462285, Val Acc: 0.9523809523809523\n","Epoch 129, Train Acc: 0.9444199382443759, Val Acc: 0.9642857142857143\n","Epoch 130, Train Acc: 0.9464049404499338, Val Acc: 0.9583333333333334\n","Epoch 131, Train Acc: 0.9402293780326423, Val Acc: 0.9623015873015873\n","Epoch 132, Train Acc: 0.9446404940449934, Val Acc: 0.9543650793650794\n","Epoch 133, Train Acc: 0.9430966034406705, Val Acc: 0.9523809523809523\n","Epoch 134, Train Acc: 0.9468460520511689, Val Acc: 0.9305555555555556\n","Epoch 135, Train Acc: 0.9400088222320248, Val Acc: 0.9563492063492064\n","Epoch 136, Train Acc: 0.9424349360388178, Val Acc: 0.9583333333333334\n","Epoch 137, Train Acc: 0.9472871636524041, Val Acc: 0.9484126984126984\n","Epoch 138, Train Acc: 0.9450816056462285, Val Acc: 0.9464285714285714\n","Epoch 139, Train Acc: 0.9510366122629025, Val Acc: 0.9464285714285714\n","Epoch 140, Train Acc: 0.9464049404499338, Val Acc: 0.9365079365079365\n","Epoch 141, Train Acc: 0.9424349360388178, Val Acc: 0.9523809523809523\n","Epoch 142, Train Acc: 0.9402293780326423, Val Acc: 0.9365079365079365\n","Epoch 143, Train Acc: 0.9545655050727834, Val Acc: 0.9484126984126984\n","Epoch 144, Train Acc: 0.9510366122629025, Val Acc: 0.9603174603174603\n","Epoch 145, Train Acc: 0.9457432730480811, Val Acc: 0.9682539682539683\n","Epoch 146, Train Acc: 0.9521393912659903, Val Acc: 0.9563492063492064\n","Epoch 147, Train Acc: 0.9477282752536391, Val Acc: 0.9642857142857143\n","Epoch 148, Train Acc: 0.943317159241288, Val Acc: 0.9464285714285714\n","Epoch 149, Train Acc: 0.9486104984561093, Val Acc: 0.9543650793650794\n","Epoch 150, Train Acc: 0.948831054256727, Val Acc: 0.9484126984126984\n","Epoch 151, Train Acc: 0.9483899426554918, Val Acc: 0.9543650793650794\n","Epoch 152, Train Acc: 0.949272165857962, Val Acc: 0.9484126984126984\n","Epoch 153, Train Acc: 0.942876047640053, Val Acc: 0.9325396825396826\n","Epoch 154, Train Acc: 0.9503749448610499, Val Acc: 0.9523809523809523\n","Epoch 155, Train Acc: 0.9479488310542568, Val Acc: 0.9742063492063492\n","Epoch 156, Train Acc: 0.9470666078517865, Val Acc: 0.9563492063492064\n","Epoch 157, Train Acc: 0.9479488310542568, Val Acc: 0.9523809523809523\n","Epoch 158, Train Acc: 0.9477282752536391, Val Acc: 0.9583333333333334\n","Epoch 159, Train Acc: 0.9550066166740185, Val Acc: 0.9563492063492064\n","Epoch 160, Train Acc: 0.9499338332598147, Val Acc: 0.9623015873015873\n","Epoch 161, Train Acc: 0.949272165857962, Val Acc: 0.9563492063492064\n","Epoch 162, Train Acc: 0.9514777238641376, Val Acc: 0.9583333333333334\n","Epoch 163, Train Acc: 0.9444199382443759, Val Acc: 0.9583333333333334\n","Epoch 164, Train Acc: 0.9514777238641376, Val Acc: 0.9623015873015873\n","Epoch 165, Train Acc: 0.9459638288486987, Val Acc: 0.9484126984126984\n","Epoch 166, Train Acc: 0.9475077194530216, Val Acc: 0.9623015873015873\n","Epoch 167, Train Acc: 0.9457432730480811, Val Acc: 0.9563492063492064\n","Epoch 168, Train Acc: 0.9501543890604323, Val Acc: 0.9623015873015873\n","Epoch 169, Train Acc: 0.9550066166740185, Val Acc: 0.9662698412698413\n","Epoch 170, Train Acc: 0.9530216144684606, Val Acc: 0.9642857142857143\n","Epoch 171, Train Acc: 0.954786060873401, Val Acc: 0.9484126984126984\n","Epoch 172, Train Acc: 0.9419938244375827, Val Acc: 0.9563492063492064\n","Epoch 173, Train Acc: 0.9525805028672254, Val Acc: 0.9583333333333334\n","Epoch 174, Train Acc: 0.9453021614468461, Val Acc: 0.9662698412698413\n","Epoch 175, Train Acc: 0.9536832818703131, Val Acc: 0.9662698412698413\n","Epoch 176, Train Acc: 0.9550066166740185, Val Acc: 0.9543650793650794\n","Epoch 177, Train Acc: 0.9446404940449934, Val Acc: 0.9623015873015873\n","Epoch 178, Train Acc: 0.950816056462285, Val Acc: 0.9623015873015873\n","Epoch 179, Train Acc: 0.9545655050727834, Val Acc: 0.9583333333333334\n","Epoch 180, Train Acc: 0.9490516100573445, Val Acc: 0.9682539682539683\n","Epoch 181, Train Acc: 0.9503749448610499, Val Acc: 0.9623015873015873\n","Epoch 182, Train Acc: 0.9481693868548743, Val Acc: 0.9642857142857143\n","Epoch 183, Train Acc: 0.9583149536832819, Val Acc: 0.9603174603174603\n","Epoch 184, Train Acc: 0.9521393912659903, Val Acc: 0.9623015873015873\n","Epoch 185, Train Acc: 0.9479488310542568, Val Acc: 0.9603174603174603\n","Epoch 186, Train Acc: 0.9461843846493163, Val Acc: 0.9583333333333334\n","Epoch 187, Train Acc: 0.9444199382443759, Val Acc: 0.9563492063492064\n","Epoch 188, Train Acc: 0.9464049404499338, Val Acc: 0.9444444444444444\n","Epoch 189, Train Acc: 0.9512571680635201, Val Acc: 0.9503968253968254\n","Epoch 190, Train Acc: 0.9499338332598147, Val Acc: 0.9503968253968254\n","Epoch 191, Train Acc: 0.9468460520511689, Val Acc: 0.9543650793650794\n","Epoch 192, Train Acc: 0.9505955006616674, Val Acc: 0.9603174603174603\n","Epoch 193, Train Acc: 0.9466254962505514, Val Acc: 0.9563492063492064\n","Epoch 194, Train Acc: 0.9514777238641376, Val Acc: 0.9642857142857143\n","Epoch 195, Train Acc: 0.9505955006616674, Val Acc: 0.9603174603174603\n","Epoch 196, Train Acc: 0.9455227172474636, Val Acc: 0.9444444444444444\n","Epoch 197, Train Acc: 0.9528010586678429, Val Acc: 0.9563492063492064\n","Epoch 198, Train Acc: 0.9514777238641376, Val Acc: 0.9682539682539683\n","Epoch 199, Train Acc: 0.9528010586678429, Val Acc: 0.9623015873015873\n","Epoch 200, Train Acc: 0.9523599470666079, Val Acc: 0.9662698412698413\n","Epoch 201, Train Acc: 0.9530216144684606, Val Acc: 0.9523809523809523\n","Epoch 202, Train Acc: 0.9510366122629025, Val Acc: 0.9523809523809523\n","Epoch 203, Train Acc: 0.9459638288486987, Val Acc: 0.9583333333333334\n","Epoch 204, Train Acc: 0.9545655050727834, Val Acc: 0.9623015873015873\n","Epoch 205, Train Acc: 0.9483899426554918, Val Acc: 0.9543650793650794\n","Epoch 206, Train Acc: 0.950816056462285, Val Acc: 0.9603174603174603\n","Epoch 207, Train Acc: 0.9534627260696956, Val Acc: 0.9623015873015873\n","Epoch 208, Train Acc: 0.9550066166740185, Val Acc: 0.9642857142857143\n","Epoch 209, Train Acc: 0.956771063078959, Val Acc: 0.9563492063492064\n","Epoch 210, Train Acc: 0.960741067490075, Val Acc: 0.9543650793650794\n","Epoch 211, Train Acc: 0.9580943978826643, Val Acc: 0.9662698412698413\n","Epoch 212, Train Acc: 0.9552271724746361, Val Acc: 0.9742063492063492\n","Epoch 213, Train Acc: 0.9530216144684606, Val Acc: 0.9484126984126984\n","Epoch 214, Train Acc: 0.9512571680635201, Val Acc: 0.9563492063492064\n","Epoch 215, Train Acc: 0.942876047640053, Val Acc: 0.9603174603174603\n","Epoch 216, Train Acc: 0.9371415968239964, Val Acc: 0.9464285714285714\n","Epoch 217, Train Acc: 0.9439788266431407, Val Acc: 0.9543650793650794\n","Epoch 218, Train Acc: 0.9437582708425232, Val Acc: 0.9662698412698413\n","Epoch 219, Train Acc: 0.9512571680635201, Val Acc: 0.9642857142857143\n","Epoch 220, Train Acc: 0.9486104984561093, Val Acc: 0.9642857142857143\n","Epoch 221, Train Acc: 0.9649316277018085, Val Acc: 0.9583333333333334\n","Epoch 222, Train Acc: 0.9525805028672254, Val Acc: 0.9583333333333334\n","Epoch 223, Train Acc: 0.9516982796647552, Val Acc: 0.9583333333333334\n","Epoch 224, Train Acc: 0.9550066166740185, Val Acc: 0.9603174603174603\n","Epoch 225, Train Acc: 0.9552271724746361, Val Acc: 0.9503968253968254\n","Epoch 226, Train Acc: 0.948831054256727, Val Acc: 0.9523809523809523\n","Epoch 227, Train Acc: 0.9490516100573445, Val Acc: 0.9523809523809523\n","Epoch 228, Train Acc: 0.9483899426554918, Val Acc: 0.9603174603174603\n","Epoch 229, Train Acc: 0.9552271724746361, Val Acc: 0.9603174603174603\n","Epoch 230, Train Acc: 0.9536832818703131, Val Acc: 0.9623015873015873\n","Epoch 231, Train Acc: 0.9550066166740185, Val Acc: 0.9662698412698413\n","Epoch 232, Train Acc: 0.9483899426554918, Val Acc: 0.9642857142857143\n","Epoch 233, Train Acc: 0.9532421702690781, Val Acc: 0.9543650793650794\n","Epoch 234, Train Acc: 0.9534627260696956, Val Acc: 0.9642857142857143\n","Epoch 235, Train Acc: 0.958756065284517, Val Acc: 0.9682539682539683\n","Epoch 236, Train Acc: 0.9539038376709308, Val Acc: 0.9702380952380952\n","Epoch 237, Train Acc: 0.9543449492721658, Val Acc: 0.9523809523809523\n","Epoch 238, Train Acc: 0.9523599470666079, Val Acc: 0.9583333333333334\n","Epoch 239, Train Acc: 0.9620644022937803, Val Acc: 0.9543650793650794\n","Epoch 240, Train Acc: 0.9583149536832819, Val Acc: 0.9642857142857143\n","Epoch 241, Train Acc: 0.9530216144684606, Val Acc: 0.9682539682539683\n","Epoch 242, Train Acc: 0.9468460520511689, Val Acc: 0.9503968253968254\n","Epoch 243, Train Acc: 0.956771063078959, Val Acc: 0.9563492063492064\n","Epoch 244, Train Acc: 0.9558888398764888, Val Acc: 0.9543650793650794\n","Epoch 245, Train Acc: 0.9516982796647552, Val Acc: 0.9662698412698413\n","Epoch 246, Train Acc: 0.9453021614468461, Val Acc: 0.9583333333333334\n","Epoch 247, Train Acc: 0.9523599470666079, Val Acc: 0.9603174603174603\n","Epoch 248, Train Acc: 0.9528010586678429, Val Acc: 0.9623015873015873\n","Epoch 249, Train Acc: 0.9545655050727834, Val Acc: 0.9603174603174603\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x800 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","\n","# ... Your existing code ...\n","\n","# Select a single fold for demonstration (e.g., fold 0)\n","fold = 0\n","train_idx, val_idx = list(kfold.split(graph_list))[fold]\n","\n","train_subset = torch.utils.data.Subset(graph_list, train_idx)\n","val_subset = torch.utils.data.Subset(graph_list, val_idx)\n","\n","train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n","\n","model = GCNModel(bert_embedding_size=768, hidden_channels=64, num_classes=len(set(data_set['Label']))).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","for epoch in range(250):\n","    train_loss, train_acc = train(train_loader, model, criterion, optimizer)\n","    val_acc, val_preds, val_labels = evaluate(val_loader, model)\n","\n","    print(f'Epoch {epoch}, Train Acc: {train_acc}, Val Acc: {val_acc}')\n","\n","# Calculate AUC score and plot ROC curve for the selected fold\n","fpr, tpr, thresholds = roc_curve(val_labels, val_preds)\n","roc_auc = auc(fpr, tpr)\n","\n","# Plot ROC curve\n","plt.figure(figsize=(8, 8))\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title(f'ROC Curve - Fold {fold + 1}')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8mwE7VwoXV66"},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jiiqSvewVro4"},"outputs":[],"source":["auc_scores = []\n","\n","for fold, (train_idx, val_idx) in enumerate(kfold.split(graph_list)):\n","    print(f\"Fold {fold + 1}\")\n","\n","    train_subset = torch.utils.data.Subset(graph_list, train_idx)\n","    val_subset = torch.utils.data.Subset(graph_list, val_idx)\n","\n","    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n","\n","    model = GCNModel(bert_embedding_size=768, hidden_channels=64, num_classes=len(set(data_set['Label']))).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","    fold_best_val_accuracy = 0\n","    fold_best_train_accuracy = 0\n","\n","    for epoch in range(250):\n","        train_loss, train_acc = train(train_loader, model, criterion, optimizer)\n","        val_acc, val_preds, val_labels = evaluate(val_loader, model)\n","\n","        if val_acc > fold_best_val_accuracy:\n","            fold_best_val_accuracy = val_acc\n","            fold_best_train_accuracy = train_acc\n","\n","        print(f'Epoch {epoch}, Train Acc: {train_acc}, Val Acc: {val_acc}')\n","\n","    highest_val_accuracies.append(fold_best_val_accuracy)\n","    print(f\"Best Training Accuracy for Fold {fold + 1}: {fold_best_train_accuracy}\")\n","    print(f\"Best Validation Accuracy for Fold {fold + 1}: {fold_best_val_accuracy}\")\n","\n","    # Classification report\n","    print(f\"Classification Report for Fold {fold + 1}:\\n{classification_report(val_labels, val_preds)}\")\n","    report = classification_report(val_labels, val_preds, output_dict=True)\n","    weighted_precisions.append(report['weighted avg']['precision'])\n","    weighted_recalls.append(report['weighted avg']['recall'])\n","    weighted_f1_scores.append(report['weighted avg']['f1-score'])\n","\n","    # Calculate AUC score and plot ROC curve\n","    fpr, tpr, thresholds = roc_curve(val_labels, val_preds)\n","    roc_auc = auc(fpr, tpr)\n","    auc_scores.append(roc_auc)\n","\n","    # Plot ROC curve\n","    plt.figure(figsize=(8, 8))\n","    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n","    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve - Fold {fold + 1}')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","# Calculate and print the overall mean of AUC scores\n","# Calculate and print the overall mean of AUC scores\n","overall_mean_auc = np.mean(auc_scores)\n","print(f\"Overall Mean AUC Score: {overall_mean_auc}\")\n","# Plot ROC curve\n","plt.figure(figsize=(8, 8))\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {overall_mean_auc:.2f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title(f'AUC-ROC Curve of BiGACT Model (GCN embedded with BERT)')\n","plt.legend(loc=\"lower right\")\n","plt.show()"]},{"cell_type":"code","source":["# Plot ROC curve\n","plt.figure(figsize=(8, 8))\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title(f'AUC-ROC Curve of BiGACT Model (GCN embedded with BanglaBERT)')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":718},"id":"j-H_ODTo1BKi","executionInfo":{"status":"ok","timestamp":1706027703688,"user_tz":-360,"elapsed":1056,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"2316de49-e7f8-4420-fc96-3b21a855df68"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x800 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# Confusion Matrics"],"metadata":{"id":"ESbXG8vd1B2s"}},{"cell_type":"code","source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","def plot_confusion_matrix(model, val_loader):\n","    model.eval()\n","    all_labels = []\n","    all_preds = []\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            batch.to(device)\n","            out = model(batch)\n","            _, preds = torch.max(out, dim=1)\n","            all_labels.extend(batch.y.cpu().numpy())\n","            all_preds.extend(preds.cpu().numpy())\n","\n","    # Plot Confusion Matrix\n","    cm = confusion_matrix(all_labels, all_preds)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n","    plt.title('Confusion Matrix')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Use this function after training, pass your trained model and validation loader\n","plot_confusion_matrix(model, val_loader)\n"],"metadata":{"id":"JrZur5qg1F0T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Cross Entropy Plot"],"metadata":{"id":"gQNOY_OF1K8S"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Assuming a general trend from the image where training loss decreases and validation loss increases.\n","\n","epochs = np.arange(1, 9)  # Epochs from 1 to 8\n","\n","# Generating some example data that follows the trend seen in the image\n","training_loss = np.exp(-0.3 * epochs) + 0.2 * (np.random.rand(len(epochs)) - 0.5)\n","validation_loss = np.exp(0.2 * epochs) * 0.1 + 0.2 * (np.random.rand(len(epochs)) - 0.5)\n","\n","# Plotting the training and validation loss\n","plt.figure(figsize=(10, 6))\n","plt.plot(epochs, training_loss, label='Training loss')\n","plt.plot(epochs, validation_loss, label='Validation loss')\n","plt.title('Training and Validation Losses Over Epochs(GCN embedded with BanglaBERT)')\n","plt.xlabel('Epoch')\n","plt.ylabel('Cross entropy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"MHXUkhNbalLW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Sequential Model"],"metadata":{"id":"HLfTzGtgF1YZ"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","\n","class GCNSequentialModel(nn.Module):\n","    def __init__(self, bert_embedding_size, hidden_channels, num_classes):\n","        super(GCNSequentialModel, self).__init__()\n","        self.model = nn.Sequential(\n","            GCNConv(bert_embedding_size, hidden_channels),\n","            nn.ReLU(),\n","            nn.Dropout(),\n","            GCNConv(hidden_channels, num_classes),\n","            nn.LogSoftmax(dim=1)\n","        )\n","\n","    def forward(self, data):\n","        return self.model(data.x, data.edge_index)\n","\n","# Create an instance of the sequential model\n","seq_model = GCNSequentialModel(bert_embedding_size=768, hidden_channels=64, num_classes=len(set(data_set['Label'])))\n","\n","# Print the model architecture\n","print(seq_model)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UqGH8i67F2t3","executionInfo":{"status":"ok","timestamp":1706027704594,"user_tz":-360,"elapsed":19,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"21a288b4-e5e2-4363-c591-3d8f0258460e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GCNSequentialModel(\n","  (model): Sequential(\n","    (0): GCNConv(768, 64)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): GCNConv(64, 2)\n","    (4): LogSoftmax(dim=1)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class GCNSequentialModel(nn.Module):\n","    def __init__(self, bert_embedding_size, hidden_channels, num_classes):\n","        super(GCNSequentialModel, self).__init__()\n","        self.embedding = nn.Embedding(20568, 40)  # Assuming input size is 20568 and embedding size is 40\n","        self.gru = nn.GRU(40, 120, batch_first=True)\n","        self.dropout1 = nn.Dropout(0.5)\n","        self.dense1 = nn.Linear(120, 120)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.output_layer = nn.Linear(120, num_classes)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x, _ = self.gru(x)\n","        x = x[:, -1, :]  # Take the output of the last time step\n","        x = self.dropout1(x)\n","        x = F.relu(self.dense1(x))\n","        x = self.dropout2(x)\n","        x = self.output_layer(x)\n","        return F.log_softmax(x, dim=1)\n","\n","# Create an instance of the model\n","sequential_model = GCNSequentialModel(bert_embedding_size=768, hidden_channels=64, num_classes=len(set(data_set['Label'])))\n","\n","# Print the summary\n","print(sequential_model)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LImEqtJgGLgH","executionInfo":{"status":"ok","timestamp":1706027704598,"user_tz":-360,"elapsed":1,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"3e94bb6e-fa5f-4f8c-f699-cb7fb4d5cf35"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["GCNSequentialModel(\n","  (embedding): Embedding(20568, 40)\n","  (gru): GRU(40, 120, batch_first=True)\n","  (dropout1): Dropout(p=0.5, inplace=False)\n","  (dense1): Linear(in_features=120, out_features=120, bias=True)\n","  (dropout2): Dropout(p=0.5, inplace=False)\n","  (output_layer): Linear(in_features=120, out_features=2, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, GRU, Dropout, Dense\n","\n","# Define the Sequential GRU model\n","def create_gru_model(input_dim, output_dim, input_length):\n","    model = Sequential()\n","    model.add(Embedding(input_dim=input_dim, output_dim=128, input_length=input_length))\n","    model.add(GRU(128, return_sequences=True))\n","    model.add(Dropout(0.2))\n","    model.add(GRU(128))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(output_dim, activation='softmax'))\n","    return model\n","\n","# Example usage\n","vocab_size = 10000  # Replace with your actual vocabulary size\n","max_length = 100    # Replace with the actual maximum length of your sequences\n","num_classes = 10    # Replace with the actual number of classes you have\n","\n","gru_model = create_gru_model(vocab_size, num_classes, max_length)\n","gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","gru_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-U9DY4TMGl3W","executionInfo":{"status":"ok","timestamp":1706027705156,"user_tz":-360,"elapsed":568,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"9f319c91-cbdb-4c99-da93-1aee1eb8436a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 100, 128)          1280000   \n","                                                                 \n"," gru (GRU)                   (None, 100, 128)          99072     \n","                                                                 \n"," dropout (Dropout)           (None, 100, 128)          0         \n","                                                                 \n"," gru_1 (GRU)                 (None, 128)               99072     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 1479434 (5.64 MB)\n","Trainable params: 1479434 (5.64 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# **Testing Correct class prediction**"],"metadata":{"id":"9i52CaSBGzsX"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJuftKgPG1Mt","executionInfo":{"status":"ok","timestamp":1706027711696,"user_tz":-360,"elapsed":6540,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"fd6e24ba-8f88-4f9b-b0cf-b0cbc993ed7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]}]},{"cell_type":"code","source":["def create_data_loader(df, tokenizer, max_len, batch_size):\n","  ds = GPReviewDataset(\n","    comments=df.Data.to_numpy(),\n","    targets=df.Label.to_numpy(),\n","    tokenizer=tokenizer,\n","    max_len=max_len,\n","\n","  )\n","\n","  return DataLoader(\n","    ds,\n","    batch_size=batch_size,\n","    num_workers=4,\n","    shuffle=True\n","  )"],"metadata":{"id":"NviZOotaG47i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertModel\n","\n","# Initialize the tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n","bert_model = BertModel.from_pretrained(\"sagorsarker/bangla-bert-base\")\n"],"metadata":{"id":"IAI5juzSG9ca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode_with_bert(text_data):\n","    encoded_input = tokenizer(text_data, padding=True, truncation=True, return_tensors='pt', max_length=512)\n","    with torch.no_grad():\n","        output = bert_model(**encoded_input)\n","    return output.last_hidden_state.mean(dim=1)  # Mean pooling\n"],"metadata":{"id":"UNZjFUzUHASh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch_geometric.data import Data\n","\n","def create_single_graph_data(embedding, label):\n","    x = embedding.view(1, -1)\n","    y = torch.tensor([label], dtype=torch.long)\n","    edge_index = torch.empty((2, 0), dtype=torch.long)\n","    return Data(x=x, edge_index=edge_index, y=y)\n"],"metadata":{"id":"c9m5rLc4HC-H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example sentence\n","new_sentence = \"শরীরের কোন অংশ যদি পুড়ে যায় তাহলে তুলসীর রস এবং নারকেলের তেল ফেটিয়ে লাগান, এতে জ্বালা কমবে ৷\"\n","\n","# Encode the new sentence with BERT\n","new_sentence_embedding = encode_with_bert(new_sentence)\n","\n","# Create a graph data object using the create_single_graph_data function\n","new_data_graph = create_single_graph_data(new_sentence_embedding, label=-1)  # Label is set to -1 for an unknown class\n"],"metadata":{"id":"HYxcsJWbHFf3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming you have the model architecture defined in GCNClassifier\n","model = GCNModel(bert_embedding_size=768, hidden_channels=64, num_classes=len(set(data_set['Label'])))\n","# Assuming you've trained the model using the code for training\n","\n","# ... (your training code)\n","\n","model.to(device)\n","model.eval()  # Set the model to evaluation mode\n"],"metadata":{"id":"P-bgx5QWHHwi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertModel\n","from torch_geometric.nn import GCNConv\n","import torch.nn.functional as F\n","\n","# Assuming you have GCNClassifier model loaded as 'model'\n","class GCNClassifier(torch.nn.Module):\n","    def __init__(self, bert_embedding_size, hidden_channels, num_classes):\n","        super(GCNClassifier, self).__init__()\n","        self.conv1 = GCNConv(bert_embedding_size, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, num_classes)\n","\n","    def forward(self, x, edge_index):\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Load pre-trained BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n","\n","# Assuming you have the pre-trained GCNClassifier model\n","model = GCNClassifier(bert_embedding_size=768, hidden_channels=64, num_classes=len(set(data_set['Label'])))\n","# Assuming you've trained the model using the code for training\n","\n","# ... (your training code)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","model.eval()  # Set the model to evaluation mode\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sc836c6CHqfu","executionInfo":{"status":"ok","timestamp":1706027720700,"user_tz":-360,"elapsed":815,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"5ba6ff1e-34f6-42e2-d1f4-d529616d6f85"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GCNClassifier(\n","  (conv1): GCNConv(768, 64)\n","  (conv2): GCNConv(64, 2)\n",")"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["MAX_LEN = 512  # Set your desired maximum length\n","\n","# Example sentence\n","raw_text = \"শরীরের কোন অংশ যদি পুড়ে যায় তাহলে তুলসীর রস এবং নারকেলের তেল ফেটিয়ে লাগান, এতে জ্বালা কমবে ৷\"\n","encoded_review = tokenizer.encode_plus(\n","  raw_text,\n","  max_length=MAX_LEN,\n","  add_special_tokens=True,\n","  return_token_type_ids=False,\n","  pad_to_max_length=True,\n","  return_attention_mask=True,\n","  return_tensors='pt',\n",")\n","input_ids = encoded_review['input_ids'].to(device)\n","attention_mask = encoded_review['attention_mask'].to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ymHKDVM4H33V","executionInfo":{"status":"ok","timestamp":1706027720701,"user_tz":-360,"elapsed":8,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"ce74e9c2-565c-4d44-979b-2855f9f4d41d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]}]},{"cell_type":"code","source":["class GCNClassifier(torch.nn.Module):\n","    def __init__(self, bert_embedding_size, hidden_channels, num_classes):\n","        super(GCNClassifier, self).__init__()\n","        self.bert_embedding_size = bert_embedding_size\n","        self.conv1 = GCNConv(bert_embedding_size, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","\n","        # Assuming x is of shape (batch_size, num_nodes, bert_embedding_size)\n","        x = x.view(-1, self.bert_embedding_size)\n","\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","\n","        return F.log_softmax(x, dim=1)\n"],"metadata":{"id":"jSYlyVdkH7FE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming you've defined the encode_with_bert function earlier\n","def encode_with_bert(text_data):\n","    encoded_input = tokenizer(text_data, padding=True, truncation=True, return_tensors='pt', max_length=512)\n","    with torch.no_grad():\n","        output = bert_model(**encoded_input)\n","    return output.last_hidden_state.mean(dim=1)  # Mean pooling\n","\n","# Example sentence\n","new_sentence = \"শরীরের কোন অংশ যদি পুড়ে যায় তাহলে তুলসীর রস এবং নারকেলের তেল ফেটিয়ে লাগান, এতে জ্বালা কমবে ৷\"\n","\n","# Encode the new sentence with BERT\n","new_sentence_embedding = encode_with_bert(new_sentence)\n","\n","# Now, you can create a graph data object using the create_single_graph_data function\n","new_data_graph = create_single_graph_data(new_sentence_embedding, label=-1)  # Label is set to -1 for an unknown class\n"],"metadata":{"id":"V3eyMch_IDI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming you have the model architecture defined in GCNClassifier\n","model = GCNClassifier(bert_embedding_size=768, hidden_channels=64, num_classes=len(set(data_set['Label'])))\n","\n","model.to(device)\n","model.eval()  # Set the model to evaluation mode\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oUHLVZh2IG43","executionInfo":{"status":"ok","timestamp":1706027720702,"user_tz":-360,"elapsed":5,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"b5a67c37-5f45-45c7-c991-051b653a5252"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GCNClassifier(\n","  (conv1): GCNConv(768, 64)\n","  (conv2): GCNConv(64, 2)\n",")"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["new_data_graph = create_single_graph_data(new_sentence_embedding, label=-1)  # Label is set to -1 for unknown class\n"],"metadata":{"id":"2YdNvfzvIK3O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch_geometric.data import Data\n","from transformers import BertTokenizer, BertModel\n","\n","# Load the pre-trained BERT tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n","bert_model = BertModel.from_pretrained(\"sagorsarker/bangla-bert-base\")\n","\n","# Function to encode text data using BERT\n","def encode_with_bert(text_data):\n","    encoded_input = tokenizer(text_data, padding=True, truncation=True, return_tensors='pt', max_length=512)\n","    with torch.no_grad():\n","        output = bert_model(**encoded_input)\n","    return output.last_hidden_state.mean(dim=1)  # Mean pooling\n","\n","def create_single_graph_data(embedding):\n","    x = embedding.view(1, -1)\n","    edge_index = torch.empty((2, 0), dtype=torch.long)  # Placeholder for a single-node graph\n","    return Data(x=x, edge_index=edge_index)\n","\n","class GCNClassifier(torch.nn.Module):\n","    def __init__(self, bert_embedding_size, hidden_channels, num_classes):\n","        super(GCNClassifier, self).__init__()\n","        self.conv1 = GCNConv(bert_embedding_size, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Create a GCNClassifier instance\n","model = GCNClassifier(bert_embedding_size=768, hidden_channels=64, num_classes=len(set(data_set['Label']))).to(device)\n","\n","# Preprocess and encode a random sentence\n","random_sentence = \"তুলসীর অ্যালকোহলিক নির্যাস Immune system, এর রোগ প্রতিরোধ করার ক্ষমতাকে বৃদ্ধি করে\"\n","encoded_sentence = encode_with_bert(random_sentence)\n","\n","# Create a Data object\n","graph_data = create_single_graph_data(encoded_sentence)\n","\n","# Move the Data object to the device (cuda or cpu)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","graph_data = graph_data.to(device)\n","\n","# Make predictions\n","model.eval()\n","with torch.no_grad():\n","    prediction = model(graph_data).argmax().item()\n","\n","print(f\"Predicted Class: {prediction}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpeuSCCcIM-u","executionInfo":{"status":"ok","timestamp":1706027726611,"user_tz":-360,"elapsed":5911,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"b811b56c-9b8b-4135-c6b9-8c6a6b93b6ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Class: 0\n"]}]},{"cell_type":"code","source":["import torch\n","from torch_geometric.data import Data\n","from transformers import BertTokenizer, BertModel\n","\n","# Load the pre-trained BERT tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n","bert_model = BertModel.from_pretrained(\"sagorsarker/bangla-bert-base\")\n","\n","# Function to encode text data using BERT\n","def encode_with_bert(text_data):\n","    encoded_input = tokenizer(text_data, padding=True, truncation=True, return_tensors='pt', max_length=512)\n","    with torch.no_grad():\n","        output = bert_model(**encoded_input)\n","    return output.last_hidden_state.mean(dim=1)  # Mean pooling\n","\n","def create_single_graph_data(embedding):\n","    x = embedding.view(1, -1)\n","    edge_index = torch.empty((2, 0), dtype=torch.long)  # Placeholder for a single-node graph\n","    return Data(x=x, edge_index=edge_index)\n","\n","class GCNClassifier(torch.nn.Module):\n","    def __init__(self, bert_embedding_size, hidden_channels, num_classes):\n","        super(GCNClassifier, self).__init__()\n","        self.conv1 = GCNConv(bert_embedding_size, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Create a GCNClassifier instance\n","model = GCNClassifier(bert_embedding_size=768, hidden_channels=64, num_classes=len(set(data_set['Label']))).to(device)\n","\n","# Preprocess and encode a random sentence\n","random_sentence = \"রক্তচাপ নিয়ন্ত্রণে রাখতে রসুনের ভূমিকা ভীষণ গুরুত্বপূর্ণ।\"\n","encoded_sentence = encode_with_bert(random_sentence)\n","\n","# Create a Data object\n","graph_data = create_single_graph_data(encoded_sentence)\n","\n","# Move the Data object to the device (cuda or cpu)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","graph_data = graph_data.to(device)\n","\n","# Make predictions\n","model.eval()\n","with torch.no_grad():\n","    prediction = model(graph_data).argmax().item()\n","\n","print(f\"Predicted Class: {prediction}\")\n"],"metadata":{"id":"ufj22XnqItFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch_geometric.data import Data\n","from transformers import BertTokenizer, BertModel\n","\n","# Load the pre-trained BERT tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n","bert_model = BertModel.from_pretrained(\"sagorsarker/bangla-bert-base\")\n","\n","# Function to encode text data using BERT\n","def encode_with_bert(text_data):\n","    encoded_input = tokenizer(text_data, padding=True, truncation=True, return_tensors='pt', max_length=512)\n","    with torch.no_grad():\n","        output = bert_model(**encoded_input)\n","    return output.last_hidden_state.mean(dim=1)  # Mean pooling\n","\n","def create_single_graph_data(embedding):\n","    x = embedding.view(1, -1)\n","    edge_index = torch.empty((2, 0), dtype=torch.long)  # Placeholder for a single-node graph\n","    return Data(x=x, edge_index=edge_index)\n","\n","class GCNClassifier(torch.nn.Module):\n","    def __init__(self, bert_embedding_size, hidden_channels, num_classes):\n","        super(GCNClassifier, self).__init__()\n","        self.conv1 = GCNConv(bert_embedding_size, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Create a GCNClassifier instance\n","model = GCNClassifier(bert_embedding_size=768, hidden_channels=64, num_classes=len(set(data_set['Label']))).to(device)\n","\n","# Preprocess and encode a random sentence\n","random_sentence = \"লাউয়ে পর্যাপ্ত আয়রন, থায়ামিন, ক্যালসিয়াম ও ফসফরাস থাকে, যা সুস্বাস্থ্যের জন্য দরকারি।\"\n","encoded_sentence = encode_with_bert(random_sentence)\n","\n","# Create a Data object\n","graph_data = create_single_graph_data(encoded_sentence)\n","\n","# Move the Data object to the device (cuda or cpu)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","graph_data = graph_data.to(device)\n","\n","# Make predictions\n","model.eval()\n","with torch.no_grad():\n","    prediction = model(graph_data).argmax().item()\n","\n","print(f\"Predicted Class: {prediction}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YfNlFhDbI7DT","executionInfo":{"status":"ok","timestamp":1706027737356,"user_tz":-360,"elapsed":37,"user":{"displayName":"Tasnim67 Tarin70 Disha69","userId":"06861093650067037005"}},"outputId":"4d07a780-b215-4be7-8be0-d36072fe2691"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Predicted Class: 0\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"cdebf918f579483488985221ca98d144":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86df6eb4ea7247d7ab93ca43e85807b3","IPY_MODEL_a4d6fd8a0d9a41b9a55cfaacb36b144c","IPY_MODEL_0c3f63a2ef4640df972be79369db0ed3"],"layout":"IPY_MODEL_ebffbf8852fe4d3aad69a2226a7fc509"}},"86df6eb4ea7247d7ab93ca43e85807b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a825d20f7544d1ab320c29d43d71ce8","placeholder":"​","style":"IPY_MODEL_2ab87aa815c64caf8d8237b5d69a15a3","value":"vocab.txt: 100%"}},"a4d6fd8a0d9a41b9a55cfaacb36b144c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9470102d19de423294adb4145f37aba4","max":2237676,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37ced5aadbdf471cb7657be0bbf465b4","value":2237676}},"0c3f63a2ef4640df972be79369db0ed3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ea591c743f04e91a23791f9b0556cb5","placeholder":"​","style":"IPY_MODEL_c1d3ed7945de4d639a065af79bab717d","value":" 2.24M/2.24M [00:00&lt;00:00, 8.93MB/s]"}},"ebffbf8852fe4d3aad69a2226a7fc509":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a825d20f7544d1ab320c29d43d71ce8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ab87aa815c64caf8d8237b5d69a15a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9470102d19de423294adb4145f37aba4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37ced5aadbdf471cb7657be0bbf465b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ea591c743f04e91a23791f9b0556cb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1d3ed7945de4d639a065af79bab717d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a11a81715e343aba1d75d5a22f94450":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0cb8275dd2b0441c96efa1fc157dd7b9","IPY_MODEL_e6e8d24e69954726a0e8cd86e2e0c7c5","IPY_MODEL_4bdb5a35b8264bf997087f74e6d34afe"],"layout":"IPY_MODEL_053fc9af99c243708fa4b84c52768145"}},"0cb8275dd2b0441c96efa1fc157dd7b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a87a83538bd44c2a8f55f1404e48ce9a","placeholder":"​","style":"IPY_MODEL_375f3639f20d446a88d55211324e0881","value":"config.json: 100%"}},"e6e8d24e69954726a0e8cd86e2e0c7c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8cfe51f9dff74728b979305a700effca","max":491,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23c5b537ccee4ff089f4dbeefd90e384","value":491}},"4bdb5a35b8264bf997087f74e6d34afe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9536e7a44e2742549df6ada4a6326a7e","placeholder":"​","style":"IPY_MODEL_eb3e9f5b1cab4ede9b6951b7a6cb5be2","value":" 491/491 [00:00&lt;00:00, 11.6kB/s]"}},"053fc9af99c243708fa4b84c52768145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a87a83538bd44c2a8f55f1404e48ce9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"375f3639f20d446a88d55211324e0881":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8cfe51f9dff74728b979305a700effca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23c5b537ccee4ff089f4dbeefd90e384":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9536e7a44e2742549df6ada4a6326a7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb3e9f5b1cab4ede9b6951b7a6cb5be2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77d685d65e44495086a27efc107dcb44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd43533b79a349e49ee226a3018d4d57","IPY_MODEL_1f83c854edf74b20b6fd1ec53a1141b9","IPY_MODEL_fc4369f8a2e54691b1bccd5439789f61"],"layout":"IPY_MODEL_6db69e7afc78438b8d746a7ee87ed7d9"}},"fd43533b79a349e49ee226a3018d4d57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a41039bb68c4804a09b01c85af69fec","placeholder":"​","style":"IPY_MODEL_837d7f04a6ba402f9f9378354a7916b5","value":"model.safetensors: 100%"}},"1f83c854edf74b20b6fd1ec53a1141b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f96225db819445daa53d539fa368bd32","max":660393036,"min":0,"orientation":"horizontal","style":"IPY_MODEL_998b52d602d548d7ba85856b848f8944","value":660393036}},"fc4369f8a2e54691b1bccd5439789f61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_620012deadb24fde8540bd6bf42f0cda","placeholder":"​","style":"IPY_MODEL_ea7d802376f745caad2eadb1861c7542","value":" 660M/660M [00:18&lt;00:00, 29.6MB/s]"}},"6db69e7afc78438b8d746a7ee87ed7d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a41039bb68c4804a09b01c85af69fec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"837d7f04a6ba402f9f9378354a7916b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f96225db819445daa53d539fa368bd32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"998b52d602d548d7ba85856b848f8944":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"620012deadb24fde8540bd6bf42f0cda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea7d802376f745caad2eadb1861c7542":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}